diff --git a/3rdparty/find_dependencies.cmake b/3rdparty/find_dependencies.cmake
index c1a85010e94..682c645f9e5 100644
--- a/3rdparty/find_dependencies.cmake
+++ b/3rdparty/find_dependencies.cmake
@@ -1052,7 +1052,7 @@ if(NOT USE_SYSTEM_FMT)
     target_compile_definitions(3rdparty_fmt INTERFACE FMT_STRING_ALIAS=1)
     list(APPEND Open3D_3RDPARTY_HEADER_TARGETS_FROM_CUSTOM Open3D::3rdparty_fmt)
 else()
-    list(APPEND Open3D_3RDPARTY_HEADER_TARGETS_FROM_SYSTEM Open3D::3rdparty_fmt)
+    list(APPEND Open3D_3RDPARTY_PUBLIC_TARGETS_FROM_SYSTEM Open3D::3rdparty_fmt)
 endif()
 
 # Pybind11
@@ -1410,7 +1410,12 @@ if(USE_SYSTEM_MSGPACK)
         TARGETS msgpackc
     )
     if(NOT 3rdparty_msgpack_FOUND)
-        set(USE_SYSTEM_MSGPACK OFF)
+        open3d_pkg_config_3rdparty_library(3rdparty_msgpack
+            SEARCH_ARGS msgpack
+        )
+        if(NOT 3rdparty_msgpack_FOUND)
+            set(USE_SYSTEM_MSGPACK OFF)
+        endif()
     endif()
 endif()
 if(NOT USE_SYSTEM_MSGPACK)
diff --git a/3rdparty/fmt/fmt.cmake b/3rdparty/fmt/fmt.cmake
index 4e576c86f16..b4c7a262091 100644
--- a/3rdparty/fmt/fmt.cmake
+++ b/3rdparty/fmt/fmt.cmake
@@ -5,8 +5,8 @@ set(FMT_LIB_NAME fmt)
 ExternalProject_Add(
     ext_fmt
     PREFIX fmt
-    URL https://github.com/fmtlib/fmt/archive/refs/tags/6.0.0.tar.gz
-    URL_HASH SHA256=f1907a58d5e86e6c382e51441d92ad9e23aea63827ba47fd647eacc0d3a16c78
+    URL https://github.com/fmtlib/fmt/archive/refs/tags/9.0.0.tar.gz
+    URL_HASH SHA256=9a1e0e9e843a356d65c7604e2c8bf9402b50fe294c355de0095ebd42fb9bd2c5
     DOWNLOAD_DIR "${OPEN3D_THIRD_PARTY_DOWNLOAD_DIR}/fmt"
     UPDATE_COMMAND ""
     CMAKE_ARGS
diff --git a/CHANGELOG.md b/CHANGELOG.md
index dbe0ba8e853..a0880065ba5 100644
--- a/CHANGELOG.md
+++ b/CHANGELOG.md
@@ -6,11 +6,12 @@
 * Corrected documentation for KDTree (typo in Notebook) (PR #4744)
 * Remove `setuptools` and `wheel` from requirements for end users (PR #5020)
 * Fix various typos (PR #5070)
-* Exposed more functionality in SLAM pipeline
+* Exposed more functionality in SLAM and odometry pipelines
 * Fix for depth estimation for VoxelBlockGrid
 * Reserve fragment buffer for VoxelBlockGrid operations
 * Fix raycasting scene: Allow setting of number of threads that are used for building a raycasting scene
 * Fix Python bindings for CUDA device synchronization, voxel grid saving (PR #5425)
+* Support msgpack versions without cmake
 
 ## 0.13
 
diff --git a/cpp/benchmarks/core/BinaryEW.cpp b/cpp/benchmarks/core/BinaryEW.cpp
index e077ec879dc..868fd89fdaf 100644
--- a/cpp/benchmarks/core/BinaryEW.cpp
+++ b/cpp/benchmarks/core/BinaryEW.cpp
@@ -53,6 +53,7 @@ enum class BinaryOpCode {
     Eq,
     Neq,
 };
+using fmt::enums::format_as;
 
 static std::function<Tensor(const Tensor&, const Tensor&)> MakeOperation(
         BinaryOpCode op) {
diff --git a/cpp/benchmarks/core/UnaryEW.cpp b/cpp/benchmarks/core/UnaryEW.cpp
index 4cbde15315c..2a32dd6d017 100644
--- a/cpp/benchmarks/core/UnaryEW.cpp
+++ b/cpp/benchmarks/core/UnaryEW.cpp
@@ -56,6 +56,8 @@ enum class UnaryOpCode {
     LogicalNot,
 };
 
+using fmt::enums::format_as;
+
 std::function<Tensor(const Tensor&)> MakeOperation(UnaryOpCode op) {
     switch (op) {
         case UnaryOpCode::Sqrt:
diff --git a/cpp/benchmarks/t/geometry/PointCloud.cpp b/cpp/benchmarks/t/geometry/PointCloud.cpp
index ef3ee367473..c75a8ecee0e 100644
--- a/cpp/benchmarks/t/geometry/PointCloud.cpp
+++ b/cpp/benchmarks/t/geometry/PointCloud.cpp
@@ -343,6 +343,24 @@ void CropByAxisAlignedBox(benchmark::State& state, const core::Device& device) {
     }
 }
 
+void CropByOrientedBox(benchmark::State& state, const core::Device& device) {
+    t::geometry::PointCloud pcd;
+    t::io::ReadPointCloud(path, pcd, {"auto", false, false, false});
+
+    pcd = pcd.To(device);
+    t::geometry::OrientedBoundingBox box(
+            core::Tensor::Init<float>({0, 0, 0}, device),
+            core::Tensor::Eye(3, core::Float32, device),
+            core::Tensor::Init<float>({1, 1, 1}, device));
+
+    // Warm up.
+    pcd.Crop(box);
+
+    for (auto _ : state) {
+        pcd.Crop(box);
+    }
+}
+
 void LegacyCropByAxisAlignedBox(benchmark::State& state, const int no_use) {
     open3d::geometry::PointCloud pcd;
     open3d::io::ReadPointCloud(path, pcd, {"auto", false, false, false});
@@ -358,6 +376,22 @@ void LegacyCropByAxisAlignedBox(benchmark::State& state, const int no_use) {
     }
 }
 
+void LegacyCropByOrientedBox(benchmark::State& state, const int no_use) {
+    open3d::geometry::PointCloud pcd;
+    open3d::io::ReadPointCloud(path, pcd, {"auto", false, false, false});
+
+    open3d::geometry::OrientedBoundingBox box(Eigen::Vector3d(0, 0, 0),
+                                              Eigen::Matrix3d::Identity(),
+                                              Eigen::Vector3d(1, 1, 1));
+
+    // Warm up.
+    pcd.Crop(box);
+
+    for (auto _ : state) {
+        pcd.Crop(box);
+    }
+}
+
 BENCHMARK_CAPTURE(FromLegacyPointCloud, CPU, core::Device("CPU:0"))
         ->Unit(benchmark::kMillisecond);
 
@@ -580,6 +614,8 @@ BENCHMARK_CAPTURE(RemoveStatisticalOutliers, CPU[30], core::Device("CPU:0"), 30)
         ->Unit(benchmark::kMillisecond);
 BENCHMARK_CAPTURE(CropByAxisAlignedBox, CPU, core::Device("CPU:0"))
         ->Unit(benchmark::kMillisecond);
+BENCHMARK_CAPTURE(CropByOrientedBox, CPU, core::Device("CPU:0"))
+        ->Unit(benchmark::kMillisecond);
 BENCHMARK_CAPTURE(ComputeBoundaryPoints,
                   CPU Float32,
                   core::Device("CPU:0"),
@@ -598,13 +634,15 @@ BENCHMARK_CAPTURE(ComputeBoundaryPoints,
 BENCHMARK_CAPTURE(
         RemoveRadiusOutliers, CUDA[50 | 0.05], core::Device("CUDA:0"), 50, 0.03)
         ->Unit(benchmark::kMillisecond);
+BENCHMARK_CAPTURE(CropByAxisAlignedBox, CUDA, core::Device("CUDA:0"))
+        ->Unit(benchmark::kMillisecond);
+BENCHMARK_CAPTURE(CropByOrientedBox, CUDA, core::Device("CUDA:0"))
+        ->Unit(benchmark::kMillisecond);
 BENCHMARK_CAPTURE(RemoveStatisticalOutliers,
                   CUDA[30],
                   core::Device("CUDA:0"),
                   30)
         ->Unit(benchmark::kMillisecond);
-BENCHMARK_CAPTURE(CropByAxisAlignedBox, CPU, core::Device("CUDA:0"))
-        ->Unit(benchmark::kMillisecond);
 BENCHMARK_CAPTURE(ComputeBoundaryPoints,
                   CUDA Float32,
                   core::Device("CUDA:0"),
@@ -627,6 +665,8 @@ BENCHMARK_CAPTURE(LegacyRemoveStatisticalOutliers, Legacy[30], 30)
         ->Unit(benchmark::kMillisecond);
 BENCHMARK_CAPTURE(LegacyCropByAxisAlignedBox, Legacy, 1)
         ->Unit(benchmark::kMillisecond);
+BENCHMARK_CAPTURE(LegacyCropByOrientedBox, Legacy, 1)
+        ->Unit(benchmark::kMillisecond);
 
 }  // namespace geometry
 }  // namespace t
diff --git a/cpp/open3d/core/CUDAUtils.h b/cpp/open3d/core/CUDAUtils.h
index aba1168bd97..69e54cdb1e6 100644
--- a/cpp/open3d/core/CUDAUtils.h
+++ b/cpp/open3d/core/CUDAUtils.h
@@ -66,7 +66,8 @@
 #define OPEN3D_CUDA_CHECK(err)
 #define OPEN3D_GET_LAST_CUDA_ERROR(message)
 #define CUDA_CALL(cuda_function, ...) \
-    utility::LogError("Not built with CUDA, cannot call " #cuda_function);
+    open3d::utility::LogError(        \
+            "Not built with CUDA, cannot call " #cuda_function);
 
 #endif  // #ifdef BUILD_CUDA_MODULE
 
@@ -225,6 +226,19 @@ int GetCUDACurrentDeviceTextureAlignment();
 
 /// Returns the size of total global memory for the current device.
 size_t GetCUDACurrentTotalMemSize();
+
+#else
+
+/// When CUDA is not enabled, this is a dummy class.
+class CUDAScopedDevice {
+public:
+    explicit CUDAScopedDevice(int device_id) {}
+    explicit CUDAScopedDevice(const Device& device) {}
+    ~CUDAScopedDevice() {}
+    CUDAScopedDevice(const CUDAScopedDevice&) = delete;
+    CUDAScopedDevice& operator=(const CUDAScopedDevice&) = delete;
+};
+
 #endif
 
 namespace cuda {
diff --git a/cpp/open3d/core/SizeVector.cpp b/cpp/open3d/core/SizeVector.cpp
index 4a0f4283c38..2ea1bb17a8e 100644
--- a/cpp/open3d/core/SizeVector.cpp
+++ b/cpp/open3d/core/SizeVector.cpp
@@ -148,7 +148,9 @@ int64_t SizeVector::GetLength() const {
     }
 }
 
-std::string SizeVector::ToString() const { return fmt::format("{}", *this); }
+std::string SizeVector::ToString() const {
+    return fmt::format("{{{}}}", fmt::join(*this, ", "));
+}
 
 void SizeVector::AssertCompatible(const DynamicSizeVector& dsv,
                                   const std::string msg) const {
diff --git a/cpp/open3d/core/Tensor.h b/cpp/open3d/core/Tensor.h
index 5a869434377..8a110b918f6 100644
--- a/cpp/open3d/core/Tensor.h
+++ b/cpp/open3d/core/Tensor.h
@@ -756,6 +756,9 @@ class Tensor : public IsDevice {
     /// Element-wise negation of a tensor, in-place.
     Tensor Neg_();
 
+    /// Unary minus of a tensor, returning a new tensor.
+    Tensor operator-() const { return Neg(); }
+
     /// Element-wise exponential of a tensor, returning a new tensor.
     Tensor Exp() const;
 
diff --git a/cpp/open3d/core/hashmap/CUDA/SlabHashBackend.h b/cpp/open3d/core/hashmap/CUDA/SlabHashBackend.h
index 4c0c2161b2d..08ad28c7f15 100644
--- a/cpp/open3d/core/hashmap/CUDA/SlabHashBackend.h
+++ b/cpp/open3d/core/hashmap/CUDA/SlabHashBackend.h
@@ -93,22 +93,27 @@ SlabHashBackend<Key, Hash, Eq>::SlabHashBackend(
         const std::vector<int64_t>& value_dsizes,
         const Device& device)
     : DeviceHashBackend(init_capacity, key_dsize, value_dsizes, device) {
+    CUDAScopedDevice scoped_device(this->device_);
     Allocate(init_capacity);
 }
 
 template <typename Key, typename Hash, typename Eq>
 SlabHashBackend<Key, Hash, Eq>::~SlabHashBackend() {
+    CUDAScopedDevice scoped_device(this->device_);
     Free();
 }
 
 template <typename Key, typename Hash, typename Eq>
-void SlabHashBackend<Key, Hash, Eq>::Reserve(int64_t capacity) {}
+void SlabHashBackend<Key, Hash, Eq>::Reserve(int64_t capacity) {
+    CUDAScopedDevice scoped_device(this->device_);
+}
 
 template <typename Key, typename Hash, typename Eq>
 void SlabHashBackend<Key, Hash, Eq>::Find(const void* input_keys,
                                           buf_index_t* output_buf_indices,
                                           bool* output_masks,
                                           int64_t count) {
+    CUDAScopedDevice scoped_device(this->device_);
     if (count == 0) return;
 
     OPEN3D_CUDA_CHECK(cudaMemset(output_masks, 0, sizeof(bool) * count));
@@ -127,6 +132,7 @@ template <typename Key, typename Hash, typename Eq>
 void SlabHashBackend<Key, Hash, Eq>::Erase(const void* input_keys,
                                            bool* output_masks,
                                            int64_t count) {
+    CUDAScopedDevice scoped_device(this->device_);
     if (count == 0) return;
 
     OPEN3D_CUDA_CHECK(cudaMemset(output_masks, 0, sizeof(bool) * count));
@@ -152,6 +158,7 @@ void SlabHashBackend<Key, Hash, Eq>::Erase(const void* input_keys,
 template <typename Key, typename Hash, typename Eq>
 int64_t SlabHashBackend<Key, Hash, Eq>::GetActiveIndices(
         buf_index_t* output_buf_indices) {
+    CUDAScopedDevice scoped_device(this->device_);
     uint32_t* count = static_cast<uint32_t*>(
             MemoryManager::Malloc(sizeof(uint32_t), this->device_));
     OPEN3D_CUDA_CHECK(cudaMemset(count, 0, sizeof(uint32_t)));
@@ -177,6 +184,7 @@ int64_t SlabHashBackend<Key, Hash, Eq>::GetActiveIndices(
 
 template <typename Key, typename Hash, typename Eq>
 void SlabHashBackend<Key, Hash, Eq>::Clear() {
+    CUDAScopedDevice scoped_device(this->device_);
     // Clear the heap
     this->buffer_->ResetHeap();
 
@@ -192,16 +200,19 @@ void SlabHashBackend<Key, Hash, Eq>::Clear() {
 
 template <typename Key, typename Hash, typename Eq>
 int64_t SlabHashBackend<Key, Hash, Eq>::Size() const {
+    CUDAScopedDevice scoped_device(this->device_);
     return this->buffer_->GetHeapTopIndex();
 }
 
 template <typename Key, typename Hash, typename Eq>
 int64_t SlabHashBackend<Key, Hash, Eq>::GetBucketCount() const {
+    CUDAScopedDevice scoped_device(this->device_);
     return bucket_count_;
 }
 
 template <typename Key, typename Hash, typename Eq>
 std::vector<int64_t> SlabHashBackend<Key, Hash, Eq>::BucketSizes() const {
+    CUDAScopedDevice scoped_device(this->device_);
     thrust::device_vector<int64_t> elems_per_bucket(impl_.bucket_count_);
     thrust::fill(elems_per_bucket.begin(), elems_per_bucket.end(), 0);
 
@@ -222,6 +233,7 @@ std::vector<int64_t> SlabHashBackend<Key, Hash, Eq>::BucketSizes() const {
 
 template <typename Key, typename Hash, typename Eq>
 float SlabHashBackend<Key, Hash, Eq>::LoadFactor() const {
+    CUDAScopedDevice scoped_device(this->device_);
     return float(Size()) / float(this->bucket_count_);
 }
 
@@ -232,6 +244,7 @@ void SlabHashBackend<Key, Hash, Eq>::Insert(
         buf_index_t* output_buf_indices,
         bool* output_masks,
         int64_t count) {
+    CUDAScopedDevice scoped_device(this->device_);
     if (count == 0) return;
 
     /// Increase heap_top to pre-allocate potential memory increment and
@@ -269,6 +282,7 @@ void SlabHashBackend<Key, Hash, Eq>::Insert(
 
 template <typename Key, typename Hash, typename Eq>
 void SlabHashBackend<Key, Hash, Eq>::Allocate(int64_t capacity) {
+    CUDAScopedDevice scoped_device(this->device_);
     this->bucket_count_ = capacity * 2;
     this->capacity_ = capacity;
 
@@ -294,6 +308,7 @@ void SlabHashBackend<Key, Hash, Eq>::Allocate(int64_t capacity) {
 
 template <typename Key, typename Hash, typename Eq>
 void SlabHashBackend<Key, Hash, Eq>::Free() {
+    CUDAScopedDevice scoped_device(this->device_);
     buffer_accessor_.Shutdown(this->device_);
     MemoryManager::Free(impl_.bucket_list_head_, this->device_);
 }
diff --git a/cpp/open3d/core/hashmap/CUDA/StdGPUHashBackend.h b/cpp/open3d/core/hashmap/CUDA/StdGPUHashBackend.h
index 18a2f91ce3c..fe827fba1a1 100644
--- a/cpp/open3d/core/hashmap/CUDA/StdGPUHashBackend.h
+++ b/cpp/open3d/core/hashmap/CUDA/StdGPUHashBackend.h
@@ -186,16 +186,19 @@ StdGPUHashBackend<Key, Hash, Eq>::StdGPUHashBackend(
         const std::vector<int64_t>& value_dsizes,
         const Device& device)
     : DeviceHashBackend(init_capacity, key_dsize, value_dsizes, device) {
+    CUDAScopedDevice scoped_device(this->device_);
     Allocate(init_capacity);
 }
 
 template <typename Key, typename Hash, typename Eq>
 StdGPUHashBackend<Key, Hash, Eq>::~StdGPUHashBackend() {
+    CUDAScopedDevice scoped_device(this->device_);
     Free();
 }
 
 template <typename Key, typename Hash, typename Eq>
 int64_t StdGPUHashBackend<Key, Hash, Eq>::Size() const {
+    CUDAScopedDevice scoped_device(this->device_);
     return impl_.size();
 }
 
@@ -222,6 +225,7 @@ void StdGPUHashBackend<Key, Hash, Eq>::Find(const void* input_keys,
                                             buf_index_t* output_buf_indices,
                                             bool* output_masks,
                                             int64_t count) {
+    CUDAScopedDevice scoped_device(this->device_);
     uint32_t threads = 128;
     uint32_t blocks = (count + threads - 1) / threads;
 
@@ -260,6 +264,7 @@ template <typename Key, typename Hash, typename Eq>
 void StdGPUHashBackend<Key, Hash, Eq>::Erase(const void* input_keys,
                                              bool* output_masks,
                                              int64_t count) {
+    CUDAScopedDevice scoped_device(this->device_);
     uint32_t threads = 128;
     uint32_t blocks = (count + threads - 1) / threads;
 
@@ -285,6 +290,7 @@ struct ValueExtractor {
 template <typename Key, typename Hash, typename Eq>
 int64_t StdGPUHashBackend<Key, Hash, Eq>::GetActiveIndices(
         buf_index_t* output_indices) {
+    CUDAScopedDevice scoped_device(this->device_);
     auto range = impl_.device_range();
 
     thrust::transform(range.begin(), range.end(), output_indices,
@@ -295,25 +301,31 @@ int64_t StdGPUHashBackend<Key, Hash, Eq>::GetActiveIndices(
 
 template <typename Key, typename Hash, typename Eq>
 void StdGPUHashBackend<Key, Hash, Eq>::Clear() {
+    CUDAScopedDevice scoped_device(this->device_);
     impl_.clear();
     this->buffer_->ResetHeap();
 }
 
 template <typename Key, typename Hash, typename Eq>
-void StdGPUHashBackend<Key, Hash, Eq>::Reserve(int64_t capacity) {}
+void StdGPUHashBackend<Key, Hash, Eq>::Reserve(int64_t capacity) {
+    CUDAScopedDevice scoped_device(this->device_);
+}
 
 template <typename Key, typename Hash, typename Eq>
 int64_t StdGPUHashBackend<Key, Hash, Eq>::GetBucketCount() const {
+    CUDAScopedDevice scoped_device(this->device_);
     return impl_.bucket_count();
 }
 
 template <typename Key, typename Hash, typename Eq>
 std::vector<int64_t> StdGPUHashBackend<Key, Hash, Eq>::BucketSizes() const {
+    CUDAScopedDevice scoped_device(this->device_);
     utility::LogError("Unimplemented");
 }
 
 template <typename Key, typename Hash, typename Eq>
 float StdGPUHashBackend<Key, Hash, Eq>::LoadFactor() const {
+    CUDAScopedDevice scoped_device(this->device_);
     return impl_.load_factor();
 }
 
@@ -378,6 +390,7 @@ void StdGPUHashBackend<Key, Hash, Eq>::Insert(
         buf_index_t* output_buf_indices,
         bool* output_masks,
         int64_t count) {
+    CUDAScopedDevice scoped_device(this->device_);
     uint32_t threads = 128;
     uint32_t blocks = (count + threads - 1) / threads;
 
@@ -402,6 +415,7 @@ void StdGPUHashBackend<Key, Hash, Eq>::Insert(
 
 template <typename Key, typename Hash, typename Eq>
 void StdGPUHashBackend<Key, Hash, Eq>::Allocate(int64_t capacity) {
+    CUDAScopedDevice scoped_device(this->device_);
     this->capacity_ = capacity;
 
     // Allocate buffer for key values.
@@ -424,6 +438,7 @@ void StdGPUHashBackend<Key, Hash, Eq>::Allocate(int64_t capacity) {
 
 template <typename Key, typename Hash, typename Eq>
 void StdGPUHashBackend<Key, Hash, Eq>::Free() {
+    CUDAScopedDevice scoped_device(this->device_);
     // Buffer is automatically handled by the smart pointer.
     buffer_accessor_.Shutdown(this->device_);
 
diff --git a/cpp/open3d/core/kernel/ArangeCUDA.cu b/cpp/open3d/core/kernel/ArangeCUDA.cu
index e5e439f27f6..3751574ca1f 100644
--- a/cpp/open3d/core/kernel/ArangeCUDA.cu
+++ b/cpp/open3d/core/kernel/ArangeCUDA.cu
@@ -24,6 +24,7 @@
 // IN THE SOFTWARE.
 // ----------------------------------------------------------------------------
 
+#include "open3d/core/CUDAUtils.h"
 #include "open3d/core/Dispatch.h"
 #include "open3d/core/ParallelFor.h"
 #include "open3d/core/Tensor.h"
@@ -37,6 +38,7 @@ void ArangeCUDA(const Tensor& start,
                 const Tensor& stop,
                 const Tensor& step,
                 Tensor& dst) {
+    CUDAScopedDevice scoped_device(start.GetDevice());
     Dtype dtype = start.GetDtype();
     DISPATCH_DTYPE_TO_TEMPLATE(dtype, [&]() {
         scalar_t sstart = start.Item<scalar_t>();
diff --git a/cpp/open3d/core/kernel/IndexGetSetCUDA.cu b/cpp/open3d/core/kernel/IndexGetSetCUDA.cu
index 547e943ca00..82ce38f1148 100644
--- a/cpp/open3d/core/kernel/IndexGetSetCUDA.cu
+++ b/cpp/open3d/core/kernel/IndexGetSetCUDA.cu
@@ -68,6 +68,7 @@ void IndexGetCUDA(const Tensor& src,
                   const std::vector<Tensor>& index_tensors,
                   const SizeVector& indexed_shape,
                   const SizeVector& indexed_strides) {
+    CUDAScopedDevice scoped_device(src.GetDevice());
     Dtype dtype = src.GetDtype();
     AdvancedIndexer ai(src, dst, index_tensors, indexed_shape, indexed_strides,
                        AdvancedIndexer::AdvancedIndexerMode::GET);
@@ -96,6 +97,7 @@ void IndexSetCUDA(const Tensor& src,
                   const std::vector<Tensor>& index_tensors,
                   const SizeVector& indexed_shape,
                   const SizeVector& indexed_strides) {
+    CUDAScopedDevice scoped_device(src.GetDevice());
     Dtype dtype = src.GetDtype();
     AdvancedIndexer ai(src, dst, index_tensors, indexed_shape, indexed_strides,
                        AdvancedIndexer::AdvancedIndexerMode::SET);
diff --git a/cpp/open3d/core/kernel/NonZeroCUDA.cu b/cpp/open3d/core/kernel/NonZeroCUDA.cu
index c0ba68a0134..fe128cfcdb6 100644
--- a/cpp/open3d/core/kernel/NonZeroCUDA.cu
+++ b/cpp/open3d/core/kernel/NonZeroCUDA.cu
@@ -29,6 +29,7 @@
 #include <thrust/for_each.h>
 #include <thrust/iterator/zip_iterator.h>
 
+#include "open3d/core/CUDAUtils.h"
 #include "open3d/core/Indexer.h"
 #include "open3d/core/kernel/NonZero.h"
 
@@ -75,6 +76,7 @@ protected:
 };
 
 Tensor NonZeroCUDA(const Tensor& src) {
+    CUDAScopedDevice scoped_device(src.GetDevice());
     Tensor src_contiguous = src.Contiguous();
     const int64_t num_elements = src_contiguous.NumElements();
     const int64_t num_bytes =
diff --git a/cpp/open3d/core/linalg/AddMM.cpp b/cpp/open3d/core/linalg/AddMM.cpp
index 7149b576d96..c00aa280d71 100644
--- a/cpp/open3d/core/linalg/AddMM.cpp
+++ b/cpp/open3d/core/linalg/AddMM.cpp
@@ -28,6 +28,8 @@
 
 #include <unordered_map>
 
+#include "open3d/core/CUDAUtils.h"
+
 namespace open3d {
 namespace core {
 
@@ -110,8 +112,9 @@ void AddMM(const Tensor& A,
 
     if (device.IsCUDA()) {
 #ifdef BUILD_CUDA_MODULE
+        CUDAScopedDevice scoped_device(device);
         AddMMCUDA(B_data, A_data, C_data, n, k, m, alpha, beta, transB, transA,
-                  ldb, lda, ldc, dtype);
+                  ldb, lda, ldc, dtype, device);
 #else
         utility::LogError("Unimplemented device.");
 #endif
diff --git a/cpp/open3d/core/linalg/AddMM.h b/cpp/open3d/core/linalg/AddMM.h
index b9ad8486ee3..ca4d4b0e48c 100644
--- a/cpp/open3d/core/linalg/AddMM.h
+++ b/cpp/open3d/core/linalg/AddMM.h
@@ -53,7 +53,8 @@ void AddMMCUDA(void* A_data,
                int lda,
                int ldb,
                int ldc,
-               Dtype dtype);
+               Dtype dtype,
+               const Device& device);
 #endif
 
 void AddMMCPU(void* A_data,
diff --git a/cpp/open3d/core/linalg/AddMMCUDA.cpp b/cpp/open3d/core/linalg/AddMMCUDA.cpp
index 8cb4b425b28..538b9d5d36f 100644
--- a/cpp/open3d/core/linalg/AddMMCUDA.cpp
+++ b/cpp/open3d/core/linalg/AddMMCUDA.cpp
@@ -45,8 +45,9 @@ void AddMMCUDA(void* A_data,
                int lda,
                int ldb,
                int ldc,
-               Dtype dtype) {
-    cublasHandle_t handle = CuBLASContext::GetInstance()->GetHandle();
+               Dtype dtype,
+               const Device& device) {
+    cublasHandle_t handle = CuBLASContext::GetInstance().GetHandle(device);
     DISPATCH_LINALG_DTYPE_TO_TEMPLATE(dtype, [&]() {
         scalar_t alpha_ = scalar_t(alpha);
         scalar_t beta_ = scalar_t(beta);
diff --git a/cpp/open3d/core/linalg/Inverse.cpp b/cpp/open3d/core/linalg/Inverse.cpp
index 2cea1c707d2..54c7dcd58a8 100644
--- a/cpp/open3d/core/linalg/Inverse.cpp
+++ b/cpp/open3d/core/linalg/Inverse.cpp
@@ -28,6 +28,7 @@
 
 #include <unordered_map>
 
+#include "open3d/core/CUDAUtils.h"
 #include "open3d/core/linalg/LinalgHeadersCPU.h"
 
 namespace open3d {
@@ -57,6 +58,7 @@ void Inverse(const Tensor &A, Tensor &output) {
 
     if (device.IsCUDA()) {
 #ifdef BUILD_CUDA_MODULE
+        CUDAScopedDevice scoped_device(device);
         Tensor ipiv = Tensor::Zeros({n}, core::Int32, device);
         void *ipiv_data = ipiv.GetDataPtr();
 
diff --git a/cpp/open3d/core/linalg/InverseCUDA.cpp b/cpp/open3d/core/linalg/InverseCUDA.cpp
index 08b4afd78e6..6ed32c7065c 100644
--- a/cpp/open3d/core/linalg/InverseCUDA.cpp
+++ b/cpp/open3d/core/linalg/InverseCUDA.cpp
@@ -38,7 +38,8 @@ void InverseCUDA(void* A_data,
                  int64_t n,
                  Dtype dtype,
                  const Device& device) {
-    cusolverDnHandle_t handle = CuSolverContext::GetInstance()->GetHandle();
+    cusolverDnHandle_t handle =
+            CuSolverContext::GetInstance().GetHandle(device);
 
     DISPATCH_LINALG_DTYPE_TO_TEMPLATE(dtype, [&]() {
         int len;
diff --git a/cpp/open3d/core/linalg/LU.cpp b/cpp/open3d/core/linalg/LU.cpp
index 89540f6d5c0..df3e9a12c44 100644
--- a/cpp/open3d/core/linalg/LU.cpp
+++ b/cpp/open3d/core/linalg/LU.cpp
@@ -26,6 +26,7 @@
 
 #include "open3d/core/linalg/LU.h"
 
+#include "open3d/core/CUDAUtils.h"
 #include "open3d/core/linalg/LUImpl.h"
 #include "open3d/core/linalg/LinalgHeadersCPU.h"
 #include "open3d/core/linalg/Tri.h"
@@ -108,6 +109,7 @@ void LUIpiv(const Tensor& A, Tensor& ipiv, Tensor& output) {
     // matrix was interchanged with row IPIV(i).
     if (device.IsCUDA()) {
 #ifdef BUILD_CUDA_MODULE
+        CUDAScopedDevice scoped_device(device);
         int64_t ipiv_len = std::min(rows, cols);
         ipiv = core::Tensor::Empty({ipiv_len}, core::Int32, device);
         void* ipiv_data = ipiv.GetDataPtr();
diff --git a/cpp/open3d/core/linalg/LUCUDA.cpp b/cpp/open3d/core/linalg/LUCUDA.cpp
index 8852e9f1d54..09067ccdfcb 100644
--- a/cpp/open3d/core/linalg/LUCUDA.cpp
+++ b/cpp/open3d/core/linalg/LUCUDA.cpp
@@ -37,7 +37,8 @@ void LUCUDA(void* A_data,
             int64_t cols,
             Dtype dtype,
             const Device& device) {
-    cusolverDnHandle_t handle = CuSolverContext::GetInstance()->GetHandle();
+    cusolverDnHandle_t handle =
+            CuSolverContext::GetInstance().GetHandle(device);
     DISPATCH_LINALG_DTYPE_TO_TEMPLATE(dtype, [&]() {
         int len;
         OPEN3D_CUSOLVER_CHECK(
diff --git a/cpp/open3d/core/linalg/LeastSquares.cpp b/cpp/open3d/core/linalg/LeastSquares.cpp
index d6a67a13718..03815a75bde 100644
--- a/cpp/open3d/core/linalg/LeastSquares.cpp
+++ b/cpp/open3d/core/linalg/LeastSquares.cpp
@@ -28,6 +28,8 @@
 
 #include <unordered_map>
 
+#include "open3d/core/CUDAUtils.h"
+
 namespace open3d {
 namespace core {
 
@@ -76,6 +78,7 @@ void LeastSquares(const Tensor &A, const Tensor &B, Tensor &X) {
 
     if (device.IsCUDA()) {
 #ifdef BUILD_CUDA_MODULE
+        CUDAScopedDevice scoped_device(device);
         LeastSquaresCUDA(A_data, B_data, m, n, k, dtype, device);
 #else
         utility::LogError("Unimplemented device.");
diff --git a/cpp/open3d/core/linalg/LeastSquaresCUDA.cpp b/cpp/open3d/core/linalg/LeastSquaresCUDA.cpp
index 07b90380d24..d20a4379238 100644
--- a/cpp/open3d/core/linalg/LeastSquaresCUDA.cpp
+++ b/cpp/open3d/core/linalg/LeastSquaresCUDA.cpp
@@ -48,8 +48,9 @@ void LeastSquaresCUDA(void* A_data,
                       Dtype dtype,
                       const Device& device) {
     cusolverDnHandle_t cusolver_handle =
-            CuSolverContext::GetInstance()->GetHandle();
-    cublasHandle_t cublas_handle = CuBLASContext::GetInstance()->GetHandle();
+            CuSolverContext::GetInstance().GetHandle(device);
+    cublasHandle_t cublas_handle =
+            CuBLASContext::GetInstance().GetHandle(device);
 
     DISPATCH_LINALG_DTYPE_TO_TEMPLATE(dtype, [&]() {
         int len_geqrf, len_ormqr, len;
diff --git a/cpp/open3d/core/linalg/LinalgUtils.cpp b/cpp/open3d/core/linalg/LinalgUtils.cpp
index 57d641d90ca..607a34181bf 100644
--- a/cpp/open3d/core/linalg/LinalgUtils.cpp
+++ b/cpp/open3d/core/linalg/LinalgUtils.cpp
@@ -26,44 +26,87 @@
 
 #include "open3d/core/linalg/LinalgUtils.h"
 
+#include "open3d/core/CUDAUtils.h"
+
 namespace open3d {
 namespace core {
 
-std::shared_ptr<CuSolverContext> CuSolverContext::GetInstance() {
-    if (instance_ == nullptr) {
-        instance_ = std::make_shared<CuSolverContext>();
-    }
-    return instance_;
-};
+CuSolverContext& CuSolverContext::GetInstance() {
+    static CuSolverContext instance;
+    return instance;
+}
 
 CuSolverContext::CuSolverContext() {
-    if (cusolverDnCreate(&handle_) != CUSOLVER_STATUS_SUCCESS) {
-        utility::LogError("Unable to create cuSolver handle");
+    for (const Device& device : Device::GetAvailableCUDADevices()) {
+        CUDAScopedDevice scoped_device(device);
+        cusolverDnHandle_t handle;
+        if (cusolverDnCreate(&handle) != CUSOLVER_STATUS_SUCCESS) {
+            utility::LogError("Unable to create cuSolver handle for {}.",
+                              device.ToString());
+        }
+        map_device_to_handle_[device] = handle;
     }
 }
+
 CuSolverContext::~CuSolverContext() {
-    if (cusolverDnDestroy(handle_) != CUSOLVER_STATUS_SUCCESS) {
-        utility::LogError("Unable to destroy cuSolver handle");
+    // Destroy map_device_to_handle_
+    for (auto& item : map_device_to_handle_) {
+        if (cusolverDnDestroy(item.second) != CUSOLVER_STATUS_SUCCESS) {
+            utility::LogError(
+                    "Unable to destroy cuSolver handle for device {}.",
+                    item.first.ToString());
+        }
     }
 }
 
-std::shared_ptr<CuSolverContext> CuSolverContext::instance_ = nullptr;
-
-std::shared_ptr<CuBLASContext> CuBLASContext::GetInstance() {
-    if (instance_ == nullptr) {
-        instance_ = std::make_shared<CuBLASContext>();
+cusolverDnHandle_t& CuSolverContext::GetHandle(const Device& device) {
+    if (device.GetType() != Device::DeviceType::CUDA) {
+        utility::LogError("cuSolver is only available on CUDA devices");
+    }
+    if (map_device_to_handle_.count(device) == 0) {
+        utility::LogError("cuSolver handle not found for device: {}",
+                          device.ToString());
     }
-    return instance_;
-};
+    return map_device_to_handle_.at(device);
+}
+
+CuBLASContext& CuBLASContext::GetInstance() {
+    static CuBLASContext instance;
+    return instance;
+}
 
 CuBLASContext::CuBLASContext() {
-    if (cublasCreate(&handle_) != CUBLAS_STATUS_SUCCESS) {
-        utility::LogError("Unable to create cublas handle");
+    for (const Device& device : Device::GetAvailableCUDADevices()) {
+        CUDAScopedDevice scoped_device(device);
+        cublasHandle_t handle;
+        if (cublasCreate(&handle) != CUBLAS_STATUS_SUCCESS) {
+            utility::LogError("Unable to create cublas handle for {}.",
+                              device.ToString());
+        }
+        map_device_to_handle_[device] = handle;
+    }
+}
+
+CuBLASContext::~CuBLASContext() {
+    // Destroy map_device_to_handle_
+    for (auto& item : map_device_to_handle_) {
+        if (cublasDestroy(item.second) != CUBLAS_STATUS_SUCCESS) {
+            utility::LogError("Unable to destroy cublas handle for device {}.",
+                              item.first.ToString());
+        }
     }
 }
-CuBLASContext::~CuBLASContext() { cublasDestroy(handle_); }
 
-std::shared_ptr<CuBLASContext> CuBLASContext::instance_ = nullptr;
+cublasHandle_t& CuBLASContext::GetHandle(const Device& device) {
+    if (device.GetType() != Device::DeviceType::CUDA) {
+        utility::LogError("cuBLAS is only available on CUDA devices");
+    }
+    if (map_device_to_handle_.count(device) == 0) {
+        utility::LogError("cuBLAS handle not found for device: {}",
+                          device.ToString());
+    }
+    return map_device_to_handle_.at(device);
+}
 
 }  // namespace core
 }  // namespace open3d
diff --git a/cpp/open3d/core/linalg/LinalgUtils.h b/cpp/open3d/core/linalg/LinalgUtils.h
index b958823485b..835469afe35 100644
--- a/cpp/open3d/core/linalg/LinalgUtils.h
+++ b/cpp/open3d/core/linalg/LinalgUtils.h
@@ -26,9 +26,9 @@
 
 #pragma once
 
-#include <memory>
 #include <string>
 
+#include "open3d/core/Device.h"
 #include "open3d/core/Dtype.h"
 #include "open3d/core/MemoryManager.h"
 #include "open3d/core/linalg/LinalgHeadersCPU.h"
@@ -93,31 +93,32 @@ inline void OPEN3D_CUSOLVER_CHECK_WITH_DINFO(cusolverStatus_t status,
 
 class CuSolverContext {
 public:
-    static std::shared_ptr<CuSolverContext> GetInstance();
-    CuSolverContext();
+    static CuSolverContext& GetInstance();
+
+    CuSolverContext(const CuSolverContext&) = delete;
+    CuSolverContext& operator=(const CuSolverContext&) = delete;
     ~CuSolverContext();
 
-    cusolverDnHandle_t& GetHandle() { return handle_; }
+    cusolverDnHandle_t& GetHandle(const Device& device);
 
 private:
-    cusolverDnHandle_t handle_;
-
-    static std::shared_ptr<CuSolverContext> instance_;
+    CuSolverContext();
+    std::unordered_map<Device, cusolverDnHandle_t> map_device_to_handle_;
 };
 
 class CuBLASContext {
 public:
-    static std::shared_ptr<CuBLASContext> GetInstance();
+    static CuBLASContext& GetInstance();
 
-    CuBLASContext();
+    CuBLASContext(const CuBLASContext&) = delete;
+    CuBLASContext& operator=(const CuBLASContext&) = delete;
     ~CuBLASContext();
 
-    cublasHandle_t& GetHandle() { return handle_; }
+    cublasHandle_t& GetHandle(const Device& device);
 
 private:
-    cublasHandle_t handle_;
-
-    static std::shared_ptr<CuBLASContext> instance_;
+    CuBLASContext();
+    std::unordered_map<Device, cublasHandle_t> map_device_to_handle_;
 };
 #endif
 }  // namespace core
diff --git a/cpp/open3d/core/linalg/Matmul.cpp b/cpp/open3d/core/linalg/Matmul.cpp
index 148178ac962..ca39458b1ac 100644
--- a/cpp/open3d/core/linalg/Matmul.cpp
+++ b/cpp/open3d/core/linalg/Matmul.cpp
@@ -28,6 +28,8 @@
 
 #include <unordered_map>
 
+#include "open3d/core/CUDAUtils.h"
+
 namespace open3d {
 namespace core {
 
@@ -84,7 +86,8 @@ void Matmul(const Tensor& A, const Tensor& B, Tensor& output) {
 
     if (device.IsCUDA()) {
 #ifdef BUILD_CUDA_MODULE
-        MatmulCUDA(B_data, A_data, C_data, n, k, m, dtype);
+        CUDAScopedDevice scoped_device(device);
+        MatmulCUDA(B_data, A_data, C_data, n, k, m, dtype, device);
 #else
         utility::LogError("Unimplemented device.");
 #endif
diff --git a/cpp/open3d/core/linalg/Matmul.h b/cpp/open3d/core/linalg/Matmul.h
index 6151f78deaa..362b72fdc36 100644
--- a/cpp/open3d/core/linalg/Matmul.h
+++ b/cpp/open3d/core/linalg/Matmul.h
@@ -41,7 +41,8 @@ void MatmulCUDA(void* A_data,
                 int64_t m,
                 int64_t k,
                 int64_t n,
-                Dtype dtype);
+                Dtype dtype,
+                const Device& device);
 #endif
 void MatmulCPU(void* A_data,
                void* B_data,
diff --git a/cpp/open3d/core/linalg/MatmulCUDA.cpp b/cpp/open3d/core/linalg/MatmulCUDA.cpp
index cf94c77e0b8..c93926d6626 100644
--- a/cpp/open3d/core/linalg/MatmulCUDA.cpp
+++ b/cpp/open3d/core/linalg/MatmulCUDA.cpp
@@ -38,8 +38,9 @@ void MatmulCUDA(void* A_data,
                 int64_t m,
                 int64_t k,
                 int64_t n,
-                Dtype dtype) {
-    cublasHandle_t handle = CuBLASContext::GetInstance()->GetHandle();
+                Dtype dtype,
+                const Device& device) {
+    cublasHandle_t handle = CuBLASContext::GetInstance().GetHandle(device);
     DISPATCH_LINALG_DTYPE_TO_TEMPLATE(dtype, [&]() {
         scalar_t alpha = 1, beta = 0;
         OPEN3D_CUBLAS_CHECK(
diff --git a/cpp/open3d/core/linalg/SVD.cpp b/cpp/open3d/core/linalg/SVD.cpp
index 5ce84fba792..88700c937e9 100644
--- a/cpp/open3d/core/linalg/SVD.cpp
+++ b/cpp/open3d/core/linalg/SVD.cpp
@@ -28,6 +28,8 @@
 
 #include <unordered_map>
 
+#include "open3d/core/CUDAUtils.h"
+
 namespace open3d {
 namespace core {
 
@@ -67,6 +69,7 @@ void SVD(const Tensor &A, Tensor &U, Tensor &S, Tensor &VT) {
 
     if (device.IsCUDA()) {
 #ifdef BUILD_CUDA_MODULE
+        CUDAScopedDevice scoped_device(device);
         SVDCUDA(A_data, U_data, S_data, VT_data, superb_data, m, n, dtype,
                 device);
 #else
diff --git a/cpp/open3d/core/linalg/SVDCUDA.cpp b/cpp/open3d/core/linalg/SVDCUDA.cpp
index ab9a2febac6..214bfd573ac 100644
--- a/cpp/open3d/core/linalg/SVDCUDA.cpp
+++ b/cpp/open3d/core/linalg/SVDCUDA.cpp
@@ -41,7 +41,8 @@ void SVDCUDA(const void* A_data,
              int64_t n,
              Dtype dtype,
              const Device& device) {
-    cusolverDnHandle_t handle = CuSolverContext::GetInstance()->GetHandle();
+    cusolverDnHandle_t handle =
+            CuSolverContext::GetInstance().GetHandle(device);
 
     DISPATCH_LINALG_DTYPE_TO_TEMPLATE(dtype, [&]() {
         int len;
diff --git a/cpp/open3d/core/linalg/Solve.cpp b/cpp/open3d/core/linalg/Solve.cpp
index d4cd8aa49d9..a625990dc5d 100644
--- a/cpp/open3d/core/linalg/Solve.cpp
+++ b/cpp/open3d/core/linalg/Solve.cpp
@@ -32,6 +32,7 @@
 
 #include <unordered_map>
 
+#include "open3d/core/CUDAUtils.h"
 #include "open3d/core/linalg/LinalgHeadersCPU.h"
 
 namespace open3d {
@@ -80,6 +81,7 @@ void Solve(const Tensor &A, const Tensor &B, Tensor &X) {
 
     if (device.IsCUDA()) {
 #ifdef BUILD_CUDA_MODULE
+        CUDAScopedDevice scoped_device(device);
         Tensor ipiv = Tensor::Empty({n}, core::Int32, device);
         void *ipiv_data = ipiv.GetDataPtr();
 
diff --git a/cpp/open3d/core/linalg/SolveCUDA.cpp b/cpp/open3d/core/linalg/SolveCUDA.cpp
index 9146f730e93..594553d34a1 100644
--- a/cpp/open3d/core/linalg/SolveCUDA.cpp
+++ b/cpp/open3d/core/linalg/SolveCUDA.cpp
@@ -43,7 +43,8 @@ void SolveCUDA(void* A_data,
                int64_t k,
                Dtype dtype,
                const Device& device) {
-    cusolverDnHandle_t handle = CuSolverContext::GetInstance()->GetHandle();
+    cusolverDnHandle_t handle =
+            CuSolverContext::GetInstance().GetHandle(device);
 
     DISPATCH_LINALG_DTYPE_TO_TEMPLATE(dtype, [&]() {
         int len;
diff --git a/cpp/open3d/core/linalg/Tri.cpp b/cpp/open3d/core/linalg/Tri.cpp
index 5576e214845..60e664eb3e7 100644
--- a/cpp/open3d/core/linalg/Tri.cpp
+++ b/cpp/open3d/core/linalg/Tri.cpp
@@ -26,6 +26,7 @@
 
 #include "open3d/core/linalg/Tri.h"
 
+#include "open3d/core/CUDAUtils.h"
 #include "open3d/core/Tensor.h"
 #include "open3d/core/linalg/TriImpl.h"
 
@@ -56,6 +57,7 @@ void Triu(const Tensor& A, Tensor& output, const int diagonal) {
     output = core::Tensor::Zeros(A.GetShape(), A.GetDtype(), device);
     if (device.IsCUDA()) {
 #ifdef BUILD_CUDA_MODULE
+        CUDAScopedDevice scoped_device(device);
         TriuCUDA(A.Contiguous(), output, diagonal);
 #else
         utility::LogError("Unimplemented device.");
@@ -71,6 +73,7 @@ void Tril(const Tensor& A, Tensor& output, const int diagonal) {
     output = core::Tensor::Zeros(A.GetShape(), A.GetDtype(), device);
     if (device.IsCUDA()) {
 #ifdef BUILD_CUDA_MODULE
+        CUDAScopedDevice scoped_device(device);
         TrilCUDA(A.Contiguous(), output, diagonal);
 #else
         utility::LogError("Unimplemented device.");
@@ -87,6 +90,7 @@ void Triul(const Tensor& A, Tensor& upper, Tensor& lower, const int diagonal) {
     lower = core::Tensor::Zeros(A.GetShape(), A.GetDtype(), device);
     if (device.IsCUDA()) {
 #ifdef BUILD_CUDA_MODULE
+        CUDAScopedDevice scoped_device(device);
         TriulCUDA(A.Contiguous(), upper, lower, diagonal);
 #else
         utility::LogError("Unimplemented device.");
diff --git a/cpp/open3d/core/nns/FixedRadiusSearchOps.cu b/cpp/open3d/core/nns/FixedRadiusSearchOps.cu
index ee066c8e60e..18344b4e000 100644
--- a/cpp/open3d/core/nns/FixedRadiusSearchOps.cu
+++ b/cpp/open3d/core/nns/FixedRadiusSearchOps.cu
@@ -25,6 +25,7 @@
 // ----------------------------------------------------------------------------
 //
 
+#include "open3d/core/CUDAUtils.h"
 #include "open3d/core/Tensor.h"
 #include "open3d/core/nns/FixedRadiusIndex.h"
 #include "open3d/core/nns/FixedRadiusSearchImpl.cuh"
@@ -42,6 +43,7 @@ void BuildSpatialHashTableCUDA(const Tensor& points,
                                const Tensor& hash_table_splits,
                                Tensor& hash_table_index,
                                Tensor& hash_table_cell_splits) {
+    CUDAScopedDevice scoped_device(points.GetDevice());
     const cudaStream_t stream = 0;
     int texture_alignment = 512;
 
@@ -90,6 +92,7 @@ void FixedRadiusSearchCUDA(const Tensor& points,
                            Tensor& neighbors_index,
                            Tensor& neighbors_row_splits,
                            Tensor& neighbors_distance) {
+    CUDAScopedDevice scoped_device(points.GetDevice());
     const cudaStream_t stream = 0;
     int texture_alignment = 512;
 
@@ -189,6 +192,7 @@ void HybridSearchCUDA(const Tensor& points,
                       Tensor& neighbors_index,
                       Tensor& neighbors_count,
                       Tensor& neighbors_distance) {
+    CUDAScopedDevice scoped_device(points.GetDevice());
     const cudaStream_t stream = 0;
 
     Device device = points.GetDevice();
diff --git a/cpp/open3d/core/nns/KnnSearchOps.cu b/cpp/open3d/core/nns/KnnSearchOps.cu
index e1b107af4f6..e98181f2fdb 100644
--- a/cpp/open3d/core/nns/KnnSearchOps.cu
+++ b/cpp/open3d/core/nns/KnnSearchOps.cu
@@ -52,6 +52,7 @@ void KnnSearchCUDABruteForce(const Tensor& points,
                              int knn,
                              OUTPUT_ALLOCATOR& output_allocator,
                              Tensor& query_neighbors_row_splits) {
+    CUDAScopedDevice scoped_device(points.GetDevice());
     const cudaStream_t stream = cuda::GetStream();
     int num_points = points.GetShape(0);
     int num_queries = queries.GetShape(0);
@@ -117,6 +118,7 @@ void KnnSearchCUDAOptimized(const Tensor& points,
                             int knn,
                             OUTPUT_ALLOCATOR& output_allocator,
                             Tensor& query_neighbors_row_splits) {
+    CUDAScopedDevice scoped_device(points.GetDevice());
     int num_points = points.GetShape(0);
     int num_queries = queries.GetShape(0);
     int dim = points.GetShape(1);
@@ -241,6 +243,7 @@ void KnnSearchCUDA(const Tensor& points,
                    Tensor& neighbors_index,
                    Tensor& neighbors_row_splits,
                    Tensor& neighbors_distance) {
+    CUDAScopedDevice scoped_device(points.GetDevice());
     int num_points = points.GetShape(0);
     int num_queries = queries.GetShape(0);
     Device device = points.GetDevice();
diff --git a/cpp/open3d/geometry/PointCloud.h b/cpp/open3d/geometry/PointCloud.h
index 09bbbd6bf76..ad14f54be8d 100644
--- a/cpp/open3d/geometry/PointCloud.h
+++ b/cpp/open3d/geometry/PointCloud.h
@@ -417,13 +417,13 @@ class PointCloud : public Geometry3D {
             const Eigen::Matrix4d &extrinsic = Eigen::Matrix4d::Identity(),
             bool project_valid_depth_only = true);
 
-    /// \brief Function to create a PointCloud from a VoxelGrid.
+    /// \brief Factory Function to create a PointCloud from a VoxelGrid.
     ///
     /// It transforms the voxel centers to 3D points using the original point
     /// cloud coordinate (with respect to the center of the voxel grid).
     ///
     /// \param voxel_grid The input VoxelGrid.
-    std::shared_ptr<PointCloud> CreateFromVoxelGrid(
+    static std::shared_ptr<PointCloud> CreateFromVoxelGrid(
             const VoxelGrid &voxel_grid);
 
 public:
diff --git a/cpp/open3d/geometry/TriangleMesh.cpp b/cpp/open3d/geometry/TriangleMesh.cpp
index d490178d006..46a575c3df8 100644
--- a/cpp/open3d/geometry/TriangleMesh.cpp
+++ b/cpp/open3d/geometry/TriangleMesh.cpp
@@ -575,7 +575,7 @@ std::shared_ptr<PointCloud> TriangleMesh::SamplePointsPoissonDisk(
 
     // Set-up sample elimination
     double alpha = 8;    // constant defined in paper
-    double beta = 0.5;   // constant defined in paper
+    double beta = 0.65;  // constant defined in paper
     double gamma = 1.5;  // constant defined in paper
     double ratio = double(number_of_points) / double(pcl->points_.size());
     double r_max = 2 * std::sqrt((surface_area / number_of_points) /
diff --git a/cpp/open3d/io/IJsonConvertibleIO.h b/cpp/open3d/io/IJsonConvertibleIO.h
index 3b2ce618411..bb6af99893b 100644
--- a/cpp/open3d/io/IJsonConvertibleIO.h
+++ b/cpp/open3d/io/IJsonConvertibleIO.h
@@ -76,9 +76,10 @@ bool WriteIJsonConvertibleToJSONString(std::string &json_string,
 /// - enum_from_string(const std::string &str, ENUM_TYPE &e) -> void
 /// for conversion between the enum and string. Invalid string values are mapped
 /// to the first specified option in the macro.
-#define DECLARE_STRINGIFY_ENUM(ENUM_TYPE)    \
-    std::string enum_to_string(ENUM_TYPE e); \
-    void enum_from_string(const std::string &str, ENUM_TYPE &e);
+#define DECLARE_STRINGIFY_ENUM(ENUM_TYPE)                        \
+    std::string enum_to_string(ENUM_TYPE e);                     \
+    void enum_from_string(const std::string &str, ENUM_TYPE &e); \
+    inline auto format_as(ENUM_TYPE e) { return enum_to_string(e); }
 
 #define STRINGIFY_ENUM(ENUM_TYPE, ...)                                    \
     std::string enum_to_string(ENUM_TYPE e) {                             \
diff --git a/cpp/open3d/io/TriangleMeshIO.h b/cpp/open3d/io/TriangleMeshIO.h
index 08eaa2ea419..e380df298b6 100644
--- a/cpp/open3d/io/TriangleMeshIO.h
+++ b/cpp/open3d/io/TriangleMeshIO.h
@@ -39,7 +39,23 @@ std::shared_ptr<geometry::TriangleMesh> CreateMeshFromFile(
         const std::string &filename, bool print_progress = false);
 
 struct ReadTriangleMeshOptions {
-    /// Enables post-processing on the mesh
+    /// Enables post-processing on the mesh.
+    /// Post-processing will
+    ///   - triangulate meshes with polygonal faces
+    ///   - remove redundant materials
+    ///   - pretransform vertices
+    ///   - generate face normals if needed
+    ///
+    /// For more information see ASSIMPs documentation on the flags
+    /// `aiProcessPreset_TargetRealtime_Fast,
+    /// aiProcess_RemoveRedundantMaterials, aiProcess_OptimizeMeshes,
+    /// aiProcess_PreTransformVertices`.
+    ///
+    /// Note that identical vertices will always be joined regardless of whether
+    /// post-processing is enabled or not, which changes the number of vertices
+    /// in the mesh.
+    ///
+    /// The ply-format is not affected by the post-processing.
     bool enable_post_processing = false;
     /// Print progress to stdout about loading progress.
     /// Also see \p update_progress if you want to have your own progress
diff --git a/cpp/open3d/pipelines/odometry/Odometry.cpp b/cpp/open3d/pipelines/odometry/Odometry.cpp
index 843f0fa3c44..b9496f17a7f 100644
--- a/cpp/open3d/pipelines/odometry/Odometry.cpp
+++ b/cpp/open3d/pipelines/odometry/Odometry.cpp
@@ -116,8 +116,8 @@ static int CountCorrespondence(const geometry::Image &correspondence_map) {
     return correspondence_count;
 }
 
-static CorrespondenceSetPixelWise ComputeCorrespondence(
-        const Eigen::Matrix3d intrinsic_matrix,
+CorrespondenceSetPixelWise ComputeCorrespondence(
+        const Eigen::Matrix3d &intrinsic_matrix,
         const Eigen::Matrix4d &extrinsic,
         const geometry::Image &depth_s,
         const geometry::Image &depth_t,
diff --git a/cpp/open3d/pipelines/odometry/Odometry.h b/cpp/open3d/pipelines/odometry/Odometry.h
index ad3b65dcaaf..0a2281e6f8e 100644
--- a/cpp/open3d/pipelines/odometry/Odometry.h
+++ b/cpp/open3d/pipelines/odometry/Odometry.h
@@ -65,6 +65,23 @@ std::tuple<bool, Eigen::Matrix4d, Eigen::Matrix6d> ComputeRGBDOdometry(
                 RGBDOdometryJacobianFromHybridTerm(),
         const OdometryOption &option = OdometryOption());
 
+/// \brief Function to estimate point to point correspondences from two depth
+/// images.
+///
+/// \param intrinsic_matrix Camera intrinsic parameters.
+/// \param extrinsic Estimation of transform from source to target.
+/// \param depth_s Source depth image.
+/// \param depth_t Target depth image.
+/// \param option Odometry hyper parameters.
+/// \return A vector of u_s, v_s, u_t, v_t which maps the 2d coordinates of
+/// source to target.
+CorrespondenceSetPixelWise ComputeCorrespondence(
+        const Eigen::Matrix3d &intrinsic_matrix,
+        const Eigen::Matrix4d &extrinsic,
+        const geometry::Image &depth_s,
+        const geometry::Image &depth_t,
+        const OdometryOption &option);
+
 }  // namespace odometry
 }  // namespace pipelines
 }  // namespace open3d
diff --git a/cpp/open3d/t/geometry/BoundingVolume.cpp b/cpp/open3d/t/geometry/BoundingVolume.cpp
index 36f48747ffc..1270ffbec51 100644
--- a/cpp/open3d/t/geometry/BoundingVolume.cpp
+++ b/cpp/open3d/t/geometry/BoundingVolume.cpp
@@ -47,6 +47,7 @@ AxisAlignedBoundingBox::AxisAlignedBoundingBox(const core::Tensor &min_bound,
     : AxisAlignedBoundingBox([&]() {
           core::AssertTensorDevice(max_bound, min_bound.GetDevice());
           core::AssertTensorDtype(max_bound, min_bound.GetDtype());
+          core::AssertTensorDtypes(max_bound, {core::Float32, core::Float64});
           core::AssertTensorShape(min_bound, {3});
           core::AssertTensorShape(max_bound, {3});
           return min_bound.GetDevice();
@@ -86,10 +87,12 @@ AxisAlignedBoundingBox &AxisAlignedBoundingBox::Clear() {
 }
 
 void AxisAlignedBoundingBox::SetMinBound(const core::Tensor &min_bound) {
-    core::AssertTensorDevice(min_bound, device_);
+    core::AssertTensorDevice(min_bound, GetDevice());
     core::AssertTensorShape(min_bound, {3});
+    core::AssertTensorDtypes(min_bound, {core::Float32, core::Float64});
+
     const core::Tensor tmp = min_bound_.Clone();
-    min_bound_ = min_bound.To(min_bound_.GetDtype());
+    min_bound_ = min_bound.To(GetDtype());
 
     // If the volume is invalid, the min_bound_ will be set to the
     // original value.
@@ -102,12 +105,12 @@ void AxisAlignedBoundingBox::SetMinBound(const core::Tensor &min_bound) {
 }
 
 void AxisAlignedBoundingBox::SetMaxBound(const core::Tensor &max_bound) {
-    core::AssertTensorDevice(max_bound, device_);
+    core::AssertTensorDevice(max_bound, GetDevice());
     core::AssertTensorShape(max_bound, {3});
-    core::AssertTensorDtype(max_bound, GetDtype());
+    core::AssertTensorDtypes(max_bound, {core::Float32, core::Float64});
 
     const core::Tensor tmp = max_bound_.Clone();
-    max_bound_ = max_bound;
+    max_bound_ = max_bound.To(GetDtype());
 
     // If the volume is invalid, the max_bound_ will be set to the
     // original value.
@@ -122,7 +125,7 @@ void AxisAlignedBoundingBox::SetMaxBound(const core::Tensor &max_bound) {
 void AxisAlignedBoundingBox::SetColor(const core::Tensor &color) {
     core::AssertTensorDevice(color, GetDevice());
     core::AssertTensorShape(color, {3});
-    core::AssertTensorDtype(color, GetDtype());
+
     if (color.Max({0}).To(core::Float64).Item<double>() > 1.0 ||
         color.Min({0}).To(core::Float64).Item<double>() < 0.0) {
         utility::LogError(
@@ -132,34 +135,41 @@ void AxisAlignedBoundingBox::SetColor(const core::Tensor &color) {
                 color.Max({0}).To(core::Float64).Item<double>());
     }
 
-    color_ = color;
+    color_ = color.To(GetDtype());
 }
 
 AxisAlignedBoundingBox &AxisAlignedBoundingBox::Translate(
         const core::Tensor &translation, bool relative) {
     core::AssertTensorDevice(translation, GetDevice());
     core::AssertTensorShape(translation, {3});
-    core::AssertTensorDtype(translation, GetDtype());
+    core::AssertTensorDtypes(translation, {core::Float32, core::Float64});
 
+    const core::Tensor translation_d = translation.To(GetDtype());
     if (relative) {
-        min_bound_ += translation;
-        max_bound_ += translation;
+        min_bound_ += translation_d;
+        max_bound_ += translation_d;
     } else {
         const core::Tensor half_extent = GetHalfExtent();
-        min_bound_ = translation - half_extent;
-        max_bound_ = translation + half_extent;
+        min_bound_ = translation_d - half_extent;
+        max_bound_ = translation_d + half_extent;
     }
     return *this;
 }
 
 AxisAlignedBoundingBox &AxisAlignedBoundingBox::Scale(
-        double scale, const core::Tensor &center) {
-    core::AssertTensorDevice(center, GetDevice());
-    core::AssertTensorShape(center, {3});
-    core::AssertTensorDtype(center, min_bound_.GetDtype());
-
-    min_bound_ = center + scale * (min_bound_ - center);
-    max_bound_ = center + scale * (max_bound_ - center);
+        double scale, const utility::optional<core::Tensor> &center) {
+    core::Tensor center_d;
+    if (!center.has_value()) {
+        center_d = GetCenter();
+    } else {
+        center_d = center.value();
+        core::AssertTensorDevice(center_d, GetDevice());
+        core::AssertTensorShape(center_d, {3});
+        core::AssertTensorDtypes(center_d, {core::Float32, core::Float64});
+        center_d = center_d.To(GetDtype());
+    }
+    min_bound_ = center_d + scale * (min_bound_ - center_d);
+    max_bound_ = center_d + scale * (max_bound_ - center_d);
 
     return *this;
 }
@@ -216,11 +226,14 @@ core::Tensor AxisAlignedBoundingBox::GetPointIndicesWithinBoundingBox(
         const core::Tensor &points) const {
     core::AssertTensorDevice(points, GetDevice());
     core::AssertTensorShape(points, {utility::nullopt, 3});
+    core::AssertTensorDtypes(points, {core::Float32, core::Float64});
 
     core::Tensor mask =
             core::Tensor::Zeros({points.GetLength()}, core::Bool, GetDevice());
-    kernel::pointcloud::GetPointMaskWithinAABB(points, min_bound_, max_bound_,
-                                               mask);
+    // Convert min_bound and max_bound to the same dtype as points.
+    kernel::pointcloud::GetPointMaskWithinAABB(
+            points, min_bound_.To(points.GetDtype()),
+            max_bound_.To(points.GetDtype()), mask);
 
     return mask.NonZero().Flatten();
 }
@@ -233,14 +246,14 @@ std::string AxisAlignedBoundingBox::ToString() const {
 AxisAlignedBoundingBox AxisAlignedBoundingBox::CreateFromPoints(
         const core::Tensor &points) {
     core::AssertTensorShape(points, {utility::nullopt, 3});
+    core::AssertTensorDtypes(points, {core::Float32, core::Float64});
     if (points.GetLength() <= 3) {
         utility::LogWarning("The points number is less than 3.");
         return AxisAlignedBoundingBox(points.GetDevice());
     } else {
         const core::Tensor min_bound = points.Min({0});
         const core::Tensor max_bound = points.Max({0});
-        return AxisAlignedBoundingBox(min_bound.To(core::Float32),
-                                      max_bound.To(core::Float32));
+        return AxisAlignedBoundingBox(min_bound, max_bound);
     }
 }
 
@@ -248,22 +261,19 @@ open3d::geometry::AxisAlignedBoundingBox AxisAlignedBoundingBox::ToLegacy()
         const {
     open3d::geometry::AxisAlignedBoundingBox legacy_box;
 
-    AxisAlignedBoundingBox box_new;
-
-    // Make sure the box is in CPU.
-    box_new = To(core::Device("CPU:0"));
-
-    // TODO: The helper function for conversion between 1-D Tensor and
-    // Eigen::VectorXd could be implemented in `core/EigenConverter.cpp`.
     legacy_box.min_bound_ = core::eigen_converter::TensorToEigenVector3dVector(
-            box_new.GetMinBound().Reshape({1, 3}))[0];
+            GetMinBound().Reshape({1, 3}))[0];
     legacy_box.max_bound_ = core::eigen_converter::TensorToEigenVector3dVector(
-            max_bound_.Reshape({1, 3}))[0];
+            GetMaxBound().Reshape({1, 3}))[0];
     legacy_box.color_ = core::eigen_converter::TensorToEigenVector3dVector(
-            color_.Reshape({1, 3}))[0];
+            GetColor().Reshape({1, 3}))[0];
     return legacy_box;
 }
 
+OrientedBoundingBox AxisAlignedBoundingBox::GetOrientedBoundingBox() const {
+    return OrientedBoundingBox::CreateFromAxisAlignedBoundingBox(*this);
+}
+
 AxisAlignedBoundingBox AxisAlignedBoundingBox::FromLegacy(
         const open3d::geometry::AxisAlignedBoundingBox &box,
         const core::Dtype &dtype,
@@ -289,6 +299,295 @@ AxisAlignedBoundingBox AxisAlignedBoundingBox::FromLegacy(
     return t_box;
 }
 
+OrientedBoundingBox::OrientedBoundingBox(const core::Device &device)
+    : Geometry(Geometry::GeometryType::OrientedBoundingBox, 3),
+      device_(device),
+      dtype_(core::Float32),
+      center_(core::Tensor::Zeros({3}, dtype_, device)),
+      rotation_(core::Tensor::Eye(3, dtype_, device)),
+      extent_(core::Tensor::Zeros({3}, dtype_, device)),
+      color_(core::Tensor::Ones({3}, dtype_, device)) {}
+
+OrientedBoundingBox::OrientedBoundingBox(const core::Tensor &center,
+                                         const core::Tensor &rotation,
+                                         const core::Tensor &extent)
+    : OrientedBoundingBox([&]() {
+          core::AssertTensorDevice(center, extent.GetDevice());
+          core::AssertTensorDevice(rotation, extent.GetDevice());
+          core::AssertTensorDtype(center, extent.GetDtype());
+          core::AssertTensorDtype(rotation, extent.GetDtype());
+          core::AssertTensorDtypes(extent, {core::Float32, core::Float64});
+          core::AssertTensorShape(center, {3});
+          core::AssertTensorShape(extent, {3});
+          core::AssertTensorShape(rotation, {3, 3});
+          return center.GetDevice();
+      }()) {
+    device_ = center.GetDevice();
+    dtype_ = center.GetDtype();
+
+    center_ = center;
+    extent_ = extent;
+    rotation_ = rotation;
+    color_ = core::Tensor::Ones({3}, dtype_, device_);
+
+    // Check if the bounding box is valid by checking the volume and the
+    // orthogonality of rotation.
+    if (Volume() < 0 ||
+        !rotation_.T().AllClose(rotation.Inverse(), 1e-5, 1e-5)) {
+        utility::LogError(
+                "Invalid oriented bounding box. Please make sure the values of "
+                "extent are all positive and the rotation matrix is "
+                "othogonal.");
+    }
+}
+
+OrientedBoundingBox OrientedBoundingBox::To(const core::Device &device,
+                                            bool copy) const {
+    if (!copy && GetDevice() == device) {
+        return *this;
+    }
+    OrientedBoundingBox box(device);
+    box.SetCenter(center_.To(device, true));
+    box.SetRotation(rotation_.To(device, true));
+    box.SetExtent(extent_.To(device, true));
+    box.SetColor(color_.To(device, true));
+    return box;
+}
+
+OrientedBoundingBox &OrientedBoundingBox::Clear() {
+    center_ = core::Tensor::Zeros({3}, GetDtype(), GetDevice());
+    extent_ = core::Tensor::Zeros({3}, GetDtype(), GetDevice());
+    rotation_ = core::Tensor::Eye(3, GetDtype(), GetDevice());
+    color_ = core::Tensor::Ones({3}, GetDtype(), GetDevice());
+    return *this;
+}
+
+void OrientedBoundingBox::SetCenter(const core::Tensor &center) {
+    core::AssertTensorDevice(center, GetDevice());
+    core::AssertTensorShape(center, {3});
+    core::AssertTensorDtypes(center, {core::Float32, core::Float64});
+
+    center_ = center.To(GetDtype());
+}
+
+void OrientedBoundingBox::SetExtent(const core::Tensor &extent) {
+    core::AssertTensorDevice(extent, GetDevice());
+    core::AssertTensorShape(extent, {3});
+    core::AssertTensorDtypes(extent, {core::Float32, core::Float64});
+
+    if (extent.Min({0}).To(core::Float64).Item<double>() <= 0) {
+        utility::LogError(
+                "Invalid oriented bounding box. Please make sure the values of "
+                "extent are all positive.");
+    }
+
+    extent_ = extent.To(GetDtype());
+}
+
+void OrientedBoundingBox::SetRotation(const core::Tensor &rotation) {
+    core::AssertTensorDevice(rotation, GetDevice());
+    core::AssertTensorShape(rotation, {3, 3});
+    core::AssertTensorDtypes(rotation, {core::Float32, core::Float64});
+
+    if (!rotation.T().AllClose(rotation.Inverse(), 1e-5, 1e-5)) {
+        utility::LogWarning(
+                "Invalid oriented bounding box. Please make sure the rotation "
+                "matrix is orthogonal.");
+    } else {
+        rotation_ = rotation.To(GetDtype());
+    }
+}
+
+void OrientedBoundingBox::SetColor(const core::Tensor &color) {
+    core::AssertTensorDevice(color, GetDevice());
+    core::AssertTensorShape(color, {3});
+    if (color.Max({0}).To(core::Float64).Item<double>() > 1.0 ||
+        color.Min({0}).To(core::Float64).Item<double>() < 0.0) {
+        utility::LogError(
+                "The color must be in the range [0, 1], but for range [{}, "
+                "{}].",
+                color.Min({0}).To(core::Float64).Item<double>(),
+                color.Max({0}).To(core::Float64).Item<double>());
+    }
+
+    color_ = color.To(GetDtype());
+}
+
+core::Tensor OrientedBoundingBox::GetMinBound() const {
+    return GetBoxPoints().Min({0});
+}
+
+core::Tensor OrientedBoundingBox::GetMaxBound() const {
+    return GetBoxPoints().Max({0});
+}
+
+core::Tensor OrientedBoundingBox::GetBoxPoints() const {
+    const t::geometry::AxisAlignedBoundingBox aabb(GetExtent() * -0.5,
+                                                   GetExtent() * 0.5);
+    return aabb.GetBoxPoints().Matmul(GetRotation()).Add(GetCenter());
+}
+
+OrientedBoundingBox &OrientedBoundingBox::Translate(
+        const core::Tensor &translation, bool relative) {
+    core::AssertTensorDevice(translation, GetDevice());
+    core::AssertTensorShape(translation, {3});
+    core::AssertTensorDtypes(translation, {core::Float32, core::Float64});
+
+    const core::Tensor translation_d = translation.To(GetDtype());
+    if (relative) {
+        center_ += translation_d;
+    } else {
+        center_ = translation_d;
+    }
+    return *this;
+}
+
+OrientedBoundingBox &OrientedBoundingBox::Rotate(
+        const core::Tensor &rotation,
+        const utility::optional<core::Tensor> &center) {
+    core::AssertTensorDevice(rotation, GetDevice());
+    core::AssertTensorShape(rotation, {3, 3});
+    core::AssertTensorDtypes(rotation, {core::Float32, core::Float64});
+
+    if (!rotation.T().AllClose(rotation.Inverse(), 1e-5, 1e-5)) {
+        utility::LogWarning(
+                "Invalid rotation matrix. Please make sure the rotation "
+                "matrix is orthogonal.");
+        return *this;
+    }
+
+    const core::Tensor rotation_d = rotation.To(GetDtype());
+    rotation_ = rotation_d.Matmul(rotation_);
+    if (center.has_value()) {
+        core::AssertTensorDevice(center.value(), GetDevice());
+        core::AssertTensorShape(center.value(), {3});
+        core::AssertTensorDtypes(center.value(),
+                                 {core::Float32, core::Float64});
+
+        core::Tensor center_d = center.value().To(GetDtype());
+        center_ = rotation_d.Matmul(center_ - center_d).Flatten() + center_d;
+    }
+
+    return *this;
+}
+
+OrientedBoundingBox &OrientedBoundingBox::Transform(
+        const core::Tensor &transformation) {
+    core::AssertTensorDevice(transformation, GetDevice());
+    core::AssertTensorShape(transformation, {4, 4});
+    core::AssertTensorDtypes(transformation, {core::Float32, core::Float64});
+
+    const core::Tensor transformation_d = transformation.To(GetDtype());
+    Rotate(transformation_d.GetItem({core::TensorKey::Slice(0, 3, 1),
+                                     core::TensorKey::Slice(0, 3, 1)}));
+    Translate(transformation_d
+                      .GetItem({core::TensorKey::Slice(0, 3, 1),
+                                core::TensorKey::Index(3)})
+                      .Flatten());
+    return *this;
+}
+
+OrientedBoundingBox &OrientedBoundingBox::Scale(
+        const double scale, const utility::optional<core::Tensor> &center) {
+    extent_ *= scale;
+    if (center.has_value()) {
+        core::Tensor center_d = center.value();
+        core::AssertTensorDevice(center_d, GetDevice());
+        core::AssertTensorShape(center_d, {3});
+        core::AssertTensorDtypes(center_d, {core::Float32, core::Float64});
+
+        center_d = center_d.To(GetDtype());
+        center_ = scale * (center_ - center_d) + center_d;
+    }
+    return *this;
+}
+
+core::Tensor OrientedBoundingBox::GetPointIndicesWithinBoundingBox(
+        const core::Tensor &points) const {
+    core::AssertTensorDevice(points, GetDevice());
+    core::AssertTensorShape(points, {utility::nullopt, 3});
+    core::AssertTensorDtypes(points, {core::Float32, core::Float64});
+
+    core::Tensor mask =
+            core::Tensor::Zeros({points.GetLength()}, core::Bool, GetDevice());
+    // Convert center, rotation and same to the same dtype as points.
+    kernel::pointcloud::GetPointMaskWithinOBB(
+            points, center_.To(points.GetDtype()),
+            rotation_.To(points.GetDtype()), extent_.To(points.GetDtype()),
+            mask);
+
+    return mask.NonZero().Flatten();
+}
+
+std::string OrientedBoundingBox::ToString() const {
+    return fmt::format("OrientedBoundingBox[{}, {}]", GetDtype().ToString(),
+                       GetDevice().ToString());
+}
+
+open3d::geometry::OrientedBoundingBox OrientedBoundingBox::ToLegacy() const {
+    open3d::geometry::OrientedBoundingBox legacy_box;
+
+    legacy_box.center_ = core::eigen_converter::TensorToEigenVector3dVector(
+            GetCenter().Reshape({1, 3}))[0];
+    legacy_box.extent_ = core::eigen_converter::TensorToEigenVector3dVector(
+            GetExtent().Reshape({1, 3}))[0];
+    legacy_box.R_ = core::eigen_converter::TensorToEigenMatrixXd(GetRotation());
+    legacy_box.color_ = core::eigen_converter::TensorToEigenVector3dVector(
+            GetColor().Reshape({1, 3}))[0];
+    return legacy_box;
+}
+
+AxisAlignedBoundingBox OrientedBoundingBox::GetAxisAlignedBoundingBox() const {
+    return AxisAlignedBoundingBox::CreateFromPoints(GetBoxPoints());
+}
+
+OrientedBoundingBox OrientedBoundingBox::CreateFromAxisAlignedBoundingBox(
+        const AxisAlignedBoundingBox &aabb) {
+    OrientedBoundingBox box(
+            aabb.GetCenter(),
+            core::Tensor::Eye(3, aabb.GetDtype(), aabb.GetDevice()),
+            aabb.GetExtent());
+    return box;
+}
+
+OrientedBoundingBox OrientedBoundingBox::FromLegacy(
+        const open3d::geometry::OrientedBoundingBox &box,
+        const core::Dtype &dtype,
+        const core::Device &device) {
+    if (dtype != core::Float32 && dtype != core::Float64) {
+        utility::LogError(
+                "Got data-type {}, but the supported data-type of the bounding "
+                "box are Float32 and Float64.",
+                dtype.ToString());
+    }
+
+    OrientedBoundingBox t_box(
+            core::eigen_converter::EigenMatrixToTensor(box.center_)
+                    .Flatten()
+                    .To(device, dtype),
+            core::eigen_converter::EigenMatrixToTensor(box.R_).To(device,
+                                                                  dtype),
+            core::eigen_converter::EigenMatrixToTensor(box.extent_)
+                    .Flatten()
+                    .To(device, dtype));
+
+    t_box.SetColor(core::eigen_converter::EigenMatrixToTensor(box.color_)
+                           .Flatten()
+                           .To(device, dtype));
+    return t_box;
+}
+
+OrientedBoundingBox OrientedBoundingBox::CreateFromPoints(
+        const core::Tensor &points, bool robust) {
+    core::AssertTensorShape(points, {utility::nullopt, 3});
+    core::AssertTensorDtypes(points, {core::Float32, core::Float64});
+    return OrientedBoundingBox::FromLegacy(
+            open3d::geometry::OrientedBoundingBox::CreateFromPoints(
+                    core::eigen_converter::TensorToEigenVector3dVector(points),
+                    robust),
+            points.GetDtype(), points.GetDevice());
+}
+
 }  // namespace geometry
 }  // namespace t
 }  // namespace open3d
diff --git a/cpp/open3d/t/geometry/BoundingVolume.h b/cpp/open3d/t/geometry/BoundingVolume.h
index 6638af927ce..84e67a14240 100644
--- a/cpp/open3d/t/geometry/BoundingVolume.h
+++ b/cpp/open3d/t/geometry/BoundingVolume.h
@@ -37,6 +37,8 @@ namespace open3d {
 namespace t {
 namespace geometry {
 
+class OrientedBoundingBox;
+
 /// \class AxisAlignedBoundingBox
 /// \brief A bounding box that is aligned along the coordinate axes and defined
 /// by the min_bound and max_bound.
@@ -85,9 +87,9 @@ class AxisAlignedBoundingBox : public Geometry, public DrawableGeometry {
     /// \brief Returns the data type attribute of this AxisAlignedBoundingBox.
     core::Dtype GetDtype() const { return dtype_; }
 
-    /// Transfer the AxisAlignedBoundingBox to a specified device.
+    /// \brief Transfer the AxisAlignedBoundingBox to a specified device.
     /// \param device The targeted device to convert to.
-    /// \param copy If true, a new AxisAlignedBoundingBox is always created; if
+    /// \param copy If true, a new AxisAlignedBoundingBox is always created; If
     /// false, the copy is avoided when the original AxisAlignedBoundingBox is
     /// already on the targeted device.
     AxisAlignedBoundingBox To(const core::Device &device,
@@ -104,19 +106,23 @@ class AxisAlignedBoundingBox : public Geometry, public DrawableGeometry {
 
     /// \brief Set the min bound of the box.
     /// If the data type of the given tensor differs from the data type of the
-    /// original tensor, it will be converted into the same data type.
+    /// box, an exception will be thrown.
+    ///
     /// If the min bound makes the box invalid, it will not be set to the box.
     /// \param min_bound Tensor with {3,} shape, and type float32 or float64.
     void SetMinBound(const core::Tensor &min_bound);
 
     /// \brief Set the max boundof the box.
     /// If the data type of the given tensor differs from the data type of the
-    /// original tensor, it will be converted into the same data type.
+    /// box, an exception will be thrown.
+    ///
     /// If the max bound makes the box invalid, it will not be set to the box.
     /// \param min_bound Tensor with {3,} shape, and type float32 or float64.
     void SetMaxBound(const core::Tensor &max_bound);
 
     /// \brief Set the color of the box.
+    /// If the data type of the given tensor differs from the data type of the
+    /// box, an exception will be thrown.
     ///
     /// \param color Tensor with {3,} shape, and type float32 or float64,
     /// with values in range [0.0, 1.0].
@@ -149,11 +155,14 @@ class AxisAlignedBoundingBox : public Geometry, public DrawableGeometry {
     /// provided scaling factor and center respectively, then the new
     /// min_bound and max_bound are given by \f$mi = c + s (mi - c)\f$
     /// and \f$ma = c + s (ma - c)\f$.
+    /// The scaling center will be the box center if it is not specified.
     ///
     /// \param scale The scale parameter.
     /// \param center Center used for the scaling operation. Tensor of shape
     /// {3,}, type float32 or float64, device same as the box.
-    AxisAlignedBoundingBox &Scale(double scale, const core::Tensor &center);
+    AxisAlignedBoundingBox &Scale(
+            double scale,
+            const utility::optional<core::Tensor> &center = utility::nullopt);
 
     /// \brief Add operation for axis-aligned bounding box.
     /// The device of ohter box must be the same as the device of the current
@@ -184,7 +193,7 @@ class AxisAlignedBoundingBox : public Geometry, public DrawableGeometry {
     }
 
     /// Returns the eight points that define the bounding box. The Return tensor
-    /// has shape {8, 3} and data type of float32.
+    /// has shape {8, 3} and data type same as the box.
     core::Tensor GetBoxPoints() const;
 
     /// \brief Indices to points that are within the bounding box.
@@ -199,12 +208,16 @@ class AxisAlignedBoundingBox : public Geometry, public DrawableGeometry {
     /// Convert to a legacy Open3D axis-aligned box.
     open3d::geometry::AxisAlignedBoundingBox ToLegacy() const;
 
+    /// Convert to an oriented box.
+    OrientedBoundingBox GetOrientedBoundingBox() const;
+
     /// Create an AxisAlignedBoundingBox from a legacy Open3D
     /// axis-aligned box.
     ///
-    /// \param dtype The data type of the box for min_bound max_bound and color.
-    /// The default is float32. \param device The device of the box. The default
-    /// is CPU:0.
+    /// \param box Legacy AxisAlignedBoundingBox.
+    /// \param dtype The data type of the box for min_bound, max_bound and
+    /// color. The default is float32.
+    /// \param device The device of the box. The default is CPU:0.
     static AxisAlignedBoundingBox FromLegacy(
             const open3d::geometry::AxisAlignedBoundingBox &box,
             const core::Dtype &dtype = core::Float32,
@@ -213,6 +226,8 @@ class AxisAlignedBoundingBox : public Geometry, public DrawableGeometry {
     /// Creates the axis-aligned box that encloses the set of points.
     /// \param points A list of points with data type of float32 or float64 (N x
     /// 3 tensor, where N must be larger than 3).
+    /// \return AxisAlignedBoundingBox with same data type and device as input
+    /// points.
     static AxisAlignedBoundingBox CreateFromPoints(const core::Tensor &points);
 
 protected:
@@ -223,6 +238,243 @@ class AxisAlignedBoundingBox : public Geometry, public DrawableGeometry {
     core::Tensor color_;
 };
 
+/// \class OrientedBoundingBox
+/// \brief A bounding box oriented along an arbitrary frame of reference.
+///
+/// - (center, rotation, extent): The oriented bounding box is defined by its
+/// center position, rotation maxtrix and extent.
+///     - Usage
+///         - OrientedBoundingBox::GetCenter()
+///         - OrientedBoundingBox::SetCenter(const core::Tensor &center)
+///         - OrientedBoundingBox::GetRotation()
+///         - OrientedBoundingBox::SetRotation(const core::Tensor &rotation)
+///     - Value tensor of center and extent must have shape {3,}.
+///     - Value tensor of rotation must have shape {3, 3}.
+///     - Value tensor must have the same data type and device.
+///     - Value tensor can only be float32 (default) or float64.
+///     - The device of the tensor determines the device of the box.
+///
+/// - color: Color of the bounding box.
+///     - Usage
+///         - OrientedBoundingBox::GetColor()
+///         - OrientedBoundingBox::SetColor(const core::Tensor &color)
+///     - Value tensor must have shape {3,}.
+///     - Value tensor can only be float32 (default) or float64.
+///     - Value tensor can only be range [0.0, 1.0].
+class OrientedBoundingBox : public Geometry, public DrawableGeometry {
+public:
+    /// \brief Construct an empty OrientedBoundingBox on the provided device.
+    OrientedBoundingBox(const core::Device &device = core::Device("CPU:0"));
+
+    /// \brief Construct an OrientedBoundingBox from center, rotation and
+    /// extent.
+    ///
+    /// The OrientedBoundingBox will be created on the device of the given
+    /// tensors, which must be on the same device and have the same data
+    /// type.
+    /// \param center Center of the bounding box. Tensor of shape {3,}, and type
+    /// float32 or float64.
+    /// \param rotation Rotation matrix of the bounding box. Tensor of shape {3,
+    /// 3}, and type float32 or float64.
+    /// \param extent Extent of the bounding box. Tensor of shape {3,}, and type
+    /// float32 or float64.
+    OrientedBoundingBox(const core::Tensor &center,
+                        const core::Tensor &rotation,
+                        const core::Tensor &extent);
+
+    virtual ~OrientedBoundingBox() override {}
+
+    /// \brief Returns the device attribute of this OrientedBoundingBox.
+    core::Device GetDevice() const override { return device_; }
+
+    /// \brief Returns the data type attribute of this OrientedBoundingBox.
+    core::Dtype GetDtype() const { return dtype_; }
+
+    /// Transfer the OrientedBoundingBox to a specified device.
+    /// \param device The targeted device to convert to.
+    /// \param copy If true, a new OrientedBoundingBox is always created; if
+    /// false, the copy is avoided when the original OrientedBoundingBox is
+    /// already on the targeted device.
+    OrientedBoundingBox To(const core::Device &device, bool copy = false) const;
+
+    /// Returns copy of the OrientedBoundingBox on the same device.
+    OrientedBoundingBox Clone() const { return To(GetDevice(), /*copy=*/true); }
+
+    OrientedBoundingBox &Clear() override;
+
+    bool IsEmpty() const override { return Volume() == 0; }
+
+    /// \brief Set the center of the box.
+    /// If the data type of the given tensor differs from the data type of the
+    /// box, an exception will be thrown.
+    ///
+    /// \param center Tensor with {3,} shape, and type float32 or float64.
+    void SetCenter(const core::Tensor &center);
+
+    /// \brief Set the rotation matrix of the box.
+    /// If the data type of the given tensor differs from the data type of the
+    /// box, an exception will be thrown.
+    ///
+    /// \param rotation Tensor with {3, 3} shape, and type float32 or float64.
+    void SetRotation(const core::Tensor &rotation);
+
+    /// \brief Set the extent of the box.
+    /// If the data type of the given tensor differs from the data type of the
+    /// box, an exception will be thrown.
+    ///
+    /// \param extent Tensor with {3,} shape, and type float32 or float64.
+    void SetExtent(const core::Tensor &extent);
+
+    /// \brief Set the color of the box.
+    ///
+    /// \param color Tensor with {3,} shape, and type float32 or float64,
+    /// with values in range [0.0, 1.0].
+    void SetColor(const core::Tensor &color);
+
+public:
+    core::Tensor GetMinBound() const;
+
+    core::Tensor GetMaxBound() const;
+
+    core::Tensor GetColor() const { return color_; }
+
+    core::Tensor GetCenter() const { return center_; }
+
+    core::Tensor GetRotation() const { return rotation_; }
+
+    core::Tensor GetExtent() const { return extent_; }
+
+    /// \brief Translate the oriented box by the given translation.
+    /// If relative is true, the translation is added to the center of the box.
+    /// If false, the center will be assigned to the translation.
+    ///
+    /// \param translation Translation tensor of shape {3,}, type float32 or
+    /// float64, device same as the box.
+    /// \param relative Whether to perform relative translation.
+    OrientedBoundingBox &Translate(const core::Tensor &translation,
+                                   bool relative = true);
+
+    /// \brief Rotate the oriented box by the given rotation matrix. If the
+    /// rotation matrix is not orthogonal, the rotation will no be applied.
+    /// The rotation center will be the box center if it is not specified.
+    ///
+    /// \param rotation Rotation matrix of shape {3, 3}, type float32 or
+    /// float64, device same as the box.
+    /// \param center Center of the rotation, default is null, which means use
+    /// center of the box as rotation center.
+    OrientedBoundingBox &Rotate(
+            const core::Tensor &rotation,
+            const utility::optional<core::Tensor> &center = utility::nullopt);
+
+    /// \brief Transform the oriented box by the given transformation matrix.
+    ///
+    /// \param transformation Transformation matrix of shape {4, 4}, type
+    /// float32 or float64, device same as the box.
+    OrientedBoundingBox &Transform(const core::Tensor &transformation);
+
+    /// \brief Scale the axis-aligned box.
+    /// If \f$mi\f$ is the min_bound and \f$ma\f$ is the max_bound of
+    /// the axis aligned bounding box, and \f$s\f$ and \f$c\f$ are the
+    /// provided scaling factor and center respectively, then the new
+    /// min_bound and max_bound are given by \f$mi = c + s (mi - c)\f$
+    /// and \f$ma = c + s (ma - c)\f$.
+    /// The scaling center will be the box center if it is not specified.
+    ///
+    /// \param scale The scale parameter.
+    /// \param center Center used for the scaling operation. Tensor of shape
+    /// {3,}, type float32 or float64, device same as the box.
+    OrientedBoundingBox &Scale(
+            double scale,
+            const utility::optional<core::Tensor> &center = utility::nullopt);
+
+    /// Returns the volume of the bounding box.
+    double Volume() const {
+        return GetExtent().Prod({0}).To(core::Float64).Item<double>();
+    }
+
+    /// Returns the eight points that define the bounding box. The Return tensor
+    /// has shape {8, 3} and data type same as the box.
+    ///
+    /// \verbatim
+    ///      ------- x
+    ///     /|
+    ///    / |
+    ///   /  | z
+    ///  y
+    ///      0 ------------------- 1
+    ///       /|                /|
+    ///      / |               / |
+    ///     /  |              /  |
+    ///    /   |             /   |
+    /// 2 ------------------- 7  |
+    ///   |    |____________|____| 6
+    ///   |   /3            |   /
+    ///   |  /              |  /
+    ///   | /               | /
+    ///   |/                |/
+    /// 5 ------------------- 4
+    /// \endverbatim
+    core::Tensor GetBoxPoints() const;
+
+    /// \brief Indices to points that are within the bounding box.
+    ///
+    /// \param points Tensor with {N, 3} shape, and type float32 or float64.
+    core::Tensor GetPointIndicesWithinBoundingBox(
+            const core::Tensor &points) const;
+
+    /// Text description.
+    std::string ToString() const;
+
+    /// Convert to a legacy Open3D oriented box.
+    open3d::geometry::OrientedBoundingBox ToLegacy() const;
+
+    /// Convert to an axis-aligned box.
+    AxisAlignedBoundingBox GetAxisAlignedBoundingBox() const;
+
+    /// Create an oriented bounding box from the AxisAlignedBoundingBox.
+    ///
+    /// \param aabb AxisAlignedBoundingBox object from which
+    /// OrientedBoundingBox is created.
+    /// \return OrientedBoundingBox with the same device and dtype as input box.
+    static OrientedBoundingBox CreateFromAxisAlignedBoundingBox(
+            const AxisAlignedBoundingBox &aabb);
+
+    /// Create an OrientedBoundingBox from a legacy Open3D oriented box.
+    ///
+    /// \param box Legacy OrientedBoundingBox.
+    /// \param dtype The data type of the box for min_bound max_bound and color.
+    /// The default is float32.
+    /// \param device The device of the box. The default is CPU:0.
+    static OrientedBoundingBox FromLegacy(
+            const open3d::geometry::OrientedBoundingBox &box,
+            const core::Dtype &dtype = core::Float32,
+            const core::Device &device = core::Device("CPU:0"));
+
+    /// Creates an oriented bounding box using a PCA.
+    /// Note that this is only an approximation to the minimum oriented
+    /// bounding box that could be computed for example with O'Rourke's
+    /// algorithm (cf. http://cs.smith.edu/~jorourke/Papers/MinVolBox.pdf,
+    /// https://www.geometrictools.com/Documentation/MinimumVolumeBox.pdf)
+    /// This is a wrapper for a CPU implementation.
+    ///
+    /// \param points A list of points with data type of float32 or float64 (N x
+    /// 3 tensor, where N must be larger than 3).
+    /// \param robust If set to true uses a more robust method which works in
+    /// degenerate cases but introduces noise to the points coordinates.
+    /// \return OrientedBoundingBox with same data type and device as input
+    /// points.
+    static OrientedBoundingBox CreateFromPoints(const core::Tensor &points,
+                                                bool robust = false);
+
+protected:
+    core::Device device_ = core::Device("CPU:0");
+    core::Dtype dtype_ = core::Float32;
+    core::Tensor center_;
+    core::Tensor rotation_;
+    core::Tensor extent_;
+    core::Tensor color_;
+};
+
 }  // namespace geometry
 }  // namespace t
 }  // namespace open3d
diff --git a/cpp/open3d/t/geometry/Geometry.h b/cpp/open3d/t/geometry/Geometry.h
index 19b3a264ff1..db834428d39 100644
--- a/cpp/open3d/t/geometry/Geometry.h
+++ b/cpp/open3d/t/geometry/Geometry.h
@@ -26,6 +26,8 @@
 
 #pragma once
 
+#include <fmt/format.h>
+
 #include <string>
 
 #include "open3d/core/Device.h"
@@ -110,6 +112,8 @@ class Geometry : public core::IsDevice {
     std::string name_;
 };
 
+using fmt::enums::format_as;
+
 }  // namespace geometry
 }  // namespace t
 }  // namespace open3d
diff --git a/cpp/open3d/t/geometry/LineSet.cpp b/cpp/open3d/t/geometry/LineSet.cpp
index a541f36f80b..b13c5d38b5d 100644
--- a/cpp/open3d/t/geometry/LineSet.cpp
+++ b/cpp/open3d/t/geometry/LineSet.cpp
@@ -226,6 +226,10 @@ TriangleMesh LineSet::ExtrudeLinear(const core::Tensor &vector,
     return ExtrudeLinearTriangleMesh(*this, vector, scale, capping);
 }
 
+OrientedBoundingBox LineSet::GetOrientedBoundingBox() const {
+    return OrientedBoundingBox::CreateFromPoints(GetPointPositions());
+}
+
 }  // namespace geometry
 }  // namespace t
 }  // namespace open3d
diff --git a/cpp/open3d/t/geometry/LineSet.h b/cpp/open3d/t/geometry/LineSet.h
index c598c4211df..96ddf450180 100644
--- a/cpp/open3d/t/geometry/LineSet.h
+++ b/cpp/open3d/t/geometry/LineSet.h
@@ -378,6 +378,9 @@ class LineSet : public Geometry, public DrawableGeometry {
     /// Create an axis-aligned bounding box from point attribute "positions".
     AxisAlignedBoundingBox GetAxisAlignedBoundingBox() const;
 
+    /// Create an oriented bounding box from point attribute "positions".
+    OrientedBoundingBox GetOrientedBoundingBox() const;
+
     /// Sweeps the line set rotationally about an axis.
     /// \param angle The rotation angle in degree.
     /// \param axis The rotation axis.
diff --git a/cpp/open3d/t/geometry/PointCloud.cpp b/cpp/open3d/t/geometry/PointCloud.cpp
index b312316bba6..3f2f7fca09b 100644
--- a/cpp/open3d/t/geometry/PointCloud.cpp
+++ b/cpp/open3d/t/geometry/PointCloud.cpp
@@ -1211,24 +1211,14 @@ TriangleMesh PointCloud::ComputeConvexHull(bool joggle_inputs) const {
     return convex_hull.To(GetPointPositions().GetDevice());
 }
 
-PointCloud PointCloud::Crop(const AxisAlignedBoundingBox &aabb,
-                            bool invert) const {
-    core::AssertTensorDevice(GetPointPositions(), aabb.GetDevice());
-    if (aabb.IsEmpty()) {
-        utility::LogWarning(
-                "Bounding box is empty. Returning empty point cloud if "
-                "invert is false, or the original point cloud if "
-                "invert is true.");
-        return invert ? Clone() : PointCloud(GetDevice());
-    }
-    return SelectByIndex(
-            aabb.GetPointIndicesWithinBoundingBox(GetPointPositions()), invert);
-}
-
 AxisAlignedBoundingBox PointCloud::GetAxisAlignedBoundingBox() const {
     return AxisAlignedBoundingBox::CreateFromPoints(GetPointPositions());
 }
 
+OrientedBoundingBox PointCloud::GetOrientedBoundingBox() const {
+    return OrientedBoundingBox::CreateFromPoints(GetPointPositions());
+}
+
 LineSet PointCloud::ExtrudeRotation(double angle,
                                     const core::Tensor &axis,
                                     int resolution,
@@ -1246,6 +1236,33 @@ LineSet PointCloud::ExtrudeLinear(const core::Tensor &vector,
     return ExtrudeLinearLineSet(*this, vector, scale, capping);
 }
 
+PointCloud PointCloud::Crop(const AxisAlignedBoundingBox &aabb,
+                            bool invert) const {
+    core::AssertTensorDevice(GetPointPositions(), aabb.GetDevice());
+    if (aabb.IsEmpty()) {
+        utility::LogWarning(
+                "Bounding box is empty. Returning empty point cloud if "
+                "invert is false, or the original point cloud if "
+                "invert is true.");
+        return invert ? Clone() : PointCloud(GetDevice());
+    }
+    return SelectByIndex(
+            aabb.GetPointIndicesWithinBoundingBox(GetPointPositions()), invert);
+}
+
+PointCloud PointCloud::Crop(const OrientedBoundingBox &obb, bool invert) const {
+    core::AssertTensorDevice(GetPointPositions(), obb.GetDevice());
+    if (obb.IsEmpty()) {
+        utility::LogWarning(
+                "Bounding box is empty. Returning empty point cloud if "
+                "invert is false, or the original point cloud if "
+                "invert is true.");
+        return invert ? Clone() : PointCloud(GetDevice());
+    }
+    return SelectByIndex(
+            obb.GetPointIndicesWithinBoundingBox(GetPointPositions()), invert);
+}
+
 }  // namespace geometry
 }  // namespace t
 }  // namespace open3d
diff --git a/cpp/open3d/t/geometry/PointCloud.h b/cpp/open3d/t/geometry/PointCloud.h
index 4fc85a44fb3..f8118a62918 100644
--- a/cpp/open3d/t/geometry/PointCloud.h
+++ b/cpp/open3d/t/geometry/PointCloud.h
@@ -660,6 +660,9 @@ class PointCloud : public Geometry, public DrawableGeometry {
     /// Create an axis-aligned bounding box from attribute "positions".
     AxisAlignedBoundingBox GetAxisAlignedBoundingBox() const;
 
+    /// Create an oriented bounding box from attribute "positions".
+    OrientedBoundingBox GetOrientedBoundingBox() const;
+
     /// \brief Function to crop pointcloud into output pointcloud.
     ///
     /// \param aabb AxisAlignedBoundingBox to crop points.
@@ -668,6 +671,13 @@ class PointCloud : public Geometry, public DrawableGeometry {
     PointCloud Crop(const AxisAlignedBoundingBox &aabb,
                     bool invert = false) const;
 
+    /// \brief Function to crop pointcloud into output pointcloud.
+    ///
+    /// \param obb OrientedBoundingBox to crop points.
+    /// \param invert Crop the points outside of the bounding box or inside of
+    /// the bounding box.
+    PointCloud Crop(const OrientedBoundingBox &obb, bool invert = false) const;
+
     /// Sweeps the point cloud rotationally about an axis.
     /// \param angle The rotation angle in degree.
     /// \param axis The rotation axis.
diff --git a/cpp/open3d/t/geometry/RaycastingScene.cpp b/cpp/open3d/t/geometry/RaycastingScene.cpp
index a5431f18667..56dbd24a9c6 100644
--- a/cpp/open3d/t/geometry/RaycastingScene.cpp
+++ b/cpp/open3d/t/geometry/RaycastingScene.cpp
@@ -33,10 +33,10 @@
 // This header is in the embree src dir (embree/src/ext_embree/..).
 #include <embree3/rtcore.h>
 #include <tbb/parallel_for.h>
-#include <tutorials/common/math/closest_point.h>
 
 #include <Eigen/Core>
 #include <tuple>
+#include <unsupported/Eigen/AlignedVector3>
 #include <vector>
 
 #include "open3d/core/TensorCheck.h"
@@ -45,6 +45,11 @@
 
 namespace {
 
+typedef Eigen::AlignedVector3<float> Vec3fa;
+// Dont force alignment for Vec2f because we use it just for storing
+typedef Eigen::Matrix<float, 2, 1, Eigen::DontAlign> Vec2f;
+typedef Eigen::Vector3f Vec3f;
+
 // Error function called by embree.
 void ErrorFunction(void* userPtr, enum RTCError error, const char* str) {
     open3d::utility::LogError("embree error: {} {}", error, str);
@@ -124,9 +129,6 @@ void CountIntersectionsFunc(const RTCFilterFunctionNArguments* args) {
     }
 }
 
-namespace {
-
-using namespace embree;
 // Adapted from common/math/closest_point.h
 inline Vec3fa closestPointTriangle(Vec3fa const& p,
                                    Vec3fa const& a,
@@ -138,8 +140,8 @@ inline Vec3fa closestPointTriangle(Vec3fa const& p,
     const Vec3fa ac = c - a;
     const Vec3fa ap = p - a;
 
-    const float d1 = dot(ab, ap);
-    const float d2 = dot(ac, ap);
+    const float d1 = ab.dot(ap);
+    const float d2 = ac.dot(ap);
     if (d1 <= 0.f && d2 <= 0.f) {
         tex_u = 0;
         tex_v = 0;
@@ -147,8 +149,8 @@ inline Vec3fa closestPointTriangle(Vec3fa const& p,
     }
 
     const Vec3fa bp = p - b;
-    const float d3 = dot(ab, bp);
-    const float d4 = dot(ac, bp);
+    const float d3 = ab.dot(bp);
+    const float d4 = ac.dot(bp);
     if (d3 >= 0.f && d4 <= d3) {
         tex_u = 1;
         tex_v = 0;
@@ -156,8 +158,8 @@ inline Vec3fa closestPointTriangle(Vec3fa const& p,
     }
 
     const Vec3fa cp = p - c;
-    const float d5 = dot(ab, cp);
-    const float d6 = dot(ac, cp);
+    const float d5 = ab.dot(cp);
+    const float d6 = ac.dot(cp);
     if (d6 >= 0.f && d5 <= d6) {
         tex_u = 0;
         tex_v = 1;
@@ -196,26 +198,23 @@ inline Vec3fa closestPointTriangle(Vec3fa const& p,
     return a + v * ab + w * ac;
 }
 
-}  // namespace
-
 struct ClosestPointResult {
     ClosestPointResult()
         : primID(RTC_INVALID_GEOMETRY_ID),
           geomID(RTC_INVALID_GEOMETRY_ID),
           geometry_ptrs_ptr() {}
 
-    embree::Vec3f p;
+    Vec3f p;
     unsigned int primID;
     unsigned int geomID;
-    embree::Vec2f uv;
-    embree::Vec3f n;
+    Vec2f uv;
+    Vec3f n;
     std::vector<std::tuple<RTCGeometryType, const void*, const void*>>*
             geometry_ptrs_ptr;
 };
 
 // Code adapted from the embree closest_point tutorial.
 bool ClosestPointFunc(RTCPointQueryFunctionArguments* args) {
-    using namespace embree;
     assert(args->userPtr);
     const unsigned int geomID = args->geomID;
     const unsigned int primID = args->primID;
@@ -249,7 +248,7 @@ bool ClosestPointFunc(RTCPointQueryFunctionArguments* args) {
         // Determine distance to closest point on triangle
         float u, v;
         const Vec3fa p = closestPointTriangle(q, v0, v1, v2, u, v);
-        float d = distance(q, p);
+        float d = (q - p).norm();
 
         // Store result in userPtr and update the query radius if we found a
         // point closer to the query position. This is optional but allows for
@@ -261,8 +260,8 @@ bool ClosestPointFunc(RTCPointQueryFunctionArguments* args) {
             result->geomID = geomID;
             Vec3fa e1 = v1 - v0;
             Vec3fa e2 = v2 - v0;
-            result->uv = embree::Vec2f(u, v);
-            result->n = normalize(cross(e1, e2));
+            result->uv = Vec2f(u, v);
+            result->n = (e1.cross(e2)).normalized();
             return true;  // Return true to indicate that the query radius
                           // changed.
         }
@@ -528,16 +527,16 @@ struct RaycastingScene::Impl {
                 rtcPointQuery(scene_, &query, &instStack, &ClosestPointFunc,
                               (void*)&result);
 
-                closest_points[3 * i + 0] = result.p.x;
-                closest_points[3 * i + 1] = result.p.y;
-                closest_points[3 * i + 2] = result.p.z;
+                closest_points[3 * i + 0] = result.p.x();
+                closest_points[3 * i + 1] = result.p.y();
+                closest_points[3 * i + 2] = result.p.z();
                 geometry_ids[i] = result.geomID;
                 primitive_ids[i] = result.primID;
-                primitive_uvs[2 * i + 0] = result.uv.x;
-                primitive_uvs[2 * i + 1] = result.uv.y;
-                primitive_normals[3 * i + 0] = result.n.x;
-                primitive_normals[3 * i + 1] = result.n.y;
-                primitive_normals[3 * i + 2] = result.n.z;
+                primitive_uvs[2 * i + 0] = result.uv.x();
+                primitive_uvs[2 * i + 1] = result.uv.y();
+                primitive_normals[3 * i + 0] = result.n.x();
+                primitive_normals[3 * i + 1] = result.n.y();
+                primitive_normals[3 * i + 2] = result.n.z();
             }
         };
 
@@ -762,60 +761,117 @@ core::Tensor RaycastingScene::ComputeDistance(const core::Tensor& query_points,
     return distance;
 }
 
+namespace {
+// Helper function to determine the inside and outside with voting.
+core::Tensor VoteInsideOutside(RaycastingScene& scene,
+                               const core::Tensor& query_points,
+                               const int nthreads = 0,
+                               const int num_votes = 3,
+                               const int inside_val = 1,
+                               const int outside_val = 0) {
+    auto shape = query_points.GetShape();
+    shape.pop_back();  // Remove last dim, we want to use this shape for the
+                       // results.
+    size_t num_query_points = shape.NumElements();
+
+    // Use local RNG here to generate rays with a similar direction in a
+    // deterministic manner.
+    std::mt19937 gen(42);
+    std::uniform_real_distribution<float> dist(-0.001, 0.001);
+    Eigen::MatrixXf ray_dirs(3, num_votes);
+    ray_dirs = ray_dirs.unaryExpr([&](float) { return 1 + dist(gen); });
+
+    auto query_points_ = query_points.Contiguous();
+    Eigen::Map<Eigen::MatrixXf> query_points_map(
+            query_points_.GetDataPtr<float>(), 3, num_query_points);
+
+    core::Tensor rays({int64_t(num_votes * num_query_points), 6},
+                      core::Float32);
+    Eigen::Map<Eigen::MatrixXf> rays_map(rays.GetDataPtr<float>(), 6,
+                                         num_votes * num_query_points);
+    if (num_votes > 1) {
+        for (size_t i = 0; i < num_query_points; ++i) {
+            for (int j = 0; j < num_votes; ++j) {
+                rays_map.col(i * num_votes + j).topRows<3>() =
+                        query_points_map.col(i);
+                rays_map.col(i * num_votes + j).bottomRows<3>() =
+                        ray_dirs.col(j);
+            }
+        }
+    } else {
+        for (size_t i = 0; i < num_query_points; ++i) {
+            rays_map.col(i).topRows<3>() = query_points_map.col(i);
+            rays_map.col(i).bottomRows<3>() = ray_dirs;
+        }
+    }
+
+    auto intersections = scene.CountIntersections(rays, nthreads);
+    Eigen::Map<Eigen::MatrixXi> intersections_map(
+            intersections.GetDataPtr<int>(), num_votes, num_query_points);
+
+    if (num_votes > 1) {
+        core::Tensor result({int64_t(num_query_points)}, core::Int32);
+        Eigen::Map<Eigen::VectorXi> result_map(result.GetDataPtr<int>(),
+                                               num_query_points);
+        result_map =
+                intersections_map.unaryExpr([&](const int x) { return x % 2; })
+                        .colwise()
+                        .sum()
+                        .unaryExpr([&](const int x) {
+                            return (x > num_votes / 2) ? inside_val
+                                                       : outside_val;
+                        });
+        return result.Reshape(shape);
+    } else {
+        intersections_map = intersections_map.unaryExpr([&](const int x) {
+            return (x % 2) ? inside_val : outside_val;
+        });
+        return intersections.Reshape(shape);
+    }
+}
+}  // namespace
+
 core::Tensor RaycastingScene::ComputeSignedDistance(
-        const core::Tensor& query_points, const int nthreads) {
+        const core::Tensor& query_points,
+        const int nthreads,
+        const int nsamples) {
     AssertTensorDtypeLastDimDeviceMinNDim<float>(query_points, "query_points",
                                                  3, impl_->tensor_device_);
+
+    if (nsamples < 1 || (nsamples % 2) != 1) {
+        open3d::utility::LogError("nsamples must be odd and >= 1 but is {}",
+                                  nsamples);
+    }
     auto shape = query_points.GetShape();
     shape.pop_back();  // Remove last dim, we want to use this shape for the
                        // results.
     size_t num_query_points = shape.NumElements();
-
     auto data = query_points.Contiguous();
     auto distance = ComputeDistance(data, nthreads);
-    core::Tensor rays({int64_t(num_query_points), 6}, core::Float32);
-    rays.SetItem({core::TensorKey::Slice(0, num_query_points, 1),
-                  core::TensorKey::Slice(0, 3, 1)},
-                 data.Reshape({int64_t(num_query_points), 3}));
-    rays.SetItem({core::TensorKey::Slice(0, num_query_points, 1),
-                  core::TensorKey::Slice(3, 6, 1)},
-                 core::Tensor::Ones({1}, core::Float32, impl_->tensor_device_)
-                         .Expand({int64_t(num_query_points), 3}));
-    auto intersections = CountIntersections(rays, nthreads);
-
     Eigen::Map<Eigen::VectorXf> distance_map(distance.GetDataPtr<float>(),
                                              num_query_points);
-    Eigen::Map<Eigen::VectorXi> intersections_map(
-            intersections.GetDataPtr<int>(), num_query_points);
-    intersections_map = intersections_map.unaryExpr(
-            [](const int x) { return (x % 2) ? -1 : 1; });
-    distance_map.array() *= intersections_map.array().cast<float>();
+
+    auto inside_outside =
+            VoteInsideOutside(*this, data, nthreads, nsamples, -1, 1);
+    Eigen::Map<Eigen::VectorXi> inside_outside_map(
+            inside_outside.GetDataPtr<int>(), num_query_points);
+    distance_map.array() *= inside_outside_map.array().cast<float>();
     return distance;
 }
 
 core::Tensor RaycastingScene::ComputeOccupancy(const core::Tensor& query_points,
-                                               const int nthreads) {
+                                               const int nthreads,
+                                               const int nsamples) {
     AssertTensorDtypeLastDimDeviceMinNDim<float>(query_points, "query_points",
                                                  3, impl_->tensor_device_);
-    auto shape = query_points.GetShape();
-    shape.pop_back();  // Remove last dim, we want to use this shape for the
-                       // results.
-    size_t num_query_points = shape.NumElements();
 
-    core::Tensor rays({int64_t(num_query_points), 6}, core::Float32);
-    rays.SetItem({core::TensorKey::Slice(0, num_query_points, 1),
-                  core::TensorKey::Slice(0, 3, 1)},
-                 query_points.Reshape({int64_t(num_query_points), 3}));
-    rays.SetItem({core::TensorKey::Slice(0, num_query_points, 1),
-                  core::TensorKey::Slice(3, 6, 1)},
-                 core::Tensor::Ones({1}, core::Float32, impl_->tensor_device_)
-                         .Expand({int64_t(num_query_points), 3}));
-    auto intersections = CountIntersections(rays, nthreads);
-    Eigen::Map<Eigen::VectorXi> intersections_map(
-            intersections.GetDataPtr<int>(), num_query_points);
-    intersections_map =
-            intersections_map.unaryExpr([](const int x) { return x % 2; });
-    return intersections.To(core::Float32).Reshape(shape);
+    if (nsamples < 1 || (nsamples % 2) != 1) {
+        open3d::utility::LogError("samples must be odd and >= 1 but is {}",
+                                  nsamples);
+    }
+
+    auto result = VoteInsideOutside(*this, query_points, nthreads, nsamples);
+    return result.To(core::Float32);
 }
 
 core::Tensor RaycastingScene::CreateRaysPinhole(
diff --git a/cpp/open3d/t/geometry/RaycastingScene.h b/cpp/open3d/t/geometry/RaycastingScene.h
index 2e21a4d11b3..20ff3c40ec6 100644
--- a/cpp/open3d/t/geometry/RaycastingScene.h
+++ b/cpp/open3d/t/geometry/RaycastingScene.h
@@ -170,11 +170,17 @@ class RaycastingScene {
     /// shape can be {depth, height, width, 3}. The last dimension must be 3 and
     /// has the format [x, y, z].
     /// \param nthreads The number of threads to use. Set to 0 for automatic.
+    /// \param nsamples The number of rays used for determining the inside.
+    /// This must be an odd number. The default is 1. Use a higher value if you
+    /// notice sign flipping, which can occur when rays hit exactly an edge or
+    /// vertex in the scene.
+    ///
     /// \return A tensor with the signed distances to
     /// the surface. The shape is
     /// {..}. Negative distances mean a point is inside a closed surface.
     core::Tensor ComputeSignedDistance(const core::Tensor &query_points,
-                                       const int nthreads = 0);
+                                       const int nthreads = 0,
+                                       const int nsamples = 1);
 
     /// \brief Computes the occupancy at the query point positions.
     ///
@@ -191,10 +197,16 @@ class RaycastingScene {
     /// {depth, height, width, 3}.
     /// The last dimension must be 3 and has the format [x, y, z].
     /// \param nthreads The number of threads to use. Set to 0 for automatic.
+    /// \param nsamples The number of rays used for determining the inside.
+    /// This must be an odd number. The default is 1. Use a higher value if you
+    /// notice errors in the occupancy values. Errors can occur when rays hit
+    /// exactly an edge or vertex in the scene.
+    ///
     /// \return A tensor with the occupancy values. The shape is {..}. Values
     /// are either 0 or 1. A point is occupied or inside if the value is 1.
     core::Tensor ComputeOccupancy(const core::Tensor &query_points,
-                                  const int nthreads = 0);
+                                  const int nthreads = 0,
+                                  const int nsamples = 1);
 
     /// \brief Creates rays for the given camera parameters.
     ///
diff --git a/cpp/open3d/t/geometry/TriangleMesh.cpp b/cpp/open3d/t/geometry/TriangleMesh.cpp
index ee255e3743c..43a269b9b0c 100644
--- a/cpp/open3d/t/geometry/TriangleMesh.cpp
+++ b/cpp/open3d/t/geometry/TriangleMesh.cpp
@@ -556,6 +556,10 @@ AxisAlignedBoundingBox TriangleMesh::GetAxisAlignedBoundingBox() const {
     return AxisAlignedBoundingBox::CreateFromPoints(GetVertexPositions());
 }
 
+OrientedBoundingBox TriangleMesh::GetOrientedBoundingBox() const {
+    return OrientedBoundingBox::CreateFromPoints(GetVertexPositions());
+}
+
 TriangleMesh TriangleMesh::FillHoles(double hole_size) const {
     using namespace vtkutils;
     // do not include triangle attributes because they will not be preserved by
diff --git a/cpp/open3d/t/geometry/TriangleMesh.h b/cpp/open3d/t/geometry/TriangleMesh.h
index 93a3008fa30..d6934a87d20 100644
--- a/cpp/open3d/t/geometry/TriangleMesh.h
+++ b/cpp/open3d/t/geometry/TriangleMesh.h
@@ -801,6 +801,9 @@ class TriangleMesh : public Geometry, public DrawableGeometry {
     /// Create an axis-aligned bounding box from vertex attribute "positions".
     AxisAlignedBoundingBox GetAxisAlignedBoundingBox() const;
 
+    /// Create an oriented bounding box from vertex attribute "positions".
+    OrientedBoundingBox GetOrientedBoundingBox() const;
+
     /// Fill holes by triangulating boundary edges.
     ///
     /// This function always uses the CPU device.
diff --git a/cpp/open3d/t/geometry/kernel/NPPImage.cpp b/cpp/open3d/t/geometry/kernel/NPPImage.cpp
index 7cdaa962852..b2f7dce0f82 100644
--- a/cpp/open3d/t/geometry/kernel/NPPImage.cpp
+++ b/cpp/open3d/t/geometry/kernel/NPPImage.cpp
@@ -80,6 +80,13 @@ static NppStreamContext MakeNPPContext() {
 }
 
 void RGBToGray(const core::Tensor &src_im, core::Tensor &dst_im) {
+    if (src_im.GetDevice() != dst_im.GetDevice()) {
+        utility::LogError(
+                "src_im and dst_im are not on the same device, got {} and {}.",
+                src_im.GetDevice().ToString(), dst_im.GetDevice().ToString());
+    }
+    core::CUDAScopedDevice scoped_device(src_im.GetDevice());
+
     NppiSize size_ROI = {static_cast<int>(dst_im.GetShape(1)),
                          static_cast<int>(dst_im.GetShape(0))};
 
@@ -109,6 +116,13 @@ void RGBToGray(const core::Tensor &src_im, core::Tensor &dst_im) {
 void Resize(const open3d::core::Tensor &src_im,
             open3d::core::Tensor &dst_im,
             t::geometry::Image::InterpType interp_type) {
+    if (src_im.GetDevice() != dst_im.GetDevice()) {
+        utility::LogError(
+                "src_im and dst_im are not on the same device, got {} and {}.",
+                src_im.GetDevice().ToString(), dst_im.GetDevice().ToString());
+    }
+    core::CUDAScopedDevice scoped_device(src_im.GetDevice());
+
     // Supported device and datatype checking happens in calling code and will
     // result in an exception if there are errors.
     NppiSize src_size = {static_cast<int>(src_im.GetShape(1)),
@@ -180,6 +194,12 @@ void Resize(const open3d::core::Tensor &src_im,
 }
 
 void Dilate(const core::Tensor &src_im, core::Tensor &dst_im, int kernel_size) {
+    if (src_im.GetDevice() != dst_im.GetDevice()) {
+        utility::LogError(
+                "src_im and dst_im are not on the same device, got {} and {}.",
+                src_im.GetDevice().ToString(), dst_im.GetDevice().ToString());
+    }
+    core::CUDAScopedDevice scoped_device(src_im.GetDevice());
     // Supported device and datatype checking happens in calling code and will
     // result in an exception if there are errors.
 
@@ -244,6 +264,13 @@ void Dilate(const core::Tensor &src_im, core::Tensor &dst_im, int kernel_size) {
 void Filter(const open3d::core::Tensor &src_im,
             open3d::core::Tensor &dst_im,
             const open3d::core::Tensor &kernel) {
+    if (src_im.GetDevice() != dst_im.GetDevice()) {
+        utility::LogError(
+                "src_im and dst_im are not on the same device, got {} and {}.",
+                src_im.GetDevice().ToString(), dst_im.GetDevice().ToString());
+    }
+    core::CUDAScopedDevice scoped_device(src_im.GetDevice());
+
     // Supported device and datatype checking happens in calling code and will
     // result in an exception if there are errors.
     NppiSize src_size = {static_cast<int>(src_im.GetShape(1)),
@@ -312,6 +339,13 @@ void FilterBilateral(const core::Tensor &src_im,
                      int kernel_size,
                      float value_sigma,
                      float distance_sigma) {
+    if (src_im.GetDevice() != dst_im.GetDevice()) {
+        utility::LogError(
+                "src_im and dst_im are not on the same device, got {} and {}.",
+                src_im.GetDevice().ToString(), dst_im.GetDevice().ToString());
+    }
+    core::CUDAScopedDevice scoped_device(src_im.GetDevice());
+
     // Supported device and datatype checking happens in calling code and will
     // result in an exception if there are errors.
     NppiSize src_size = {static_cast<int>(src_im.GetShape(1)),
@@ -363,6 +397,13 @@ void FilterGaussian(const core::Tensor &src_im,
                     core::Tensor &dst_im,
                     int kernel_size,
                     float sigma) {
+    if (src_im.GetDevice() != dst_im.GetDevice()) {
+        utility::LogError(
+                "src_im and dst_im are not on the same device, got {} and {}.",
+                src_im.GetDevice().ToString(), dst_im.GetDevice().ToString());
+    }
+    core::CUDAScopedDevice scoped_device(src_im.GetDevice());
+
     // Generate separable kernel weights given the sigma value.
     core::Tensor dist =
             core::Tensor::Arange(static_cast<float>(-kernel_size / 2),
@@ -384,6 +425,16 @@ void FilterSobel(const core::Tensor &src_im,
                  core::Tensor &dst_im_dx,
                  core::Tensor &dst_im_dy,
                  int kernel_size) {
+    if (src_im.GetDevice() != dst_im_dx.GetDevice() ||
+        src_im.GetDevice() != dst_im_dy.GetDevice()) {
+        utility::LogError(
+                "src_im, dst_im_dx, and dst_im_dy are not on the same device, "
+                "got {}, {} and {}.",
+                src_im.GetDevice().ToString(), dst_im_dx.GetDevice().ToString(),
+                dst_im_dy.GetDevice().ToString());
+    }
+    core::CUDAScopedDevice scoped_device(src_im.GetDevice());
+
     // Supported device and datatype checking happens in calling code and will
     // result in an exception if there are errors.
     NppiSize src_size = {static_cast<int>(src_im.GetShape(1)),
diff --git a/cpp/open3d/t/geometry/kernel/PointCloud.cpp b/cpp/open3d/t/geometry/kernel/PointCloud.cpp
index b9d6984e03b..fc0baae925c 100644
--- a/cpp/open3d/t/geometry/kernel/PointCloud.cpp
+++ b/cpp/open3d/t/geometry/kernel/PointCloud.cpp
@@ -141,6 +141,31 @@ void GetPointMaskWithinAABB(const core::Tensor& points,
     }
 }
 
+void GetPointMaskWithinOBB(const core::Tensor& points,
+                           const core::Tensor& center,
+                           const core::Tensor& rotation,
+                           const core::Tensor& extent,
+                           core::Tensor& mask) {
+    core::AssertTensorShape(mask, {points.GetLength()});
+    core::AssertTensorDtype(mask, core::Bool);
+
+    // Convert points, center, rotation and extent into contiguous Tensor.
+    const core::Tensor center_d = center.Contiguous();
+    const core::Tensor rotation_d = rotation.Contiguous();
+    const core::Tensor extent_d = extent.Contiguous();
+    const core::Tensor points_d = points.Contiguous();
+
+    if (mask.IsCPU()) {
+        GetPointMaskWithinOBBCPU(points_d, center_d, rotation_d, extent_d,
+                                 mask);
+    } else if (mask.IsCUDA()) {
+        CUDA_CALL(GetPointMaskWithinOBBCUDA, points_d, center_d, rotation_d,
+                  extent_d, mask);
+    } else {
+        utility::LogError("Unimplemented device");
+    }
+}
+
 }  // namespace pointcloud
 }  // namespace kernel
 }  // namespace geometry
diff --git a/cpp/open3d/t/geometry/kernel/PointCloudImpl.h b/cpp/open3d/t/geometry/kernel/PointCloudImpl.h
index 4f80016f6ef..18123c6312d 100644
--- a/cpp/open3d/t/geometry/kernel/PointCloudImpl.h
+++ b/cpp/open3d/t/geometry/kernel/PointCloudImpl.h
@@ -34,6 +34,7 @@
 #include "open3d/core/ParallelFor.h"
 #include "open3d/core/SizeVector.h"
 #include "open3d/core/Tensor.h"
+#include "open3d/core/linalg/kernel/Matrix.h"
 #include "open3d/core/linalg/kernel/SVD3x3.h"
 #include "open3d/core/nns/NearestNeighborSearch.h"
 #include "open3d/t/geometry/Utility.h"
@@ -163,7 +164,7 @@ void GetPointMaskWithinAABBCPU
          const core::Tensor& max_bound,
          core::Tensor& mask) {
 
-    DISPATCH_DTYPE_TO_TEMPLATE(points.GetDtype(), [&]() {
+    DISPATCH_FLOAT_DTYPE_TO_TEMPLATE(points.GetDtype(), [&]() {
         const scalar_t* points_ptr = points.GetDataPtr<scalar_t>();
         const int64_t n = points.GetLength();
         const scalar_t* min_bound_ptr = min_bound.GetDataPtr<scalar_t>();
@@ -187,6 +188,50 @@ void GetPointMaskWithinAABBCPU
     });
 }
 
+#if defined(__CUDACC__)
+void GetPointMaskWithinOBBCUDA
+#else
+void GetPointMaskWithinOBBCPU
+#endif
+        (const core::Tensor& points,
+         const core::Tensor& center,
+         const core::Tensor& rotation,
+         const core::Tensor& extent,
+         core::Tensor& mask) {
+    const core::Tensor half_extent = extent.Div(2);
+    // Since we will extract 3 rotation axis from matrix and use it inside
+    // kernel, the transpose is needed.
+    const core::Tensor rotation_t = rotation.Transpose(0, 1).Contiguous();
+    const core::Tensor pd = points - center;
+    const int64_t n = points.GetLength();
+
+    DISPATCH_FLOAT_DTYPE_TO_TEMPLATE(points.GetDtype(), [&]() {
+        const scalar_t* pd_ptr = pd.GetDataPtr<scalar_t>();
+        // const scalar_t* center_ptr = center.GetDataPtr<scalar_t>();
+        const scalar_t* rotation_ptr = rotation_t.GetDataPtr<scalar_t>();
+        const scalar_t* half_extent_ptr = half_extent.GetDataPtr<scalar_t>();
+        bool* mask_ptr = mask.GetDataPtr<bool>();
+
+        core::ParallelFor(points.GetDevice(), n,
+                          [=] OPEN3D_DEVICE(int64_t workload_idx) {
+                              int64_t idx = 3 * workload_idx;
+                              if (abs(core::linalg::kernel::dot_3x1(
+                                          pd_ptr + idx, rotation_ptr)) <=
+                                          half_extent_ptr[0] &&
+                                  abs(core::linalg::kernel::dot_3x1(
+                                          pd_ptr + idx, rotation_ptr + 3)) <=
+                                          half_extent_ptr[1] &&
+                                  abs(core::linalg::kernel::dot_3x1(
+                                          pd_ptr + idx, rotation_ptr + 6)) <=
+                                          half_extent_ptr[2]) {
+                                  mask_ptr[workload_idx] = true;
+                              } else {
+                                  mask_ptr[workload_idx] = false;
+                              }
+                          });
+    });
+}
+
 #if defined(__CUDACC__)
 void NormalizeNormalsCUDA
 #else
@@ -310,11 +355,11 @@ template <typename scalar_t>
 OPEN3D_HOST_DEVICE void GetCoordinateSystemOnPlane(const scalar_t* query,
                                                    scalar_t* u,
                                                    scalar_t* v) {
-    // Unless the x and y coords are both close to zero, we can simply take (
-    // -y, x, 0 ) and normalize it.
-    // If both x and y are close to zero, then the vector is close to the
-    // z-axis, so it's far from colinear to the x-axis for instance. So we
-    // take the crossed product with (1,0,0) and normalize it.
+    // Unless the x and y coords are both close to zero, we can simply take
+    // ( -y, x, 0 ) and normalize it. If both x and y are close to zero,
+    // then the vector is close to the z-axis, so it's far from colinear to
+    // the x-axis for instance. So we take the crossed product with (1,0,0)
+    // and normalize it.
     if (!(abs(query[0] - query[2]) < 1e-6) ||
         !(abs(query[1] - query[2]) < 1e-6)) {
         const scalar_t norm2_inv =
@@ -398,7 +443,6 @@ void ComputeBoundaryPointsCPU
          const core::Tensor& counts,
          core::Tensor& mask,
          double angle_threshold) {
-
     const int nn_size = indices.GetShape()[1];
 
     DISPATCH_FLOAT_DTYPE_TO_TEMPLATE(points.GetDtype(), [&]() {
diff --git a/cpp/open3d/t/io/TriangleMeshIO.h b/cpp/open3d/t/io/TriangleMeshIO.h
index 04817646557..c5d21c7190b 100644
--- a/cpp/open3d/t/io/TriangleMeshIO.h
+++ b/cpp/open3d/t/io/TriangleMeshIO.h
@@ -40,9 +40,14 @@ namespace io {
 std::shared_ptr<geometry::TriangleMesh> CreateMeshFromFile(
         const std::string &filename, bool print_progress = false);
 
-/// The general entrance for reading a TriangleMesh from a file
+/// The general entrance for reading a TriangleMesh from a file.
 /// The function calls read functions based on the extension name of filename.
-/// \return return true if the read function is successful, false otherwise.
+/// Supported formats are \c obj,ply,stl,off,gltf,glb,fbx .
+/// \param filename Path to the mesh file.
+/// \param mesh Output parameter for the mesh.
+/// \param params Additional read options to enable post-processing or progress
+/// reporting. \return return true if the read function is successful, false
+/// otherwise.
 bool ReadTriangleMesh(const std::string &filename,
                       geometry::TriangleMesh &mesh,
                       open3d::io::ReadTriangleMeshOptions params = {});
diff --git a/cpp/open3d/t/io/file_format/FileASSIMP.cpp b/cpp/open3d/t/io/file_format/FileASSIMP.cpp
index 2c1b1b975db..4afd6a5836f 100644
--- a/cpp/open3d/t/io/file_format/FileASSIMP.cpp
+++ b/cpp/open3d/t/io/file_format/FileASSIMP.cpp
@@ -81,9 +81,13 @@ bool ReadTriangleMeshUsingASSIMP(
     std::vector<core::Tensor> mesh_vertices;
     std::vector<core::Tensor> mesh_vertex_normals;
     std::vector<core::Tensor> mesh_faces;
+    std::vector<core::Tensor> mesh_vertex_colors;
+    std::vector<core::Tensor> mesh_uvs;
 
     size_t current_vidx = 0;
     size_t count_mesh_with_normals = 0;
+    size_t count_mesh_with_colors = 0;
+    size_t count_mesh_with_uvs = 0;
 
     // Merge individual meshes in aiScene into a single TriangleMesh
     for (size_t midx = 0; midx < scene->mNumMeshes; ++midx) {
@@ -92,24 +96,36 @@ bool ReadTriangleMeshUsingASSIMP(
         core::Tensor vertices = core::Tensor::Empty(
                 {assimp_mesh->mNumVertices, 3}, core::Dtype::Float32);
         auto vertices_ptr = vertices.GetDataPtr<float>();
+        std::memcpy(vertices_ptr, assimp_mesh->mVertices,
+                    3 * assimp_mesh->mNumVertices * sizeof(float));
+        mesh_vertices.push_back(vertices);
 
         core::Tensor vertex_normals;
+        core::Tensor vertex_colors;
+        core::Tensor triangle_uvs;
         if (assimp_mesh->mNormals) {
             // Loop fusion for performance optimization.
-            vertex_normals = core::Tensor::Empty({assimp_mesh->mNumFaces, 3},
+            vertex_normals = core::Tensor::Empty({assimp_mesh->mNumVertices, 3},
                                                  core::Dtype::Float32);
-            auto vertex_normals_ptr = vertices.GetDataPtr<float>();
-            std::memcpy(vertices_ptr, assimp_mesh->mVertices,
-                        3 * assimp_mesh->mNumVertices * sizeof(float));
+            auto vertex_normals_ptr = vertex_normals.GetDataPtr<float>();
             std::memcpy(vertex_normals_ptr, assimp_mesh->mNormals,
                         3 * assimp_mesh->mNumVertices * sizeof(float));
             mesh_vertex_normals.push_back(vertex_normals);
             count_mesh_with_normals++;
-        } else {
-            std::memcpy(vertices_ptr, assimp_mesh->mVertices,
-                        3 * assimp_mesh->mNumVertices * sizeof(float));
         }
-        mesh_vertices.push_back(vertices);
+
+        if (assimp_mesh->HasVertexColors(0)) {
+            vertex_colors = core::Tensor::Empty({assimp_mesh->mNumVertices, 3},
+                                                core::Dtype::Float32);
+            auto vertex_colors_ptr = vertex_colors.GetDataPtr<float>();
+            for (unsigned int i = 0; i < assimp_mesh->mNumVertices; ++i) {
+                *vertex_colors_ptr++ = assimp_mesh->mColors[0][i].r;
+                *vertex_colors_ptr++ = assimp_mesh->mColors[0][i].g;
+                *vertex_colors_ptr++ = assimp_mesh->mColors[0][i].b;
+            }
+            mesh_vertex_colors.push_back(vertex_colors);
+            count_mesh_with_colors++;
+        }
 
         core::Tensor faces = core::Tensor::Empty({assimp_mesh->mNumFaces, 3},
                                                  core::Dtype::Int64);
@@ -125,6 +141,20 @@ bool ReadTriangleMeshUsingASSIMP(
 
         mesh_faces.push_back(faces);
 
+        if (assimp_mesh->HasTextureCoords(0)) {
+            auto vertex_uvs = core::Tensor::Empty(
+                    {assimp_mesh->mNumVertices, 2}, core::Dtype::Float32);
+            auto uvs_ptr = vertex_uvs.GetDataPtr<float>();
+            // NOTE: Can't just memcpy because ASSIMP UVs are 3 element and
+            // TriangleMesh wants 2 element UVs.
+            for (int i = 0; i < (int)assimp_mesh->mNumVertices; ++i) {
+                *uvs_ptr++ = assimp_mesh->mTextureCoords[0][i].x;
+                *uvs_ptr++ = assimp_mesh->mTextureCoords[0][i].y;
+            }
+            triangle_uvs = vertex_uvs.IndexGet({faces});
+            mesh_uvs.push_back(triangle_uvs);
+            count_mesh_with_uvs++;
+        }
         // Adjust face indices to index into combined mesh vertex array
         current_vidx += static_cast<int>(assimp_mesh->mNumVertices);
     }
@@ -133,15 +163,31 @@ bool ReadTriangleMeshUsingASSIMP(
     if (scene->mNumMeshes > 1) {
         mesh.SetVertexPositions(core::Concatenate(mesh_vertices));
         mesh.SetTriangleIndices(core::Concatenate(mesh_faces));
+        // NOTE: For objects with multiple meshes we only store normals, colors,
+        // and uvs if every mesh in the object had them. Mesh class does not
+        // support some vertices having normals/colors/uvs and some not having
+        // them.
         if (count_mesh_with_normals == scene->mNumMeshes) {
             mesh.SetVertexNormals(core::Concatenate(mesh_vertex_normals));
         }
+        if (count_mesh_with_colors == scene->mNumMeshes) {
+            mesh.SetVertexColors(core::Concatenate(mesh_vertex_colors));
+        }
+        if (count_mesh_with_uvs == scene->mNumMeshes) {
+            mesh.SetTriangleAttr("texture_uvs", core::Concatenate(mesh_uvs));
+        }
     } else {
         mesh.SetVertexPositions(mesh_vertices[0]);
         mesh.SetTriangleIndices(mesh_faces[0]);
-        if (count_mesh_with_normals) {
+        if (count_mesh_with_normals > 0) {
             mesh.SetVertexNormals(mesh_vertex_normals[0]);
         }
+        if (count_mesh_with_colors > 0) {
+            mesh.SetVertexColors(mesh_vertex_colors[0]);
+        }
+        if (count_mesh_with_uvs > 0) {
+            mesh.SetTriangleAttr("texture_uvs", mesh_uvs[0]);
+        }
     }
 
     return true;
diff --git a/cpp/open3d/t/pipelines/kernel/Feature.cpp b/cpp/open3d/t/pipelines/kernel/Feature.cpp
index 7b9ada37bee..dc9c318a188 100644
--- a/cpp/open3d/t/pipelines/kernel/Feature.cpp
+++ b/cpp/open3d/t/pipelines/kernel/Feature.cpp
@@ -26,6 +26,7 @@
 
 #include "open3d/t/pipelines/kernel/Feature.h"
 
+#include "open3d/core/CUDAUtils.h"
 #include "open3d/core/TensorCheck.h"
 
 namespace open3d {
@@ -47,6 +48,7 @@ void ComputeFPFHFeature(const core::Tensor &points,
         ComputeFPFHFeatureCPU(points_d, normals_d, indices, distance2, counts_d,
                               fpfhs);
     } else {
+        core::CUDAScopedDevice scoped_device(points.GetDevice());
         CUDA_CALL(ComputeFPFHFeatureCUDA, points_d, normals_d, indices,
                   distance2, counts_d, fpfhs);
     }
diff --git a/cpp/open3d/t/pipelines/kernel/FillInLinearSystem.cpp b/cpp/open3d/t/pipelines/kernel/FillInLinearSystem.cpp
index 15bf376b8cc..b02931ce2df 100644
--- a/cpp/open3d/t/pipelines/kernel/FillInLinearSystem.cpp
+++ b/cpp/open3d/t/pipelines/kernel/FillInLinearSystem.cpp
@@ -26,6 +26,7 @@
 
 #include "open3d/t/pipelines/kernel/FillInLinearSystem.h"
 
+#include "open3d/core/CUDAUtils.h"
 #include "open3d/core/TensorCheck.h"
 
 namespace open3d {
@@ -72,6 +73,7 @@ void FillInRigidAlignmentTerm(core::Tensor &AtA,
 
     } else if (AtA.IsCUDA()) {
 #ifdef BUILD_CUDA_MODULE
+        core::CUDAScopedDevice scoped_device(AtA.GetDevice());
         FillInRigidAlignmentTermCUDA(AtA, Atb, residual, Ti_ps, Tj_qs,
                                      Ri_normal_ps, i, j, threshold);
 
@@ -133,6 +135,7 @@ void FillInSLACAlignmentTerm(core::Tensor &AtA,
 
     } else if (AtA.IsCUDA()) {
 #ifdef BUILD_CUDA_MODULE
+        core::CUDAScopedDevice scoped_device(AtA.GetDevice());
         FillInSLACAlignmentTermCUDA(AtA, Atb, residual, Ti_ps, Tj_qs, normal_ps,
                                     Ri_normal_ps, RjT_Ri_normal_ps,
                                     cgrid_idx_ps, cgrid_idx_qs, cgrid_ratio_ps,
@@ -173,6 +176,7 @@ void FillInSLACRegularizerTerm(core::Tensor &AtA,
 
     } else if (AtA.IsCUDA()) {
 #ifdef BUILD_CUDA_MODULE
+        core::CUDAScopedDevice scoped_device(AtA.GetDevice());
         FillInSLACRegularizerTermCUDA(
                 AtA, Atb, residual, grid_idx, grid_nbs_idx, grid_nbs_mask,
                 positions_init, positions_curr, weight, n, anchor_idx);
diff --git a/cpp/open3d/t/pipelines/kernel/RGBDOdometry.cpp b/cpp/open3d/t/pipelines/kernel/RGBDOdometry.cpp
index be60286f730..62da11cf161 100644
--- a/cpp/open3d/t/pipelines/kernel/RGBDOdometry.cpp
+++ b/cpp/open3d/t/pipelines/kernel/RGBDOdometry.cpp
@@ -72,6 +72,7 @@ void ComputeOdometryResultPointToPlane(
                 intrinsics_d, trans_d, delta, inlier_residual, inlier_count,
                 depth_outlier_trunc, depth_huber_delta);
     } else if (device.IsCUDA()) {
+        core::CUDAScopedDevice scoped_device(source_vertex_map.GetDevice());
         CUDA_CALL(ComputeOdometryResultPointToPlaneCUDA, source_vertex_map,
                   target_vertex_map, target_normal_map, intrinsics_d, trans_d,
                   delta, inlier_residual, inlier_count, depth_outlier_trunc,
@@ -130,6 +131,7 @@ void ComputeOdometryResultIntensity(const core::Tensor &source_depth,
                 intrinsics_d, trans_d, delta, inlier_residual, inlier_count,
                 depth_outlier_trunc, intensity_huber_delta);
     } else if (device.IsCUDA()) {
+        core::CUDAScopedDevice scoped_device(source_depth.GetDevice());
         CUDA_CALL(ComputeOdometryResultIntensityCUDA, source_depth,
                   target_depth, source_intensity, target_intensity,
                   target_intensity_dx, target_intensity_dy, source_vertex_map,
@@ -197,6 +199,7 @@ void ComputeOdometryResultHybrid(const core::Tensor &source_depth,
                 delta, inlier_residual, inlier_count, depth_outlier_trunc,
                 depth_huber_delta, intensity_huber_delta);
     } else if (device.IsCUDA()) {
+        core::CUDAScopedDevice scoped_device(source_depth.GetDevice());
         CUDA_CALL(ComputeOdometryResultHybridCUDA, source_depth, target_depth,
                   source_intensity, target_intensity, target_depth_dx,
                   target_depth_dy, target_intensity_dx, target_intensity_dy,
diff --git a/cpp/open3d/t/pipelines/kernel/RGBDOdometryCUDA.cu b/cpp/open3d/t/pipelines/kernel/RGBDOdometryCUDA.cu
index e0a4e63faba..c0b6172e678 100644
--- a/cpp/open3d/t/pipelines/kernel/RGBDOdometryCUDA.cu
+++ b/cpp/open3d/t/pipelines/kernel/RGBDOdometryCUDA.cu
@@ -112,6 +112,8 @@ void ComputeOdometryResultPointToPlaneCUDA(
         int& inlier_count,
         const float depth_outlier_trunc,
         const float depth_huber_delta) {
+    core::CUDAScopedDevice scoped_device(source_vertex_map.GetDevice());
+
     NDArrayIndexer source_vertex_indexer(source_vertex_map, 2);
     NDArrayIndexer target_vertex_indexer(target_vertex_map, 2);
     NDArrayIndexer target_normal_indexer(target_normal_map, 2);
@@ -211,6 +213,8 @@ void ComputeOdometryResultIntensityCUDA(
         int& inlier_count,
         const float depth_outlier_trunc,
         const float intensity_huber_delta) {
+    core::CUDAScopedDevice scoped_device(source_depth.GetDevice());
+
     NDArrayIndexer source_depth_indexer(source_depth, 2);
     NDArrayIndexer target_depth_indexer(target_depth, 2);
 
@@ -328,6 +332,8 @@ void ComputeOdometryResultHybridCUDA(const core::Tensor& source_depth,
                                      const float depth_outlier_trunc,
                                      const float depth_huber_delta,
                                      const float intensity_huber_delta) {
+    core::CUDAScopedDevice scoped_device(source_depth.GetDevice());
+
     NDArrayIndexer source_depth_indexer(source_depth, 2);
     NDArrayIndexer target_depth_indexer(target_depth, 2);
 
diff --git a/cpp/open3d/t/pipelines/kernel/Registration.cpp b/cpp/open3d/t/pipelines/kernel/Registration.cpp
index 204b2e6be04..dee6b1d6cb1 100644
--- a/cpp/open3d/t/pipelines/kernel/Registration.cpp
+++ b/cpp/open3d/t/pipelines/kernel/Registration.cpp
@@ -54,6 +54,7 @@ core::Tensor ComputePosePointToPlane(const core::Tensor &source_points,
                 correspondence_indices.Contiguous(), pose, residual,
                 inlier_count, source_points.GetDtype(), device, kernel);
     } else if (source_points.IsCUDA()) {
+        core::CUDAScopedDevice scoped_device(source_points.GetDevice());
         CUDA_CALL(ComputePosePointToPlaneCUDA, source_points.Contiguous(),
                   target_points.Contiguous(), target_normals.Contiguous(),
                   correspondence_indices.Contiguous(), pose, residual,
@@ -94,6 +95,7 @@ core::Tensor ComputePoseColoredICP(const core::Tensor &source_points,
                 inlier_count, source_points.GetDtype(), device, kernel,
                 lambda_geometric);
     } else if (source_points.IsCUDA()) {
+        core::CUDAScopedDevice scoped_device(source_points.GetDevice());
         CUDA_CALL(ComputePoseColoredICPCUDA, source_points.Contiguous(),
                   source_colors.Contiguous(), target_points.Contiguous(),
                   target_normals.Contiguous(), target_colors.Contiguous(),
@@ -130,6 +132,7 @@ std::tuple<core::Tensor, core::Tensor> ComputeRtPointToPoint(
                 source_points.GetDtype(), device);
     } else if (source_points.IsCUDA()) {
 #ifdef BUILD_CUDA_MODULE
+        core::CUDAScopedDevice scoped_device(source_points.GetDevice());
         // TODO: Implement optimized CUDA reduction kernel.
         core::Tensor valid = correspondence_indices.Ne(-1).Reshape({-1});
         // correpondence_set : (i, corres[i]).
@@ -198,6 +201,7 @@ core::Tensor ComputeInformationMatrix(
                 target_points.Contiguous(), correspondence_indices.Contiguous(),
                 information_matrix, target_points.GetDtype(), device);
     } else if (target_points.IsCUDA()) {
+        core::CUDAScopedDevice scoped_device(target_points.GetDevice());
         CUDA_CALL(ComputeInformationMatrixCUDA, target_points.Contiguous(),
                   correspondence_indices.Contiguous(), information_matrix,
                   target_points.GetDtype(), device);
diff --git a/cpp/open3d/t/pipelines/kernel/RegistrationCUDA.cu b/cpp/open3d/t/pipelines/kernel/RegistrationCUDA.cu
index 4980b651fc3..7164d45ecfe 100644
--- a/cpp/open3d/t/pipelines/kernel/RegistrationCUDA.cu
+++ b/cpp/open3d/t/pipelines/kernel/RegistrationCUDA.cu
@@ -107,6 +107,7 @@ void ComputePosePointToPlaneCUDA(const core::Tensor &source_points,
                                  const core::Dtype &dtype,
                                  const core::Device &device,
                                  const registration::RobustKernel &kernel) {
+    core::CUDAScopedDevice scoped_device(source_points.GetDevice());
     int n = source_points.GetLength();
 
     core::Tensor global_sum = core::Tensor::Zeros({29}, dtype, device);
@@ -211,6 +212,7 @@ void ComputePoseColoredICPCUDA(const core::Tensor &source_points,
                                const core::Device &device,
                                const registration::RobustKernel &kernel,
                                const double &lambda_geometric) {
+    core::CUDAScopedDevice scoped_device(source_points.GetDevice());
     int n = source_points.GetLength();
 
     core::Tensor global_sum = core::Tensor::Zeros({29}, dtype, device);
@@ -295,6 +297,7 @@ void ComputeInformationMatrixCUDA(const core::Tensor &target_points,
                                   core::Tensor &information_matrix,
                                   const core::Dtype &dtype,
                                   const core::Device &device) {
+    core::CUDAScopedDevice scoped_device(target_points.GetDevice());
     int n = correspondence_indices.GetLength();
 
     core::Tensor global_sum = core::Tensor::Zeros({21}, dtype, device);
diff --git a/cpp/open3d/t/pipelines/kernel/TransformationConverter.cpp b/cpp/open3d/t/pipelines/kernel/TransformationConverter.cpp
index 6e7690fee1b..f926d0fcb06 100644
--- a/cpp/open3d/t/pipelines/kernel/TransformationConverter.cpp
+++ b/cpp/open3d/t/pipelines/kernel/TransformationConverter.cpp
@@ -28,6 +28,7 @@
 
 #include <cmath>
 
+#include "open3d/core/CUDAUtils.h"
 #include "open3d/core/Dispatch.h"
 #include "open3d/core/Tensor.h"
 #include "open3d/core/TensorCheck.h"
@@ -77,6 +78,7 @@ static void PoseToTransformationDevice(
         PoseToTransformationImpl<scalar_t>(transformation_ptr, pose_ptr);
     } else if (device_type == core::Device::DeviceType::CUDA) {
 #ifdef BUILD_CUDA_MODULE
+        core::CUDAScopedDevice scoped_device(transformation.GetDevice());
         PoseToTransformationCUDA<scalar_t>(transformation_ptr, pose_ptr);
 #else
         utility::LogError("Not compiled with CUDA, but CUDA device is used.");
diff --git a/cpp/open3d/t/pipelines/registration/Registration.cpp b/cpp/open3d/t/pipelines/registration/Registration.cpp
index 06f302f3c9f..e8180c36f4a 100644
--- a/cpp/open3d/t/pipelines/registration/Registration.cpp
+++ b/cpp/open3d/t/pipelines/registration/Registration.cpp
@@ -328,6 +328,8 @@ static std::tuple<RegistrationResult, int> DoSingleScaleICPIterations(
                     criteria.relative_rmse_) {
             break;
         }
+        prev_fitness = result.fitness_;
+        prev_inlier_rmse = result.inlier_rmse_;
     }
     return std::make_tuple(result, prev_iteration_count + iteration_count);
 }
diff --git a/cpp/open3d/utility/IJsonConvertible.cpp b/cpp/open3d/utility/IJsonConvertible.cpp
index 2d4f98f9b25..4c154a5da2a 100644
--- a/cpp/open3d/utility/IJsonConvertible.cpp
+++ b/cpp/open3d/utility/IJsonConvertible.cpp
@@ -47,7 +47,7 @@ Json::Value StringToJson(const std::string &json_str) {
     return json;
 }
 
-std::string JsonToString(const Json::Value json) {
+std::string JsonToString(const Json::Value &json) {
     return Json::writeString(Json::StreamWriterBuilder(), json);
 }
 
diff --git a/cpp/open3d/utility/IJsonConvertible.h b/cpp/open3d/utility/IJsonConvertible.h
index f20eb603eed..8b3d8942da9 100644
--- a/cpp/open3d/utility/IJsonConvertible.h
+++ b/cpp/open3d/utility/IJsonConvertible.h
@@ -26,6 +26,8 @@
 
 #pragma once
 
+#include <fmt/format.h>
+
 #include <Eigen/Core>
 
 #include "open3d/utility/Eigen.h"
@@ -50,7 +52,7 @@ Json::Value StringToJson(const std::string &json_str);
 ///
 /// \param json The Json::Value object to be converted.
 /// \return A string containing the json value.
-std::string JsonToString(const Json::Value json);
+std::string JsonToString(const Json::Value &json);
 
 /// Class IJsonConvertible defines the behavior of a class that can convert
 /// itself to/from a json::Value.
@@ -98,3 +100,20 @@ class IJsonConvertible {
 
 }  // namespace utility
 }  // namespace open3d
+
+namespace fmt {
+template <>
+struct formatter<Json::Value> {
+    template <typename FormatContext>
+    auto format(const Json::Value &value, FormatContext &ctx)
+            -> decltype(ctx.out()) {
+        return format_to(ctx.out(), "{}", open3d::utility::JsonToString(value));
+    }
+
+    template <typename ParseContext>
+    constexpr auto parse(ParseContext &ctx) -> decltype(ctx.begin()) {
+        return ctx.begin();
+    }
+};
+
+}  // namespace fmt
diff --git a/cpp/open3d/visualization/rendering/RendererHandle.h b/cpp/open3d/visualization/rendering/RendererHandle.h
index dbf9d7652a4..2c47cadd590 100644
--- a/cpp/open3d/visualization/rendering/RendererHandle.h
+++ b/cpp/open3d/visualization/rendering/RendererHandle.h
@@ -31,6 +31,7 @@
 #include <array>
 #include <cstdint>
 #include <functional>
+#include <type_traits>
 
 namespace open3d {
 
@@ -173,12 +174,16 @@ class hash<open3d::visualization::rendering::REHandle_abstract> {
 }  // namespace std
 
 namespace fmt {
-using namespace open3d::visualization;
-template <>
-struct formatter<open3d::visualization::rendering::REHandle_abstract> {
+template <typename T>
+struct formatter<
+        T,
+        std::enable_if_t<std::is_base_of<open3d::visualization::rendering::
+                                                 REHandle_abstract,
+                                         T>::value,
+                         char>> {
     template <typename FormatContext>
     auto format(const open3d::visualization::rendering::REHandle_abstract& uid,
-                FormatContext& ctx) {
+                FormatContext& ctx) -> decltype(ctx.out()) {
         return format_to(ctx.out(), "[{}, {}, hash: {}]",
                          open3d::visualization::rendering::REHandle_abstract::
                                  TypeToString(uid.type),
@@ -186,7 +191,7 @@ struct formatter<open3d::visualization::rendering::REHandle_abstract> {
     }
 
     template <typename ParseContext>
-    constexpr auto parse(ParseContext& ctx) {
+    constexpr auto parse(ParseContext& ctx) -> decltype(ctx.begin()) {
         return ctx.begin();
     }
 };
diff --git a/cpp/pybind/core/tensor.cpp b/cpp/pybind/core/tensor.cpp
index ac5a2bdd3af..171e8cb6e49 100644
--- a/cpp/pybind/core/tensor.cpp
+++ b/cpp/pybind/core/tensor.cpp
@@ -860,6 +860,7 @@ inputs data copied.
     tensor.def("cos_", &Tensor::Cos_);
     tensor.def("neg", &Tensor::Neg);
     tensor.def("neg_", &Tensor::Neg_);
+    tensor.def("__neg__", &Tensor::Neg);
     tensor.def("exp", &Tensor::Exp);
     tensor.def("exp_", &Tensor::Exp_);
     tensor.def("abs", &Tensor::Abs);
diff --git a/cpp/pybind/make_python_package.cmake b/cpp/pybind/make_python_package.cmake
index 2e5285a173e..dee6e394d36 100644
--- a/cpp/pybind/make_python_package.cmake
+++ b/cpp/pybind/make_python_package.cmake
@@ -50,14 +50,6 @@ configure_file("${PYTHON_PACKAGE_SRC_DIR}/tools/cli.py"
                "${PYTHON_PACKAGE_DST_DIR}/open3d/tools/cli.py")
 configure_file("${PYTHON_PACKAGE_SRC_DIR}/tools/app.py"
                "${PYTHON_PACKAGE_DST_DIR}/open3d/app.py")
-configure_file("${PYTHON_PACKAGE_SRC_DIR}/open3d/visualization/__init__.py"
-               "${PYTHON_PACKAGE_DST_DIR}/open3d/visualization/__init__.py")
-configure_file("${PYTHON_PACKAGE_SRC_DIR}/open3d/visualization/app/__init__.py"
-               "${PYTHON_PACKAGE_DST_DIR}/open3d/visualization/app/__init__.py")
-configure_file("${PYTHON_PACKAGE_SRC_DIR}/open3d/visualization/gui/__init__.py"
-               "${PYTHON_PACKAGE_DST_DIR}/open3d/visualization/gui/__init__.py")
-configure_file("${PYTHON_PACKAGE_SRC_DIR}/open3d/visualization/rendering/__init__.py"
-               "${PYTHON_PACKAGE_DST_DIR}/open3d/visualization/rendering/__init__.py")
 configure_file("${PYTHON_PACKAGE_SRC_DIR}/open3d/web_visualizer.py"
                "${PYTHON_PACKAGE_DST_DIR}/open3d/web_visualizer.py")
 configure_file("${PYTHON_PACKAGE_SRC_DIR}/js/lib/web_visualizer.js"
diff --git a/cpp/pybind/pipelines/odometry/odometry.cpp b/cpp/pybind/pipelines/odometry/odometry.cpp
index fdeeaab1328..479aaf19cc4 100644
--- a/cpp/pybind/pipelines/odometry/odometry.cpp
+++ b/cpp/pybind/pipelines/odometry/odometry.cpp
@@ -127,6 +127,18 @@ void pybind_odometry_classes(py::module &m) {
                     m, "RGBDOdometryJacobian",
                     "Base class that computes Jacobian from two RGB-D images.");
 
+    jacobian.def(
+            "compute_jacobian_and_residual",
+            &RGBDOdometryJacobian::ComputeJacobianAndResidual,
+            py::call_guard<py::gil_scoped_release>(),
+            "Function to compute i-th row of J and r the vector form of J_r is "
+            "basically 6x1 matrix, but it can be easily extendable to 6xn "
+            "matrix. See RGBDOdometryJacobianFromHybridTerm for this case."
+            "row"_a,
+            "J_r"_a, "r"_a, "w"_a, "source"_a, "target"_a, "source_xyz"_a,
+            "target_dx"_a, "target_dy"_a, "intrinsic"_a, "extrinsic"_a,
+            "corresps"_a);
+
     // open3d.odometry.RGBDOdometryJacobianFromColorTerm: RGBDOdometryJacobian
     py::class_<RGBDOdometryJacobianFromColorTerm,
                PyRGBDOdometryJacobian<RGBDOdometryJacobianFromColorTerm>,
@@ -201,6 +213,24 @@ void pybind_odometry_methods(py::module &m) {
                      ").``"},
                     {"option", "Odometry hyper parameters."},
             });
+
+    m.def("compute_correspondence", &ComputeCorrespondence,
+          py::call_guard<py::gil_scoped_release>(),
+          "Function to estimate point to point correspondences from two depth "
+          "images. A vector of u_s, v_s, u_t, v_t which maps the 2d "
+          "coordinates of source to target.",
+          "intrinsic_matrix"_a, "extrinsic"_a, "depth_s"_a, "depth_t"_a,
+          "option"_a = OdometryOption());
+    docstring::FunctionDocInject(
+            m, "compute_correspondence",
+            {
+                    {"intrinsic_matrix", "Camera intrinsic parameters."},
+                    {"extrinsic",
+                     "Estimation of transform from source to target."},
+                    {"depth_s", "Source depth image."},
+                    {"depth_t", "Target depth image."},
+                    {"option", "Odometry hyper parameters."},
+            });
 }
 
 void pybind_odometry(py::module &m) {
diff --git a/cpp/pybind/t/geometry/boundingvolume.cpp b/cpp/pybind/t/geometry/boundingvolume.cpp
index bbb6698a2dc..6c2fd4ab768 100644
--- a/cpp/pybind/t/geometry/boundingvolume.cpp
+++ b/cpp/pybind/t/geometry/boundingvolume.cpp
@@ -68,18 +68,22 @@ axes.
              "device.");
     aabb.def(py::init<const core::Tensor&, const core::Tensor&>(),
              "min_bound"_a, "max_bound"_a,
-             R"(Construct an  axis-aligned box from min/max bound.
+             R"(Construct an axis-aligned box from min/max bound.
 The axis-aligned box will be created on the device of the given bound 
 tensor, which must be on the same device and have the same data type.)");
     docstring::ClassMethodDocInject(
             m, "AxisAlignedBoundingBox", "__init__",
             {{"min_bound",
               "Lower bounds of the bounding box for all axes. Tensor with {3,} "
-              "shape, and type float32 or float64"},
+              "shape, and type float32 or float64."},
              {"max_bound",
               "Upper bounds of the bounding box for all axes. Tensor with {3,} "
-              "shape, and type float32 or float64"}});
+              "shape, and type float32 or float64."}});
 
+    aabb.def_property_readonly(
+            "dtype", &AxisAlignedBoundingBox::GetDtype,
+            "Returns the data type attribute of this AxisAlignedBoundingBox.");
+    py::detail::bind_copy_functions<AxisAlignedBoundingBox>(aabb);
     aabb.def("__repr__", &AxisAlignedBoundingBox::ToString);
     aabb.def(
             "__add__",
@@ -120,12 +124,15 @@ The device of ohter box must be the same as the device of the current box.)");
              "Set the upper bound of the axis-aligned box.", "max_bound"_a);
     aabb.def("set_color", &AxisAlignedBoundingBox::SetColor,
              "Set the color of the axis-aligned box.", "color"_a);
-    aabb.def("get_min_bound", &AxisAlignedBoundingBox::GetMinBound,
-             "Returns the min bound for box coordinates.");
-    aabb.def("get_max_bound", &AxisAlignedBoundingBox::GetMaxBound,
-             "Returns the max bound for box coordinates.");
-    aabb.def("get_color", &AxisAlignedBoundingBox::GetColor,
-             "Returns the color for box.");
+
+    aabb.def_property_readonly("min_bound",
+                               &AxisAlignedBoundingBox::GetMinBound,
+                               "Returns the min bound for box coordinates.");
+    aabb.def_property_readonly("max_bound",
+                               &AxisAlignedBoundingBox::GetMaxBound,
+                               "Returns the max bound for box coordinates.");
+    aabb.def_property_readonly("color", &AxisAlignedBoundingBox::GetColor,
+                               "Returns the color for box.");
     aabb.def("get_center", &AxisAlignedBoundingBox::GetCenter,
              "Returns the center for box coordinates.");
 
@@ -139,8 +146,9 @@ box.
 If \f$mi\f$ is the min_bound and \f$ma\f$ is the max_bound of the axis aligned
 bounding box, and \f$s\f$ and \f$c\f$ are the provided scaling factor and 
 center respectively, then the new min_bound and max_bound are given by
-\f$mi = c + s (mi - c)\f$ and \f$ma = c + s (ma - c)\f$.)",
-             "scale"_a, "center"_a);
+\f$mi = c + s (mi - c)\f$ and \f$ma = c + s (ma - c)\f$.
+The scaling center will be the box center if it is not specified.)",
+             "scale"_a, "center"_a = utility::nullopt);
 
     aabb.def("get_extent", &AxisAlignedBoundingBox::GetExtent,
              "Get the extent/length of the bounding box in x, y, and z "
@@ -161,6 +169,9 @@ center respectively, then the new min_bound and max_bound are given by
 
     aabb.def("to_legacy", &AxisAlignedBoundingBox::ToLegacy,
              "Convert to a legacy Open3D axis-aligned box.");
+    aabb.def("get_oriented_bounding_box",
+             &AxisAlignedBoundingBox::GetOrientedBoundingBox,
+             "Convert to an oriented box.");
     aabb.def_static("from_legacy", &AxisAlignedBoundingBox::FromLegacy, "box"_a,
                     "dtype"_a = core::Float32,
                     "device"_a = core::Device("CPU:0"),
@@ -206,6 +217,209 @@ center respectively, then the new min_bound and max_bound are given by
             {{"points",
               "A list of points with data type of float32 or float64 (N x 3 "
               "tensor, where N must be larger than 3)."}});
+
+    py::class_<OrientedBoundingBox, PyGeometry<OrientedBoundingBox>,
+               std::shared_ptr<OrientedBoundingBox>, Geometry, DrawableGeometry>
+            obb(m, "OrientedBoundingBox",
+                R"(A bounding box oriented along an arbitrary frame of reference.
+- (center, rotation, extent): The oriented bounding box is defined by its
+center position, rotation maxtrix and extent.
+    - Usage
+        - OrientedBoundingBox::GetCenter()
+        - OrientedBoundingBox::SetCenter(const core::Tensor &center)
+        - OrientedBoundingBox::GetRotation()
+        - OrientedBoundingBox::SetRotation(const core::Tensor &rotation)
+    - Value tensor of center and extent must have shape {3,}.
+    - Value tensor of rotation must have shape {3, 3}.
+    - Value tensor must have the same data type and device.
+    - Value tensor can only be float32 (default) or float64.
+    - The device of the tensor determines the device of the box.
+
+- color: Color of the bounding box.
+    - Usage
+        - OrientedBoundingBox::GetColor()
+        - OrientedBoundingBox::SetColor(const core::Tensor &color)
+    - Value tensor must have shape {3,}.
+    - Value tensor can only be float32 (default) or float64.
+    - Value tensor can only be range [0.0, 1.0].)");
+    obb.def(py::init<const core::Device&>(), "device"_a = core::Device("CPU:0"),
+            "Construct an empty OrientedBoundingBox on the provided device.");
+    obb.def(py::init<const core::Tensor&, const core::Tensor&,
+                     const core::Tensor&>(),
+            "center"_a, "rotation"_a, "extent"_a,
+            R"(Construct an OrientedBoundingBox from center, rotation and extent. 
+The OrientedBoundingBox will be created on the device of the given tensors, which 
+must be on the same device and have the same data type.)");
+    docstring::ClassMethodDocInject(
+            m, "OrientedBoundingBox", "__init__",
+            {{"center",
+              "Center of the bounding box. Tensor of shape {3,}, and type "
+              "float32 or float64."},
+             {"rotation",
+              "Rotation matrix of the bounding box. Tensor of shape {3, 3}, "
+              "and type float32 or float64."},
+             {"extent",
+              "Extent of the bounding box. Tensor of shape {3,}, and type "
+              "float32 or float64."}});
+    obb.def_property_readonly(
+            "dtype", &OrientedBoundingBox::GetDtype,
+            "Returns the data type attribute of this OrientedBoundingBox.");
+    py::detail::bind_copy_functions<OrientedBoundingBox>(obb);
+    obb.def("__repr__", &OrientedBoundingBox::ToString);
+
+    // Device transfers.
+    obb.def("to", &OrientedBoundingBox::To,
+            "Transfer the oriented box to a specified device.", "device"_a,
+            "copy"_a = false);
+    obb.def("clone", &OrientedBoundingBox::Clone,
+            "Returns copy of the oriented box on the same device.");
+    obb.def(
+            "cpu",
+            [](const OrientedBoundingBox& obb) {
+                return obb.To(core::Device("CPU:0"));
+            },
+            "Transfer the oriented box to CPU. If the oriented box is "
+            "already on CPU, no copy will be performed.");
+    obb.def(
+            "cuda",
+            [](const OrientedBoundingBox& obb, int device_id) {
+                return obb.To(core::Device("CUDA", device_id));
+            },
+            "Transfer the oriented box to a CUDA device. If the oriented box "
+            "is already on the specified CUDA device, no copy will be "
+            "performed.",
+            "device_id"_a = 0);
+
+    obb.def("set_center", &OrientedBoundingBox::SetCenter,
+            "Set the center of the box.", "center"_a);
+    obb.def("set_rotation", &OrientedBoundingBox::SetRotation,
+            "Set the rotation matrix of the box.", "rotation"_a);
+    obb.def("set_extent", &OrientedBoundingBox::SetExtent,
+            "Set the extent of the box.", "extent"_a);
+    obb.def("set_color", &OrientedBoundingBox::SetColor,
+            "Set the color of the oriented box.", "color"_a);
+
+    obb.def_property_readonly("center", &OrientedBoundingBox::GetCenter,
+                              "Returns the center for box.");
+    obb.def_property_readonly("extent", &OrientedBoundingBox::GetExtent,
+                              "Returns the extent for box coordinates.");
+    obb.def_property_readonly("rotation", &OrientedBoundingBox::GetRotation,
+                              "Returns the rotation for box.");
+    obb.def_property_readonly("color", &OrientedBoundingBox::GetColor,
+                              "Returns the color for box.");
+    obb.def("get_min_bound", &OrientedBoundingBox::GetMinBound,
+            "Returns the min bound for box.");
+    obb.def("get_max_bound", &OrientedBoundingBox::GetMaxBound,
+            "Returns the max bound for box.");
+
+    obb.def("translate", &OrientedBoundingBox::Translate, R"(Translate the
+oriented box by the given translation. If relative is true, the translation is
+added to the center of the box. If false, the center will be assigned to the 
+translation.)",
+            "translation"_a, "relative"_a = true);
+    obb.def("rotate", &OrientedBoundingBox::Rotate,
+            R"(Rotate the oriented box by the given rotation matrix. If the
+rotation matrix is not orthogonal, the rotation will no be applied.
+The rotation center will be the box center if it is not specified.)",
+            "rotation"_a, "center"_a = utility::nullopt);
+    obb.def("transform", &OrientedBoundingBox::Transform,
+            "Transform the oriented box by the given transformation matrix.",
+            "transformation"_a);
+    obb.def("scale", &OrientedBoundingBox::Scale, R"(Scale the axis-aligned
+box.
+If \f$mi\f$ is the min_bound and \f$ma\f$ is the max_bound of the axis aligned
+bounding box, and \f$s\f$ and \f$c\f$ are the provided scaling factor and 
+center respectively, then the new min_bound and max_bound are given by
+\f$mi = c + s (mi - c)\f$ and \f$ma = c + s (ma - c)\f$.
+The scaling center will be the box center if it is not specified.)",
+            "scale"_a, "center"_a = utility::nullopt);
+
+    obb.def("volume", &OrientedBoundingBox::Volume,
+            "Returns the volume of the bounding box.");
+    obb.def("get_box_points", &OrientedBoundingBox::GetBoxPoints,
+            "Returns the eight points that define the bounding box. The "
+            "Return tensor has shape {8, 3} and data type same as the box.");
+    obb.def("get_point_indices_within_bounding_box",
+            &OrientedBoundingBox::GetPointIndicesWithinBoundingBox,
+            "Indices to points that are within the bounding box.", "points"_a);
+    obb.def("get_axis_aligned_bounding_box",
+            &OrientedBoundingBox::GetAxisAlignedBoundingBox,
+            " Returns an oriented bounding box from the "
+            "AxisAlignedBoundingBox.");
+
+    obb.def("to_legacy", &OrientedBoundingBox::ToLegacy,
+            "Convert to a legacy Open3D oriented box.");
+    obb.def_static(
+            "from_legacy", &OrientedBoundingBox::FromLegacy, "box"_a,
+            "dtype"_a = core::Float32, "device"_a = core::Device("CPU:0"),
+            "Create an oriented bounding box from the AxisAlignedBoundingBox.");
+    obb.def_static(
+            "create_from_axis_aligned_bounding_box",
+            &OrientedBoundingBox::CreateFromAxisAlignedBoundingBox, "aabb"_a,
+            "Create an OrientedBoundingBox from a legacy Open3D oriented box.");
+    obb.def_static("create_from_points", &OrientedBoundingBox::CreateFromPoints,
+                   R"(Creates an oriented bounding box using a PCA.
+Note that this is only an approximation to the minimum oriented bounding box
+that could be computed for example with O'Rourke's algorithm 
+(cf. http://cs.smith.edu/~jorourke/Papers/MinVolBox.pdf, https://www.geometrictools.com/Documentation/MinimumVolumeBox.pdf)
+This is a wrapper for a CPU implementation.)",
+                   "points"_a, "robust"_a = false);
+
+    docstring::ClassMethodDocInject(
+            m, "OrientedBoundingBox", "set_center",
+            {{"center",
+              "Tensor with {3,} shape, and type float32 or float64."}});
+    docstring::ClassMethodDocInject(
+            m, "OrientedBoundingBox", "set_extent",
+            {{"extent",
+              "Tensor with {3,} shape, and type float32 or float64."}});
+    docstring::ClassMethodDocInject(
+            m, "OrientedBoundingBox", "set_rotation",
+            {{"rotation",
+              "Tensor with {3, 3} shape, and type float32 or float64."}});
+    docstring::ClassMethodDocInject(
+            m, "OrientedBoundingBox", "set_color",
+            {{"color",
+              "Tensor with {3,} shape, and type float32 or float64, with "
+              "values in range [0.0, 1.0]."}});
+    docstring::ClassMethodDocInject(
+            m, "OrientedBoundingBox", "translate",
+            {{"translation",
+              "Translation tensor of shape {3,}, type float32 or float64, "
+              "device same as the box."},
+             {"relative", "Whether to perform relative translation."}});
+    docstring::ClassMethodDocInject(
+            m, "OrientedBoundingBox", "rotate",
+            {{"rotation",
+              "Rotation matrix of shape {3, 3}, type float32 or float64, "
+              "device same as the box."},
+             {"center",
+              "Center of the rotation, default is null, which means use center "
+              "of the box as rotation center."}});
+    docstring::ClassMethodDocInject(
+            m, "OrientedBoundingBox", "scale",
+            {{"scale", "The scale parameter."},
+             {"center",
+              "Center used for the scaling operation. Tensor with {3,} shape, "
+              "and type float32 or float64"}});
+    docstring::ClassMethodDocInject(
+            m, "OrientedBoundingBox", "get_point_indices_within_bounding_box",
+            {{"points",
+              "Tensor with {N, 3} shape, and type float32 or float64."}});
+    docstring::ClassMethodDocInject(
+            m, "OrientedBoundingBox", "create_from_axis_aligned_bounding_box",
+            {{"aabb",
+              "AxisAlignedBoundingBox object from which OrientedBoundingBox is "
+              "created."}});
+    docstring::ClassMethodDocInject(
+            m, "OrientedBoundingBox", "create_from_points",
+            {{"points",
+              "A list of points with data type of float32 or float64 (N x 3 "
+              "tensor, where N must be larger than 3)."},
+             {"robust",
+              "If set to true uses a more robust method which works in "
+              "degenerate cases but introduces noise to the points "
+              "coordinates."}});
 }
 
 }  // namespace geometry
diff --git a/cpp/pybind/t/geometry/image.cpp b/cpp/pybind/t/geometry/image.cpp
index fe873578812..3fd82206b60 100644
--- a/cpp/pybind/t/geometry/image.cpp
+++ b/cpp/pybind/t/geometry/image.cpp
@@ -101,6 +101,7 @@ void pybind_image(py::module &m) {
                  "tensor"_a);
     docstring::ClassMethodDocInject(m, "Image", "__init__",
                                     map_shared_argument_docstrings);
+    py::detail::bind_copy_functions<Image>(image);
 
     // Pickle support.
     image.def(py::pickle(
diff --git a/cpp/pybind/t/geometry/lineset.cpp b/cpp/pybind/t/geometry/lineset.cpp
index 818175c61ef..635ea35a4d1 100644
--- a/cpp/pybind/t/geometry/lineset.cpp
+++ b/cpp/pybind/t/geometry/lineset.cpp
@@ -110,6 +110,7 @@ and ``device`` as the tensor. The device for ``point_positions`` must be consist
              {"line_indices",
               "A tensor with element shape (2,) and Int dtype."}});
 
+    py::detail::bind_copy_functions<LineSet>(line_set);
     // Pickling support.
     line_set.def(py::pickle(
             [](const LineSet& line_set) {
@@ -260,7 +261,9 @@ transformation as :math:`P = R(P) + t`)");
                  &LineSet::GetAxisAlignedBoundingBox,
                  "Create an axis-aligned bounding box from point attribute "
                  "'positions'.");
-
+    line_set.def("get_oriented_bounding_box", &LineSet::GetOrientedBoundingBox,
+                 "Create an oriented bounding box from point attribute "
+                 "'positions'.");
     line_set.def("extrude_rotation", &LineSet::ExtrudeRotation, "angle"_a,
                  "axis"_a, "resolution"_a = 16, "translation"_a = 0.0,
                  "capping"_a = true,
diff --git a/cpp/pybind/t/geometry/pointcloud.cpp b/cpp/pybind/t/geometry/pointcloud.cpp
index e0c453e8134..6966dd0f542 100644
--- a/cpp/pybind/t/geometry/pointcloud.cpp
+++ b/cpp/pybind/t/geometry/pointcloud.cpp
@@ -127,6 +127,8 @@ The attributes of the point cloud have different levels::
                  "map_keys_to_tensors"_a)
             .def("__repr__", &PointCloud::ToString);
 
+    py::detail::bind_copy_functions<PointCloud>(pointcloud);
+
     // Pickle support.
     pointcloud.def(py::pickle(
             [](const PointCloud& pcd) {
@@ -475,7 +477,7 @@ resulting plane model and inlier indiecs will be made.
                                                  ransac_n=3,
                                                  num_iterations=1000)
         inlier_cloud = pcd.select_by_index(inliers)
-        inlier_cloud.paint_uniform_color([1.0, 0, 0])
+        inlier_cloud = inlier_cloud.paint_uniform_color([1.0, 0, 0])
         outlier_cloud = pcd.select_by_index(inliers, invert=True)
         o3d.visualization.draw([inlier_cloud, outlier_cloud]))");
     pointcloud.def(
@@ -536,9 +538,21 @@ The implementation is inspired by the PCL implementation. Reference:
             "get_axis_aligned_bounding_box",
             &PointCloud::GetAxisAlignedBoundingBox,
             "Create an axis-aligned bounding box from attribute 'positions'.");
-    pointcloud.def("crop", &PointCloud::Crop,
+    pointcloud.def(
+            "get_oriented_bounding_box", &PointCloud::GetOrientedBoundingBox,
+            "Create an oriented bounding box from attribute 'positions'.");
+    pointcloud.def("crop",
+                   (PointCloud(PointCloud::*)(const AxisAlignedBoundingBox&,
+                                              bool) const) &
+                           PointCloud::Crop,
                    "Function to crop pointcloud into output pointcloud.",
                    "aabb"_a, "invert"_a = false);
+    pointcloud.def("crop",
+                   (PointCloud(PointCloud::*)(const OrientedBoundingBox&, bool)
+                            const) &
+                           PointCloud::Crop,
+                   "Function to crop pointcloud into output pointcloud.",
+                   "obb"_a, "invert"_a = false);
 
     docstring::ClassMethodDocInject(m, "PointCloud", "estimate_normals",
                                     map_shared_argument_docstrings);
@@ -606,7 +620,12 @@ The implementation is inspired by the PCL implementation. Reference:
              {"invert",
               "Crop the points outside of the bounding box or inside of the "
               "bounding box."}});
-
+    docstring::ClassMethodDocInject(
+            m, "PointCloud", "crop",
+            {{"obb", "OrientedBoundingBox to crop points."},
+             {"invert",
+              "Crop the points outside of the bounding box or inside of the "
+              "bounding box."}});
     pointcloud.def("extrude_rotation", &PointCloud::ExtrudeRotation, "angle"_a,
                    "axis"_a, "resolution"_a = 16, "translation"_a = 0.0,
                    "capping"_a = true,
diff --git a/cpp/pybind/t/geometry/raycasting_scene.cpp b/cpp/pybind/t/geometry/raycasting_scene.cpp
index 7b1307df799..338f255e755 100644
--- a/cpp/pybind/t/geometry/raycasting_scene.cpp
+++ b/cpp/pybind/t/geometry/raycasting_scene.cpp
@@ -253,9 +253,9 @@ Computes the distance to the surface of the scene.
     A tensor with the distances to the surface. The shape is {..}.
 )doc");
 
-    raycasting_scene.def("compute_signed_distance",
-                         &RaycastingScene::ComputeSignedDistance,
-                         "query_points"_a, "nthreads"_a = 0, R"doc(
+    raycasting_scene.def(
+            "compute_signed_distance", &RaycastingScene::ComputeSignedDistance,
+            "query_points"_a, "nthreads"_a = 0, "nsamples"_a = 1, R"doc(
 Computes the signed distance to the surface of the scene.
 
 This function computes the signed distance to the meshes in the scene.
@@ -274,6 +274,11 @@ the intersections of a rays starting at the query points.
 
     nthreads (int): The number of threads to use. Set to 0 for automatic.
 
+    nsamples (int): The number of rays used for determining the inside.
+        This must be an odd number. The default is 1. Use a higher value if you
+        notice sign flipping, which can occur when rays hit exactly an edge or 
+        vertex in the scene.
+
 Returns:
     A tensor with the signed distances to the surface. The shape is {..}.
     Negative distances mean a point is inside a closed surface.
@@ -281,7 +286,7 @@ the intersections of a rays starting at the query points.
 
     raycasting_scene.def("compute_occupancy",
                          &RaycastingScene::ComputeOccupancy, "query_points"_a,
-                         "nthreads"_a = 0,
+                         "nthreads"_a = 0, "nsamples"_a = 1,
                          R"doc(
 Computes the occupancy at the query point positions.
 
@@ -301,6 +306,11 @@ intersections of a rays starting at the query points.
 
     nthreads (int): The number of threads to use. Set to 0 for automatic.
 
+    nsamples (int): The number of rays used for determining the inside.
+        This must be an odd number. The default is 1. Use a higher value if you
+        notice errors in the occupancy values. Errors can occur when rays hit
+        exactly an edge or vertex in the scene.
+
 Returns:
     A tensor with the occupancy values. The shape is {..}. Values are either 0
     or 1. A point is occupied or inside if the value is 1.
diff --git a/cpp/pybind/t/geometry/trianglemesh.cpp b/cpp/pybind/t/geometry/trianglemesh.cpp
index 85ee9b69b27..31525fe8736 100644
--- a/cpp/pybind/t/geometry/trianglemesh.cpp
+++ b/cpp/pybind/t/geometry/trianglemesh.cpp
@@ -107,6 +107,7 @@ The attributes of the triangle mesh have different levels::
                  "vertex_positions"_a, "triangle_indices"_a)
             .def("__repr__", &TriangleMesh::ToString);
 
+    py::detail::bind_copy_functions<TriangleMesh>(triangle_mesh);
     // Pickle support.
     triangle_mesh.def(py::pickle(
             [](const TriangleMesh& mesh) {
@@ -651,6 +652,10 @@ This function always uses the CPU device.
                       &TriangleMesh::GetAxisAlignedBoundingBox,
                       "Create an axis-aligned bounding box from vertex "
                       "attribute 'positions'.");
+    triangle_mesh.def("get_oriented_bounding_box",
+                      &TriangleMesh::GetOrientedBoundingBox,
+                      "Create an oriented bounding box from vertex attribute "
+                      "'positions'.");
 
     triangle_mesh.def("fill_holes", &TriangleMesh::FillHoles,
                       "hole_size"_a = 1e6,
diff --git a/cpp/pybind/t/io/class_io.cpp b/cpp/pybind/t/io/class_io.cpp
index 6e2d0d91757..951ae6f1ba6 100644
--- a/cpp/pybind/t/io/class_io.cpp
+++ b/cpp/pybind/t/io/class_io.cpp
@@ -161,9 +161,39 @@ void pybind_class_io(py::module &m_io) {
                 return mesh;
             },
             "Function to read TriangleMesh from file", "filename"_a,
-            "enable_post_processing"_a = false, "print_progress"_a = false);
-    docstring::FunctionDocInject(m_io, "read_triangle_mesh",
-                                 map_shared_argument_docstrings);
+            "enable_post_processing"_a = false, "print_progress"_a = false,
+            R"doc(The general entrance for reading a TriangleMesh from a file.
+The function calls read functions based on the extension name of filename.
+Supported formats are `obj, ply, stl, off, gltf, glb, fbx`.
+
+The following example reads a triangle mesh with the .ply extension::
+    import open3d as o3d
+    mesh = o3d.t.io.read_triangle_mesh('mesh.ply')
+
+Args:
+    filename (str): Path to the mesh file.
+    enable_post_processing (bool): If True enables post-processing. 
+        Post-processing will 
+          - triangulate meshes with polygonal faces
+          - remove redundant materials
+          - pretransform vertices
+          - generate face normals if needed
+        
+        For more information see ASSIMPs documentation on the flags
+        `aiProcessPreset_TargetRealtime_Fast, aiProcess_RemoveRedundantMaterials, 
+        aiProcess_OptimizeMeshes, aiProcess_PreTransformVertices`.
+        
+        Note that identical vertices will always be joined regardless of whether
+        post-processing is enabled or not, which changes the number of vertices 
+        in the mesh.
+
+        The `ply`-format is not affected by the post-processing.
+
+    print_progress (bool): If True print the reading progress to the terminal.
+    
+Returns:
+    Returns the mesh object. On failure an empty mesh is returned.
+)doc");
 
     m_io.def(
             "write_triangle_mesh",
diff --git a/cpp/tests/core/CoreTest.cpp b/cpp/tests/core/CoreTest.cpp
index b16f14307d0..441aa48e3e7 100644
--- a/cpp/tests/core/CoreTest.cpp
+++ b/cpp/tests/core/CoreTest.cpp
@@ -55,8 +55,14 @@ std::vector<core::Device> PermuteDevices::TestCases() {
     if (!cpu_devices.empty()) {
         devices.push_back(cpu_devices[0]);
     }
-    if (!cuda_devices.empty()) {
+
+    // Test 0, 1, or 2 CUDA devices.
+    // Testing 2 CUDA devices is necessary for testing device switching.
+    if (cuda_devices.size() == 1) {
+        devices.push_back(cuda_devices[0]);
+    } else if (cuda_devices.size() == 2) {
         devices.push_back(cuda_devices[0]);
+        devices.push_back(cuda_devices[1]);
     }
 
     return devices;
diff --git a/cpp/tests/core/Tensor.cpp b/cpp/tests/core/Tensor.cpp
index c5c271e7cd7..dfbcb5734ab 100644
--- a/cpp/tests/core/Tensor.cpp
+++ b/cpp/tests/core/Tensor.cpp
@@ -686,7 +686,7 @@ TEST_P(TensorPermuteDevices, ToString) {
 
     // 0D
     t = core::Tensor::Ones({}, core::Float32, device);
-    EXPECT_EQ(t.ToString(/*with_suffix=*/false), R"(1.0)");
+    EXPECT_EQ(t.ToString(/*with_suffix=*/false), R"(1)");
     t = core::Tensor::Full({}, std::numeric_limits<float>::quiet_NaN(),
                            core::Float32, device);
     EXPECT_EQ(t.ToString(/*with_suffix=*/false), R"(nan)");
@@ -697,7 +697,7 @@ TEST_P(TensorPermuteDevices, ToString) {
     // 1D float
     t = core::Tensor(std::vector<float>{0, 1, 2, 3, 4}, {5}, core::Float32,
                      device);
-    EXPECT_EQ(t.ToString(/*with_suffix=*/false), R"([0.0 1.0 2.0 3.0 4.0])");
+    EXPECT_EQ(t.ToString(/*with_suffix=*/false), R"([0 1 2 3 4])");
 
     // 1D int
     std::vector<int32_t> vals{0,  1,  2,  3,  4,  5,  6,  7,  8,  9,  10, 11,
@@ -2352,6 +2352,21 @@ TEST_P(TensorPermuteDevices, Neg) {
     EXPECT_EQ(dst.ToFlatVector<int>(), std::vector<int>({1, 0, -2}));
 }
 
+TEST_P(TensorPermuteDevices, UnaryMinus) {
+    core::Device device = GetParam();
+
+    std::vector<float> dst_vals{2, 1, 0, -1, -2, -3};
+    core::Tensor src =
+            core::Tensor::Init<float>({{-2, -1, 0}, {1, 2, 3}}, device);
+    core::Tensor dst = -src;
+    EXPECT_EQ(dst.ToFlatVector<float>(), dst_vals);
+
+    // Also works for int.
+    src = core::Tensor(std::vector<int>{-1, 0, 2}, {1, 3}, core::Int32, device);
+    dst = -src;
+    EXPECT_EQ(dst.ToFlatVector<int>(), std::vector<int>({1, 0, -2}));
+}
+
 TEST_P(TensorPermuteDevices, Exp) {
     core::Device device = GetParam();
 
diff --git a/cpp/tests/t/geometry/BoundingVolume.cpp b/cpp/tests/t/geometry/AxisAlignedBoundingBox.cpp
similarity index 99%
rename from cpp/tests/t/geometry/BoundingVolume.cpp
rename to cpp/tests/t/geometry/AxisAlignedBoundingBox.cpp
index d66f1a09c30..57d29b06c50 100644
--- a/cpp/tests/t/geometry/BoundingVolume.cpp
+++ b/cpp/tests/t/geometry/AxisAlignedBoundingBox.cpp
@@ -24,14 +24,13 @@
 // IN THE SOFTWARE.
 // ----------------------------------------------------------------------------
 
-#include "open3d/t/geometry/BoundingVolume.h"
-
 #include <gmock/gmock.h>
 
 #include "core/CoreTest.h"
 #include "open3d/core/Tensor.h"
 #include "open3d/data/Dataset.h"
 #include "open3d/geometry/BoundingVolume.h"
+#include "open3d/t/geometry/BoundingVolume.h"
 #include "open3d/t/geometry/PointCloud.h"
 #include "open3d/utility/FileSystem.h"
 #include "tests/Tests.h"
diff --git a/cpp/tests/t/geometry/CMakeLists.txt b/cpp/tests/t/geometry/CMakeLists.txt
index 4bef495c688..5fd17122a31 100644
--- a/cpp/tests/t/geometry/CMakeLists.txt
+++ b/cpp/tests/t/geometry/CMakeLists.txt
@@ -4,7 +4,8 @@ target_sources(tests PRIVATE
     PointCloud.cpp
     TensorMap.cpp
     TriangleMesh.cpp
-    BoundingVolume.cpp
+    AxisAlignedBoundingBox.cpp
+    OrientedBoundingBox.cpp
     VoxelBlockGrid.cpp
     VtkUtils.cpp
 )
diff --git a/cpp/tests/t/geometry/OrientedBoundingBox.cpp b/cpp/tests/t/geometry/OrientedBoundingBox.cpp
new file mode 100644
index 00000000000..a52168b1055
--- /dev/null
+++ b/cpp/tests/t/geometry/OrientedBoundingBox.cpp
@@ -0,0 +1,347 @@
+// ----------------------------------------------------------------------------
+// -                        Open3D: www.open3d.org                            -
+// ----------------------------------------------------------------------------
+// The MIT License (MIT)
+//
+// Copyright (c) 2018-2021 www.open3d.org
+//
+// Permission is hereby granted, free of charge, to any person obtaining a copy
+// of this software and associated documentation files (the "Software"), to deal
+// in the Software without restriction, including without limitation the rights
+// to use, copy, modify, merge, publish, distribute, sublicense, and/or sell
+// copies of the Software, and to permit persons to whom the Software is
+// furnished to do so, subject to the following conditions:
+//
+// The above copyright notice and this permission notice shall be included in
+// all copies or substantial portions of the Software.
+//
+// THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR
+// IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,
+// FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE
+// AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER
+// LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING
+// FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS
+// IN THE SOFTWARE.
+// ----------------------------------------------------------------------------
+
+#include <gmock/gmock.h>
+
+#include "core/CoreTest.h"
+#include "open3d/core/Tensor.h"
+#include "open3d/data/Dataset.h"
+#include "open3d/geometry/BoundingVolume.h"
+#include "open3d/t/geometry/BoundingVolume.h"
+#include "open3d/t/geometry/PointCloud.h"
+#include "open3d/utility/FileSystem.h"
+#include "tests/Tests.h"
+
+namespace open3d {
+namespace tests {
+
+class OrientedBoundingBoxPermuteDevices : public PermuteDevices {};
+INSTANTIATE_TEST_SUITE_P(OrientedBoundingBox,
+                         OrientedBoundingBoxPermuteDevices,
+                         testing::ValuesIn(PermuteDevices::TestCases()));
+
+class OrientedBoundingBoxPermuteDevicePairs : public PermuteDevicePairs {};
+INSTANTIATE_TEST_SUITE_P(
+        OrientedBoundingBox,
+        OrientedBoundingBoxPermuteDevicePairs,
+        testing::ValuesIn(OrientedBoundingBoxPermuteDevicePairs::TestCases()));
+
+TEST_P(OrientedBoundingBoxPermuteDevices, ConstructorNoArg) {
+    t::geometry::OrientedBoundingBox obb;
+
+    // Inherited from Geometry3D.
+    EXPECT_EQ(obb.GetGeometryType(),
+              t::geometry::Geometry::GeometryType::OrientedBoundingBox);
+    EXPECT_EQ(obb.Dimension(), 3);
+
+    // Public members.
+    EXPECT_TRUE(obb.IsEmpty());
+    EXPECT_TRUE(obb.GetMinBound().AllClose(
+            core::Tensor::Init<float>({0, 0, 0}, core::Device("CPU:0"))));
+    EXPECT_TRUE(obb.GetMaxBound().AllClose(
+            core::Tensor::Init<float>({0, 0, 0}, core::Device("CPU:0"))));
+    EXPECT_TRUE(obb.GetColor().AllClose(
+            core::Tensor::Init<float>({1, 1, 1}, core::Device("CPU:0"))));
+
+    EXPECT_EQ(obb.GetDevice(), core::Device("CPU:0"));
+
+    // Print Information.
+    EXPECT_EQ(obb.ToString(), "OrientedBoundingBox[Float32, CPU:0]");
+}
+
+TEST_P(OrientedBoundingBoxPermuteDevices, Constructor) {
+    core::Device device = GetParam();
+
+    core::Tensor center = core::Tensor::Init<float>({-1, -1, -1}, device);
+    core::Tensor extent_err = core::Tensor::Init<float>({-1, 1, 1}, device);
+    core::Tensor extent = core::Tensor::Init<float>({2, 2, 2}, device);
+    core::Tensor rotation_err = core::Tensor::Init<float>(
+            {{1, 1, 0}, {0, 1, 0}, {0, 0, 1}}, device);
+    core::Tensor rotation = core::Tensor::Eye(3, core::Float32, device);
+
+    // Attempt to construct with invalid extent and rotation.
+    EXPECT_THROW(t::geometry::OrientedBoundingBox(center, rotation_err, extent),
+                 std::runtime_error);
+    EXPECT_THROW(t::geometry::OrientedBoundingBox(center, rotation, extent_err),
+                 std::runtime_error);
+
+    t::geometry::OrientedBoundingBox obb(center, rotation, extent);
+
+    // Public members.
+    EXPECT_FALSE(obb.IsEmpty());
+    EXPECT_TRUE(obb.GetMinBound().AllClose(
+            core::Tensor::Init<float>({-2, -2, -2}, device)));
+    EXPECT_TRUE(obb.GetMaxBound().AllClose(
+            core::Tensor::Init<float>({0, 0, 0}, device)));
+    EXPECT_TRUE(obb.GetColor().AllClose(
+            core::Tensor::Init<float>({1, 1, 1}, device)));
+
+    EXPECT_EQ(obb.GetDevice(), device);
+}
+
+TEST_P(OrientedBoundingBoxPermuteDevicePairs, CopyDevice) {
+    core::Device dst_device;
+    core::Device src_device;
+    std::tie(dst_device, src_device) = GetParam();
+
+    const core::Dtype dtype = core::Float32;
+
+    core::Tensor center = core::Tensor::Ones({3}, dtype, src_device);
+    core::Tensor extent = core::Tensor::Ones({3}, dtype, src_device) * 2;
+    core::Tensor rotation = core::Tensor::Eye(3, dtype, src_device);
+    core::Tensor color = core::Tensor::Ones({3}, dtype, src_device);
+
+    t::geometry::OrientedBoundingBox obb(center, rotation, extent);
+    obb.SetColor(color);
+
+    // Copy is created on the dst_device.
+    t::geometry::OrientedBoundingBox obb_copy =
+            obb.To(dst_device, /*copy=*/true);
+
+    EXPECT_EQ(obb_copy.GetDevice(), dst_device);
+    EXPECT_EQ(obb_copy.GetExtent().GetDtype(), obb.GetExtent().GetDtype());
+}
+
+TEST_P(OrientedBoundingBoxPermuteDevices, Setters) {
+    core::Device device = GetParam();
+
+    t::geometry::OrientedBoundingBox obb(device);
+
+    core::Tensor center = core::Tensor::Init<float>({-1, -1, -1}, device);
+    core::Tensor extent = core::Tensor::Init<float>({1.0, 1.0, 1.0}, device);
+    core::Tensor rotation = core::Tensor::Init<float>(
+            {{1, 0, 0}, {0, -1, 0}, {0, 0, -1}}, device);
+    core::Tensor color = core::Tensor::Init<float>({0.0, 0.0, 0.0}, device);
+
+    // SetCenter.
+    obb.SetCenter(center);
+    EXPECT_TRUE(obb.GetCenter().AllClose(center));
+
+    // SetExtent.
+    obb.SetExtent(extent);
+    EXPECT_TRUE(obb.GetExtent().AllClose(extent));
+
+    // SetRotation.
+    obb.SetRotation(rotation);
+    EXPECT_TRUE(obb.GetRotation().AllClose(rotation));
+
+    // SetColor.
+    obb.SetColor(color);
+    EXPECT_TRUE(obb.GetColor().AllClose(color));
+}
+
+TEST_P(OrientedBoundingBoxPermuteDevices, Translate) {
+    core::Device device = GetParam();
+
+    core::Tensor center = core::Tensor::Init<float>({-1, -1, -1}, device);
+    core::Tensor extent = core::Tensor::Init<float>({1.0, 1.0, 1.0}, device);
+    core::Tensor rotation = core::Tensor::Init<float>(
+            {{1, 0, 0}, {0, -1, 0}, {0, 0, -1}}, device);
+
+    t::geometry::OrientedBoundingBox obb(center, rotation, extent);
+
+    obb.Translate(core::Tensor::Init<float>({1, 1, 1}, device), true);
+
+    EXPECT_TRUE(obb.GetCenter().AllClose(
+            core::Tensor::Init<float>({0, 0, 0}, device)));
+
+    obb.Translate(core::Tensor::Init<float>({1, 1, 1}, device), false);
+
+    EXPECT_TRUE(obb.GetCenter().AllClose(
+            core::Tensor::Init<float>({1, 1, 1}, device)));
+}
+
+TEST_P(OrientedBoundingBoxPermuteDevices, Rotate) {
+    core::Device device = GetParam();
+
+    core::Tensor center = core::Tensor::Init<float>({-1, -1, -1}, device);
+    core::Tensor extent = core::Tensor::Init<float>({1.0, 1.0, 1.0}, device);
+    core::Tensor rotation = core::Tensor::Eye(3, core::Float32, device);
+
+    t::geometry::OrientedBoundingBox obb(center, rotation, extent);
+    auto obb_copy = obb.Clone();
+
+    core::Tensor rotation_apply = core::Tensor::Init<float>(
+            {{1, 0, 0}, {0, -1, 0}, {0, 0, -1}}, device);
+
+    obb.Rotate(rotation_apply);
+    obb_copy.Rotate(rotation_apply,
+                    core::Tensor::Zeros({3}, core::Float32, device));
+
+    EXPECT_TRUE(obb.GetCenter().AllClose(
+            core::Tensor::Init<float>({-1, -1, -1}, device)));
+    EXPECT_TRUE(obb.GetRotation().AllClose(core::Tensor::Init<float>(
+            {{1, 0, 0}, {0, -1, 0}, {0, 0, -1}}, device)));
+    EXPECT_TRUE(obb_copy.GetCenter().AllClose(
+            core::Tensor::Init<float>({-1, 1, 1}, device)));
+    EXPECT_TRUE(obb_copy.GetRotation().AllClose(core::Tensor::Init<float>(
+            {{1, 0, 0}, {0, -1, 0}, {0, 0, -1}}, device)));
+}
+
+TEST_P(OrientedBoundingBoxPermuteDevices, Transform) {
+    core::Device device = GetParam();
+
+    core::Tensor center = core::Tensor::Init<float>({-1, -1, -1}, device);
+    core::Tensor extent = core::Tensor::Init<float>({1.0, 1.0, 1.0}, device);
+    core::Tensor rotation = core::Tensor::Eye(3, core::Float32, device);
+
+    t::geometry::OrientedBoundingBox obb(center, rotation, extent);
+
+    core::Tensor transformation = core::Tensor::Init<float>(
+            {{1, 0, 0, 1}, {0, -1, 0, 2}, {0, 0, -1, 3}, {0, 0, 0, 1}}, device);
+
+    obb.Transform(transformation);
+
+    EXPECT_TRUE(obb.GetCenter().AllClose(
+            core::Tensor::Init<float>({0, 1, 2}, device)));
+    EXPECT_TRUE(obb.GetRotation().AllClose(core::Tensor::Init<float>(
+            {{1, 0, 0}, {0, -1, 0}, {0, 0, -1}}, device)));
+}
+
+TEST_P(OrientedBoundingBoxPermuteDevices, Scale) {
+    core::Device device = GetParam();
+
+    core::Tensor center = core::Tensor::Init<float>({-1, -1, -1}, device);
+    core::Tensor extent = core::Tensor::Init<float>({1.0, 1.0, 1.0}, device);
+    core::Tensor rotation = core::Tensor::Eye(3, core::Float32, device);
+
+    t::geometry::OrientedBoundingBox obb(center, rotation, extent);
+    auto obb_copy = obb.Clone();
+
+    obb.Scale(2.0);
+    obb_copy.Scale(2.0, core::Tensor::Zeros({3}, core::Float32, device));
+
+    EXPECT_TRUE(obb.GetExtent().AllClose(
+            core::Tensor::Init<float>({2, 2, 2}, device)));
+    EXPECT_TRUE(obb.GetCenter().AllClose(
+            core::Tensor::Init<float>({-1, -1, -1}, device)));
+    EXPECT_TRUE(obb_copy.GetCenter().AllClose(
+            core::Tensor::Init<float>({-2, -2, -2}, device)));
+}
+
+TEST_P(OrientedBoundingBoxPermuteDevices, GetBoxPoints) {
+    core::Device device = GetParam();
+
+    core::Tensor center = core::Tensor::Init<float>({-1, -1, -1}, device);
+    core::Tensor extent = core::Tensor::Init<float>({1.0, 1.0, 1.0}, device);
+    core::Tensor rotation = core::Tensor::Eye(3, core::Float32, device);
+
+    t::geometry::OrientedBoundingBox obb(center, rotation, extent);
+
+    auto box_points = obb.GetBoxPoints();
+
+    EXPECT_TRUE(
+            box_points.AllClose(core::Tensor::Init<float>({{-1.5, -1.5, -1.5},
+                                                           {-0.5, -1.5, -1.5},
+                                                           {-1.5, -0.5, -1.5},
+                                                           {-1.5, -1.5, -0.5},
+                                                           {-0.5, -0.5, -0.5},
+                                                           {-1.5, -0.5, -0.5},
+                                                           {-0.5, -1.5, -0.5},
+                                                           {-0.5, -0.5, -1.5}},
+                                                          device)));
+}
+
+TEST_P(OrientedBoundingBoxPermuteDevices, GetPointIndicesWithinBoundingBox) {
+    core::Device device = GetParam();
+
+    core::Tensor center = core::Tensor::Init<float>({0.5, 0.5, 0.5}, device);
+    core::Tensor rotation = core::Tensor::Eye(3, core::Float32, device);
+    core::Tensor extent = core::Tensor::Init<float>({1, 1, 1}, device);
+    t::geometry::OrientedBoundingBox obb(center, rotation, extent);
+
+    core::Tensor points = core::Tensor::Init<float>({{0.1, 0.3, 0.9},
+                                                     {-0.2, 0.2, 0.5},
+                                                     {0.9, 0.2, 0.4},
+                                                     {0.3, 0.6, 0.8},
+                                                     {0.2, 0.4, 0.2},
+                                                     {1.2, 0.3, 0.5}},
+                                                    device);
+
+    core::Tensor indices = obb.GetPointIndicesWithinBoundingBox(points);
+
+    EXPECT_TRUE(indices.AllClose(
+            core::Tensor::Init<int64_t>({0, 2, 3, 4}, device)));
+}
+
+TEST_P(OrientedBoundingBoxPermuteDevices, LegacyConversion) {
+    core::Device device = GetParam();
+
+    core::Tensor center = core::Tensor::Init<float>({-1, -1, -1}, device);
+    core::Tensor extent = core::Tensor::Init<float>({1.0, 1.0, 1.0}, device);
+    core::Tensor rotation =
+            core::Tensor::Init<float>({{0.770062, -0.231286, -0.594569},
+                                       {-0.584733, 0.116831, -0.802769},
+                                       {0.255133, 0.965845, -0.0452729}},
+                                      device);
+
+    t::geometry::OrientedBoundingBox obb(center, rotation, extent);
+
+    auto legacy_obb = obb.ToLegacy();
+    ExpectEQ(legacy_obb.center_, Eigen::Vector3d(-1, -1, -1));
+    ExpectEQ(legacy_obb.extent_, Eigen::Vector3d(1, 1, 1));
+    ExpectEQ(legacy_obb.color_, Eigen::Vector3d(1, 1, 1));
+
+    // In Legacy, the data-type is eigen-double, so the created aabb is of
+    // type Float64.
+    auto obb_new = t::geometry::OrientedBoundingBox::FromLegacy(
+            legacy_obb, core::Float64, device);
+    EXPECT_TRUE(obb_new.GetCenter().AllClose(
+            core::Tensor::Init<double>({-1, -1, -1}, device)));
+    EXPECT_TRUE(obb_new.GetExtent().AllClose(
+            core::Tensor::Init<double>({1, 1, 1}, device)));
+    EXPECT_TRUE(obb_new.GetRotation().AllClose(
+            core::Tensor::Init<double>({{0.770062, -0.231286, -0.594569},
+                                        {-0.584733, 0.116831, -0.802769},
+                                        {0.255133, 0.965845, -0.0452729}},
+                                       device),
+            1e-5, 1e-5));
+}
+
+TEST_P(OrientedBoundingBoxPermuteDevices, CreateFromPoints) {
+    core::Device device = GetParam();
+
+    core::Tensor points = core::Tensor::Init<float>({{0.1, 0.3, 0.9},
+                                                     {0.9, 0.2, 0.4},
+                                                     {0.3, 0.6, 0.8},
+                                                     {0.2, 0.4, 0.2}},
+                                                    device);
+    t::geometry::OrientedBoundingBox obb =
+            t::geometry::OrientedBoundingBox::CreateFromPoints(points);
+
+    EXPECT_TRUE(obb.GetCenter().AllClose(
+            core::Tensor::Init<float>({0.376834, 0.383993, 0.438357}, device)));
+    EXPECT_TRUE(obb.GetExtent().AllClose(
+            core::Tensor::Init<float>({0.936462, 0.593233, 0.345308}, device)));
+    EXPECT_TRUE(obb.GetRotation().AllClose(
+            core::Tensor::Init<float>({{0.77006164, -0.5847325, 0.25513324},
+                                       {-0.23128562, 0.11683135, 0.96584543},
+                                       {-0.59456878, -0.80276917, -0.04527287}},
+                                      device)));
+}
+
+}  // namespace tests
+}  // namespace open3d
diff --git a/cpp/tools/GLInfo.cpp b/cpp/tools/GLInfo.cpp
index f49be5ebba9..2efe1e7b98f 100644
--- a/cpp/tools/GLInfo.cpp
+++ b/cpp/tools/GLInfo.cpp
@@ -41,6 +41,10 @@ void TryGLVersion(int major,
     std::string forwardCompatStr =
             (forwardCompat ? "GLFW_OPENGL_FORWARD_COMPAT " : "");
     std::string profileStr = "UnknownProfile";
+    // Some versions of GCC reports Wstringop-overflow error if string storage
+    // is not reserved. This might be related to a bug reported here:
+    // https://gcc.gnu.org/bugzilla/show_bug.cgi?id=96963
+    profileStr.reserve(32);
 #define OPEN3D_CHECK_PROFILESTR(p) \
     if (profileId == p) {          \
         profileStr = #p;           \
@@ -81,7 +85,8 @@ void TryGLVersion(int major,
         if (!r) {
             utility::LogWarning("Unable to get info on {} id {:d}", name, id);
         } else {
-            utility::LogDebug("{}:\t{}", name, r);
+            utility::LogDebug("{}:\t{}", name,
+                              reinterpret_cast<const char *>(r));
         }
     };
 #define OPEN3D_REPORT_GL_STRING(n) reportGlStringFunc(n, #n)
diff --git a/docs/index.rst b/docs/index.rst
index 132788528a3..391c0298e64 100644
--- a/docs/index.rst
+++ b/docs/index.rst
@@ -35,6 +35,7 @@ Open3D: A Modern Library for 3D Data Processing
     :caption: Tutorial
 
     tutorial/geometry/index
+    tutorial/t_geometry/index
     tutorial/pipelines/index
     tutorial/t_pipelines/index
     tutorial/visualization/index
diff --git a/docs/jupyter/geometry/pointcloud.ipynb b/docs/jupyter/geometry/pointcloud.ipynb
index e7c96221827..c8799fbc435 100644
--- a/docs/jupyter/geometry/pointcloud.ipynb
+++ b/docs/jupyter/geometry/pointcloud.ipynb
@@ -462,7 +462,7 @@
  "metadata": {
   "celltoolbar": "Edit Metadata",
   "kernelspec": {
-   "display_name": "Python 3 (ipykernel)",
+   "display_name": "Python 3.8.13 ('open3d')",
    "language": "python",
    "name": "python3"
   },
@@ -476,7 +476,12 @@
    "name": "python",
    "nbconvert_exporter": "python",
    "pygments_lexer": "ipython3",
-   "version": "3.8.11"
+   "version": "3.8.13"
+  },
+  "vscode": {
+   "interpreter": {
+    "hash": "d3ff712f491db3b4ccd20005f84e312b261650c105d83adbc3f83f5ecf60b94b"
+   }
   }
  },
  "nbformat": 4,
diff --git a/docs/jupyter/t_geometry/pointcloud.ipynb b/docs/jupyter/t_geometry/pointcloud.ipynb
new file mode 100644
index 00000000000..d402f71dbbe
--- /dev/null
+++ b/docs/jupyter/t_geometry/pointcloud.ipynb
@@ -0,0 +1,824 @@
+{
+ "cells": [
+  {
+   "cell_type": "code",
+   "execution_count": null,
+   "metadata": {
+    "ExecuteTime": {
+     "end_time": "2022-12-09T15:53:09.502685Z",
+     "start_time": "2022-12-09T15:53:08.653426Z"
+    }
+   },
+   "outputs": [],
+   "source": [
+    "import open3d as o3d\n",
+    "import open3d.core as o3c\n",
+    "import numpy as np\n",
+    "import matplotlib.pyplot as plt\n",
+    "import copy\n",
+    "import os\n",
+    "import sys\n",
+    "\n",
+    "# Only needed for tutorial, monkey patches visualization\n",
+    "sys.path.append(\"..\")\n",
+    "import open3d_tutorial as o3dtut\n",
+    "# Change to True if you want to interact with the visualization windows\n",
+    "o3dtut.interactive = not \"CI\" in os.environ"
+   ]
+  },
+  {
+   "cell_type": "markdown",
+   "metadata": {},
+   "source": [
+    "# PointCloud\n",
+    "This tutorial demonstrates basic usage of a point cloud.\n",
+    "\n",
+    "## PointCloud creation\n",
+    "The first part of the tutorial shows how to construct a point cloud."
+   ]
+  },
+  {
+   "cell_type": "code",
+   "execution_count": null,
+   "metadata": {
+    "ExecuteTime": {
+     "end_time": "2022-12-09T15:53:09.507147Z",
+     "start_time": "2022-12-09T15:53:09.503719Z"
+    }
+   },
+   "outputs": [],
+   "source": [
+    "# Create a empty point cloud on CPU.\n",
+    "pcd = o3d.t.geometry.PointCloud()\n",
+    "print(pcd, \"\\n\")\n",
+    "\n",
+    "# To create a point cloud on CUDA, specify the device.\n",
+    "# pcd = o3d.t.geometry.PointCloud(o3c.Device(\"cuda:0\"))\n",
+    "\n",
+    "# Create a point cloud from open3d tensor with dtype of float32.\n",
+    "pcd = o3d.t.geometry.PointCloud(o3c.Tensor([[0, 0, 0], [1, 1, 1]], o3c.float32))\n",
+    "print(pcd, \"\\n\")\n",
+    "\n",
+    "# Create a point cloud from open3d tensor with dtype of float64.\n",
+    "pcd = o3d.t.geometry.PointCloud(o3c.Tensor([[0, 0, 0], [1, 1, 1]], o3c.float64))\n",
+    "print(pcd, \"\\n\")\n",
+    "\n",
+    "# Create a point cloud from numpy array. The array will be copied.\n",
+    "pcd = o3d.t.geometry.PointCloud(\n",
+    "    np.array([[0, 0, 0], [1, 1, 1]], dtype=np.float32))\n",
+    "print(pcd, \"\\n\")\n",
+    "\n",
+    "# Create a point cloud from python list.\n",
+    "pcd = o3d.t.geometry.PointCloud([[0., 0., 0.], [1., 1., 1.]])\n",
+    "print(pcd, \"\\n\")\n",
+    "\n",
+    "# Error creation. The point cloud must have shape of (N, 3).\n",
+    "try:\n",
+    "    pcd = o3d.t.geometry.PointCloud(o3c.Tensor([0, 0, 0, 0], o3c.float32))\n",
+    "except:\n",
+    "    print(f\"Error creation. The point cloud must have shape of (N, 3).\")\n"
+   ]
+  },
+  {
+   "cell_type": "markdown",
+   "metadata": {},
+   "source": [
+    "The `PointCloud` can be created on both CPU and GPU, and with different data types. The device of the point cloud will be the same as the device of the input tensor.\n",
+    "\n",
+    "Besides, `PointCloud` can be also created by python dict with multiple attributes. "
+   ]
+  },
+  {
+   "cell_type": "code",
+   "execution_count": null,
+   "metadata": {
+    "ExecuteTime": {
+     "end_time": "2022-12-09T15:53:15.378492Z",
+     "start_time": "2022-12-09T15:53:15.375715Z"
+    }
+   },
+   "outputs": [],
+   "source": [
+    "map_to_tensors = {}\n",
+    "\n",
+    "# - The \"positions\" attribute must be specified.\n",
+    "# - Common attributes include \"colors\" and \"normals\". \n",
+    "# - You may also use custom attributes, such as \"labels\".\n",
+    "# - The value of an attribute could be of any shape and dtype. Its correctness\n",
+    "#   will only be checked when the attribute is used by some algorithms.\n",
+    "map_to_tensors[\"positions\"] = o3c.Tensor([[0, 0, 0], [1, 1, 1]], o3c.float32)\n",
+    "map_to_tensors[\"normals\"] = o3c.Tensor([[0, 0, 1], [0, 0, 1]], o3c.float32)\n",
+    "map_to_tensors[\"labels\"] = o3c.Tensor([0, 1], o3c.int64)\n",
+    "\n",
+    "pcd = o3d.t.geometry.PointCloud(map_to_tensors)\n",
+    "print(pcd)"
+   ]
+  },
+  {
+   "cell_type": "markdown",
+   "metadata": {},
+   "source": [
+    "## Point cloud attributes setter and getter"
+   ]
+  },
+  {
+   "cell_type": "code",
+   "execution_count": null,
+   "metadata": {
+    "ExecuteTime": {
+     "end_time": "2022-12-09T15:53:24.681751Z",
+     "start_time": "2022-12-09T15:53:24.678427Z"
+    }
+   },
+   "outputs": [],
+   "source": [
+    "pcd = o3d.t.geometry.PointCloud(o3c.Tensor([[0, 0, 0], [1, 1, 1]], o3c.float32))\n",
+    "# Set attributes.\n",
+    "pcd.point.normals = o3c.Tensor([[0, 0, 1], [0, 0, 1]], o3c.float32)\n",
+    "pcd.point.colors = o3c.Tensor([[1, 0, 0], [0, 1, 0]], o3c.float32)\n",
+    "pcd.point.labels = o3c.Tensor([0, 1], o3c.int64)\n",
+    "print(pcd, \"\\n\")\n",
+    "\n",
+    "# Set by numpy array or python list.\n",
+    "pcd.point.normals = np.array([[0, 0, 1], [0, 0, 1]], dtype=np.float32)\n",
+    "pcd.point.intensity = [0.4, 0.4]\n",
+    "print(pcd, \"\\n\")\n",
+    "\n",
+    "# Get attributes.\n",
+    "posisions = pcd.point.positions\n",
+    "print(\"posisions: \")\n",
+    "print(posisions, \"\\n\")\n",
+    "labels = pcd.point.labels\n",
+    "print(\"labels: \")\n",
+    "print(labels, \"\")"
+   ]
+  },
+  {
+   "cell_type": "markdown",
+   "metadata": {},
+   "source": [
+    "## Conversion between tensor and legacy point cloud\n",
+    "PointCloud can be converted to/from legacy `open3d.geometry.PointCloud`."
+   ]
+  },
+  {
+   "cell_type": "code",
+   "execution_count": null,
+   "metadata": {},
+   "outputs": [],
+   "source": [
+    "legacy_pcd = pcd.to_legacy()\n",
+    "print(legacy_pcd, \"\\n\")\n",
+    "\n",
+    "tensor_pcd = o3d.t.geometry.PointCloud.from_legacy(legacy_pcd)\n",
+    "print(tensor_pcd, \"\\n\")\n",
+    "\n",
+    "# Convert from legacy point cloud with data type of float64.\n",
+    "tensor_pcd_f64 = o3d.t.geometry.PointCloud.from_legacy(legacy_pcd, o3c.float64)\n",
+    "print(tensor_pcd_f64, \"\\n\")"
+   ]
+  },
+  {
+   "cell_type": "markdown",
+   "metadata": {},
+   "source": [
+    "## Visualize point cloud"
+   ]
+  },
+  {
+   "cell_type": "code",
+   "execution_count": null,
+   "metadata": {},
+   "outputs": [],
+   "source": [
+    "print(\"Load a ply point cloud, print it, and render it\")\n",
+    "ply_point_cloud = o3d.data.PLYPointCloud()\n",
+    "pcd = o3d.t.io.read_point_cloud(ply_point_cloud.path)\n",
+    "print(pcd)\n",
+    "o3d.visualization.draw_geometries([pcd.to_legacy()],\n",
+    "                                  zoom=0.3412,\n",
+    "                                  front=[0.4257, -0.2125, -0.8795],\n",
+    "                                  lookat=[2.6172, 2.0475, 1.532],\n",
+    "                                  up=[-0.0694, -0.9768, 0.2024])"
+   ]
+  },
+  {
+   "cell_type": "markdown",
+   "metadata": {},
+   "source": [
+    "`read_point_cloud` reads a point cloud from a file. It tries to decode the file based on the extension name. For a list of supported file types, refer to [File IO](file_io.ipynb).\n",
+    "\n",
+    "`draw_geometries` visualizes the point cloud. Use a mouse/trackpad to see the geometry from different view points.\n",
+    "\n",
+    "It looks like a dense surface, but it is actually a point cloud rendered as surfels. The GUI supports various keyboard functions. For instance, the `-` key reduces the size of the points (surfels).\n",
+    "\n",
+    "<div class=\"alert alert-info\">\n",
+    "    \n",
+    "**Note:** \n",
+    "\n",
+    "Press the `H` key to print out a complete list of keyboard instructions for the GUI. For more information of the visualization GUI, refer to [Visualization](visualization.ipynb) and [Customized visualization](../visualization/customized_visualization.rst).\n",
+    "\n",
+    "</div>\n",
+    "\n",
+    "<div class=\"alert alert-info\">\n",
+    "    \n",
+    "**Note:** \n",
+    "\n",
+    "On macOS, the GUI window may not receive keyboard events. In this case, try to launch Python with `pythonw` instead of `python`.\n",
+    "\n",
+    "</div>"
+   ]
+  },
+  {
+   "cell_type": "markdown",
+   "metadata": {},
+   "source": [
+    "## Downsampling\n",
+    "This section provides several downsamle methods of a point cloud.\n",
+    "### Voxel downsampling\n",
+    "Voxel downsampling uses a regular voxel grid to create a uniformly downsampled point cloud from an input point cloud. It is often used as a pre-processing step for many point cloud processing tasks. The algorithm operates in two steps:\n",
+    "\n",
+    "1. Points are bucketed into voxels.\n",
+    "2. Each occupied voxel generates exactly one point by averaging all points inside. \n",
+    "\n",
+    "<div class=\"alert alert-info\">\n",
+    "    \n",
+    "**Note:** \n",
+    "\n",
+    "Currently, the method returns the voxel coordinates of the point cloud.\n",
+    "\n",
+    "</div>"
+   ]
+  },
+  {
+   "cell_type": "code",
+   "execution_count": null,
+   "metadata": {},
+   "outputs": [],
+   "source": [
+    "print(\"Downsample the point cloud with a voxel of 0.03\")\n",
+    "downpcd = pcd.voxel_down_sample(voxel_size=0.03)\n",
+    "o3d.visualization.draw_geometries([downpcd.to_legacy()],\n",
+    "                                  zoom=0.3412,\n",
+    "                                  front=[0.4257, -0.2125, -0.8795],\n",
+    "                                  lookat=[2.6172, 2.0475, 1.532],\n",
+    "                                  up=[-0.0694, -0.9768, 0.2024])"
+   ]
+  },
+  {
+   "cell_type": "markdown",
+   "metadata": {},
+   "source": [
+    "### Farthest point downsampling\n",
+    "Farthest point sampling samples the point cloud by selecting the farthest point from the current selected point iteratively. It is used to sample the point cloud to a fixed number of points which holds the maximum geometrical information of the original point cloud."
+   ]
+  },
+  {
+   "cell_type": "code",
+   "execution_count": null,
+   "metadata": {},
+   "outputs": [],
+   "source": [
+    "print(\"Downsample the point cloud by selecting 5000 farthest points.\")\n",
+    "downpcd_farthest = pcd.farthest_point_down_sample(5000)\n",
+    "o3d.visualization.draw_geometries([downpcd_farthest.to_legacy()],\n",
+    "                                  zoom=0.3412,\n",
+    "                                  front=[0.4257, -0.2125, -0.8795],\n",
+    "                                  lookat=[2.6172, 2.0475, 1.532],\n",
+    "                                  up=[-0.0694, -0.9768, 0.2024])"
+   ]
+  },
+  {
+   "cell_type": "markdown",
+   "metadata": {},
+   "source": [
+    "Open3D also provides `uniform_down_sample` and `random_down_sample` for point cloud downsampling."
+   ]
+  },
+  {
+   "cell_type": "markdown",
+   "metadata": {},
+   "source": [
+    "## Vertex normal estimation\n",
+    "Another basic operation for point cloud is normal estimation.\n",
+    "Press `N` to see point normals. The keys `-` and `+` can be used to control the length of the normal."
+   ]
+  },
+  {
+   "cell_type": "code",
+   "execution_count": null,
+   "metadata": {},
+   "outputs": [],
+   "source": [
+    "print(\"Recompute the normal of the downsampled point cloud using hybrid nearest neighbor search with 30 max_nn and radius of 0.1m.\")\n",
+    "downpcd.estimate_normals(max_nn=30, radius=0.1)\n",
+    "o3d.visualization.draw_geometries([downpcd.to_legacy()],\n",
+    "                                  zoom=0.3412,\n",
+    "                                  front=[0.4257, -0.2125, -0.8795],\n",
+    "                                  lookat=[2.6172, 2.0475, 1.532],\n",
+    "                                  up=[-0.0694, -0.9768, 0.2024],\n",
+    "                                  point_show_normal=True)"
+   ]
+  },
+  {
+   "cell_type": "markdown",
+   "metadata": {},
+   "source": [
+    "`estimate_normals` computes the normal for every point. The function finds adjacent points and calculates the principal axis of the adjacent points using covariance analysis.\n",
+    "\n",
+    "The two key arguments `radius = 0.1` and `max_nn = 30` specifies search radius and maximum nearest neighbor. It has 10cm of search radius, and only considers up to 30 neighbors to save computation time. If only `max_nn` or `radius` is specified (`downpcd.estimate_normals(30, None)` or `downpcd.estimate_normals(None, 0.01)`), the function will use knn or radius search respectively. \n",
+    "\n",
+    "<div class=\"alert alert-info\">\n",
+    "    \n",
+    "**Note:** \n",
+    "It is always recommended to specify both `radius` and `max_nn`, especially if the point cloud is on CUDA device.\n",
+    "</div>\n",
+    "\n",
+    "<div class=\"alert alert-info\">\n",
+    "    \n",
+    "**Note:** \n",
+    "The covariance analysis algorithm produces two opposite directions as normal candidates. Without knowing the global structure of the geometry, both can be correct. This is known as the normal orientation problem. Open3D tries to orient the normal to align with the original normal if it exists. Otherwise, Open3D does a random guess. Further orientation functions such as `orient_normals_to_align_with_direction` and `orient_normals_towards_camera_location` need to be called if the orientation is a concern.\n",
+    "\n",
+    "</div>"
+   ]
+  },
+  {
+   "cell_type": "markdown",
+   "metadata": {},
+   "source": [
+    "### Access estimated normals\n",
+    "The estimated normals can be access and converted to numpy array."
+   ]
+  },
+  {
+   "cell_type": "code",
+   "execution_count": null,
+   "metadata": {},
+   "outputs": [],
+   "source": [
+    "normals = downpcd.point.normals\n",
+    "print(\"Print first 5 normals of the downsampled point cloud.\")\n",
+    "print(normals[:5], \"\\n\")\n",
+    "print(\"Convert normals tensor into numpy array.\")\n",
+    "normals_np = normals.numpy()\n",
+    "print(normals_np[:5])"
+   ]
+  },
+  {
+   "cell_type": "markdown",
+   "metadata": {},
+   "source": [
+    "## Crop point cloud"
+   ]
+  },
+  {
+   "cell_type": "code",
+   "execution_count": null,
+   "metadata": {},
+   "outputs": [],
+   "source": [
+    "print(\"Load a polygon volume and use it to crop the original point cloud\")\n",
+    "demo_crop_data = o3d.data.DemoCropPointCloud()\n",
+    "pcd = o3d.t.io.read_point_cloud(demo_crop_data.point_cloud_path)\n",
+    "vol = o3d.visualization.read_selection_polygon_volume(demo_crop_data.cropped_json_path)\n",
+    "chair = vol.crop_point_cloud(pcd.to_legacy())\n",
+    "o3d.visualization.draw_geometries([chair],\n",
+    "                                  zoom=0.7,\n",
+    "                                  front=[0.5439, -0.2333, -0.8060],\n",
+    "                                  lookat=[2.4615, 2.1331, 1.338],\n",
+    "                                  up=[-0.1781, -0.9708, 0.1608])"
+   ]
+  },
+  {
+   "cell_type": "markdown",
+   "metadata": {},
+   "source": [
+    "`read_selection_polygon_volume` reads a json file that specifies polygon selection area. `vol.crop_point_cloud(pcd)` filters out points. Only the chair remains.\n",
+    "\n",
+    "We can also get the cropped indices of the point cloud using `crop_in_polygon`. "
+   ]
+  },
+  {
+   "cell_type": "code",
+   "execution_count": null,
+   "metadata": {},
+   "outputs": [],
+   "source": [
+    "indices = vol.crop_in_polygon(pcd.to_legacy())\n",
+    "print(f\"Cropped indices length: {len(indices)}\") "
+   ]
+  },
+  {
+   "cell_type": "markdown",
+   "metadata": {},
+   "source": [
+    "## Paint point cloud"
+   ]
+  },
+  {
+   "cell_type": "code",
+   "execution_count": null,
+   "metadata": {},
+   "outputs": [],
+   "source": [
+    "print(\"Paint point cloud.\")\n",
+    "pcd.paint_uniform_color([1, 0.706, 0])\n",
+    "o3d.visualization.draw_geometries([pcd.to_legacy()],\n",
+    "                                  zoom=0.7,\n",
+    "                                  front=[0.5439, -0.2333, -0.8060],\n",
+    "                                  lookat=[2.4615, 2.1331, 1.338],\n",
+    "                                  up=[-0.1781, -0.9708, 0.1608])"
+   ]
+  },
+  {
+   "cell_type": "markdown",
+   "metadata": {},
+   "source": [
+    "`paint_uniform_color` paints all the points to a uniform color. The color is in RGB space, [0, 1] range."
+   ]
+  },
+  {
+   "cell_type": "markdown",
+   "metadata": {},
+   "source": [
+    "## Bounding volumes\n",
+    "The `PointCloud` geometry type has bounding volumes as all other geometry types in Open3D. Currently, Open3D implements an `AxisAlignedBoundingBox` and an `OrientedBoundingBox` that can also be used to crop the geometry."
+   ]
+  },
+  {
+   "cell_type": "code",
+   "execution_count": null,
+   "metadata": {},
+   "outputs": [],
+   "source": [
+    "aabb = pcd.get_axis_aligned_bounding_box()\n",
+    "aabb.set_color(o3c.Tensor([1, 0, 0], o3c.float32))\n",
+    "obb = pcd.get_oriented_bounding_box()\n",
+    "obb.set_color(o3c.Tensor([0, 1, 0], o3c.float32))\n",
+    "o3d.visualization.draw_geometries(\n",
+    "    [pcd.to_legacy(), aabb.to_legacy(),\n",
+    "     obb.to_legacy()],\n",
+    "    zoom=0.7,\n",
+    "    front=[0.5439, -0.2333, -0.8060],\n",
+    "    lookat=[2.4615, 2.1331, 1.338],\n",
+    "    up=[-0.1781, -0.9708, 0.1608])"
+   ]
+  },
+  {
+   "cell_type": "markdown",
+   "metadata": {},
+   "source": [
+    "## Point cloud outlier removal\n",
+    "When collecting data from scanning devices, the resulting point cloud tends to contain noise and artifacts that one would like to remove. This demo below addresses the outlier removal features of Open3D.\n",
+    "\n",
+    "### Prepare input data\n",
+    "A point cloud is loaded and downsampled using `voxel_downsample`."
+   ]
+  },
+  {
+   "cell_type": "code",
+   "execution_count": null,
+   "metadata": {},
+   "outputs": [],
+   "source": [
+    "print(\"Load a ply point cloud, print it, and render it\")\n",
+    "sample_pcd_data = o3d.data.PCDPointCloud()\n",
+    "pcd = o3d.t.io.read_point_cloud(sample_pcd_data.path)\n",
+    "o3d.visualization.draw_geometries([pcd.to_legacy()],\n",
+    "                                  zoom=0.3412,\n",
+    "                                  front=[0.4257, -0.2125, -0.8795],\n",
+    "                                  lookat=[2.6172, 2.0475, 1.532],\n",
+    "                                  up=[-0.0694, -0.9768, 0.2024])\n",
+    "\n",
+    "print(\"Downsample the point cloud with a voxel of 0.02\")\n",
+    "voxel_down_pcd = pcd.voxel_down_sample(voxel_size=0.02)\n",
+    "o3d.visualization.draw_geometries([voxel_down_pcd.to_legacy()],\n",
+    "                                  zoom=0.3412,\n",
+    "                                  front=[0.4257, -0.2125, -0.8795],\n",
+    "                                  lookat=[2.6172, 2.0475, 1.532],\n",
+    "                                  up=[-0.0694, -0.9768, 0.2024])"
+   ]
+  },
+  {
+   "cell_type": "markdown",
+   "metadata": {},
+   "source": [
+    "Alternatively, use `uniform_down_sample` to downsample the point cloud by collecting every n-th points."
+   ]
+  },
+  {
+   "cell_type": "code",
+   "execution_count": null,
+   "metadata": {},
+   "outputs": [],
+   "source": [
+    "print(\"Every 5th points are selected\")\n",
+    "uni_down_pcd = pcd.uniform_down_sample(every_k_points=5)\n",
+    "o3d.visualization.draw_geometries([uni_down_pcd.to_legacy()],\n",
+    "                                  zoom=0.3412,\n",
+    "                                  front=[0.4257, -0.2125, -0.8795],\n",
+    "                                  lookat=[2.6172, 2.0475, 1.532],\n",
+    "                                  up=[-0.0694, -0.9768, 0.2024])"
+   ]
+  },
+  {
+   "cell_type": "markdown",
+   "metadata": {},
+   "source": [
+    "### Select down sample\n",
+    "The following helper function uses `select_by_mask`, which takes a binary mask to output only the selected points. The selected points and the non-selected points are visualized."
+   ]
+  },
+  {
+   "cell_type": "code",
+   "execution_count": null,
+   "metadata": {},
+   "outputs": [],
+   "source": [
+    "def display_inlier_outlier(cloud : o3d.t.geometry.PointCloud, mask : o3c.Tensor):\n",
+    "    inlier_cloud = cloud.select_by_mask(mask)\n",
+    "    outlier_cloud = cloud.select_by_mask(mask, invert=True)\n",
+    "\n",
+    "    print(\"Showing outliers (red) and inliers (gray): \")\n",
+    "    outlier_cloud = outlier_cloud.paint_uniform_color([1.0, 0, 0])\n",
+    "    inlier_cloud.paint_uniform_color([0.8, 0.8, 0.8])\n",
+    "    inlier_cloud = o3d.visualization.draw_geometries([inlier_cloud.to_legacy(), outlier_cloud.to_legacy()],\n",
+    "                                      zoom=0.3412,\n",
+    "                                      front=[0.4257, -0.2125, -0.8795],\n",
+    "                                      lookat=[2.6172, 2.0475, 1.532],\n",
+    "                                      up=[-0.0694, -0.9768, 0.2024])"
+   ]
+  },
+  {
+   "cell_type": "markdown",
+   "metadata": {},
+   "source": [
+    "### Statistical outlier removal\n",
+    "`statistical_outlier_removal` removes points that are further away from their neighbors compared to the average for the point cloud. It takes two input parameters:\n",
+    "\n",
+    "- `nb_neighbors`, which specifies how many neighbors are taken into account in order to calculate the average distance for a given point.\n",
+    "- `std_ratio`, which allows setting the threshold level based on the standard deviation of the average distances across the point cloud. The lower this number the more aggressive the filter will be."
+   ]
+  },
+  {
+   "cell_type": "code",
+   "execution_count": null,
+   "metadata": {},
+   "outputs": [],
+   "source": [
+    "print(\"Statistical oulier removal\")\n",
+    "cl, ind = voxel_down_pcd.remove_statistical_outliers(nb_neighbors=20,\n",
+    "                                                     std_ratio=2.0)\n",
+    "display_inlier_outlier(voxel_down_pcd, ind)"
+   ]
+  },
+  {
+   "cell_type": "markdown",
+   "metadata": {},
+   "source": [
+    "### Radius outlier removal\n",
+    "`radius_outlier_removal` removes points that have few neighbors in a given sphere around them. Two parameters can be used to tune the filter to your data:\n",
+    "\n",
+    "- `nb_points`, which lets you pick the minimum amount of points that the sphere should contain.\n",
+    "- `radius`, which defines the radius of the sphere that will be used for counting the neighbors."
+   ]
+  },
+  {
+   "cell_type": "code",
+   "execution_count": null,
+   "metadata": {},
+   "outputs": [],
+   "source": [
+    "print(\"Radius oulier removal\")\n",
+    "cl, ind = voxel_down_pcd.remove_radius_outliers(nb_points=16, search_radius=0.05)\n",
+    "display_inlier_outlier(voxel_down_pcd, ind)"
+   ]
+  },
+  {
+   "cell_type": "markdown",
+   "metadata": {},
+   "source": [
+    "## Convex hull\n",
+    "The convex hull of a point cloud is the smallest convex set that contains all points. Open3D contains the method `compute_convex_hull` that computes the convex hull of a point cloud. The implementation is based on [Qhull](http://www.qhull.org/).\n",
+    "\n",
+    "In the example code below we compute the convex hull that is returned as a triangle mesh. Then, we visualize the convex hull as a red `LineSet`."
+   ]
+  },
+  {
+   "cell_type": "code",
+   "execution_count": null,
+   "metadata": {},
+   "outputs": [],
+   "source": [
+    "bunny = o3d.data.BunnyMesh()\n",
+    "pcd = o3d.t.io.read_point_cloud(bunny.path)\n",
+    "\n",
+    "hull = pcd.compute_convex_hull()\n",
+    "hull_ls = o3d.geometry.LineSet.create_from_triangle_mesh(hull.to_legacy())\n",
+    "hull_ls.paint_uniform_color((1, 0, 0))\n",
+    "o3d.visualization.draw_geometries([pcd.to_legacy(), hull_ls])"
+   ]
+  },
+  {
+   "cell_type": "markdown",
+   "metadata": {},
+   "source": [
+    "## DBSCAN clustering\n",
+    "Given a point cloud from e.g. a depth sensor we want to group local point cloud clusters together. For this purpose, we can use clustering algorithms. Open3D implements DBSCAN [\\[Ester1996\\]](../reference.html#Ester1996) that is a density based clustering algorithm. The algorithm is implemented in `cluster_dbscan` and requires two parameters: `eps` defines the distance to neighbors in a cluster and `min_points` defines the minimum number of points required to form a cluster. The function returns `labels`, where the label `-1` indicates noise."
+   ]
+  },
+  {
+   "cell_type": "code",
+   "execution_count": null,
+   "metadata": {},
+   "outputs": [],
+   "source": [
+    "ply_point_cloud = o3d.data.PLYPointCloud()\n",
+    "pcd = o3d.t.io.read_point_cloud(ply_point_cloud.path)\n",
+    "\n",
+    "with o3d.utility.VerbosityContextManager(\n",
+    "        o3d.utility.VerbosityLevel.Debug) as cm:\n",
+    "    labels = pcd.cluster_dbscan(eps=0.02, min_points=10, print_progress=True)\n",
+    "\n",
+    "max_label = labels.max().item()\n",
+    "print(f\"point cloud has {max_label + 1} clusters\")\n",
+    "colors = plt.get_cmap(\"tab20\")(\n",
+    "        labels.numpy() / (max_label if max_label > 0 else 1))\n",
+    "colors = o3c.Tensor(colors[:, :3], o3c.float32)\n",
+    "colors[labels < 0] = 0\n",
+    "pcd.point.colors = colors\n",
+    "o3d.visualization.draw_geometries([pcd.to_legacy()],\n",
+    "                                  zoom=0.455,\n",
+    "                                  front=[-0.4999, -0.1659, -0.8499],\n",
+    "                                  lookat=[2.1813, 2.0619, 2.0999],\n",
+    "                                  up=[0.1204, -0.9852, 0.1215])"
+   ]
+  },
+  {
+   "cell_type": "markdown",
+   "metadata": {},
+   "source": [
+    "<div class=\"alert alert-info\">\n",
+    "    \n",
+    "**Note:** \n",
+    "\n",
+    "This algorithm precomputes all neighbors in the epsilon radius for all points. This can require a lot of memory if the chosen epsilon is too large.\n",
+    "\n",
+    "</div>"
+   ]
+  },
+  {
+   "cell_type": "markdown",
+   "metadata": {},
+   "source": [
+    "## Plane segmentation\n",
+    "Open3D also supports segmententation of geometric primitives from point clouds using RANSAC. To find the plane with the largest support in the point cloud, we can use `segment_plane`. The method has four arguments: `distance_threshold` defines the maximum distance a point can have to an estimated plane to be considered an inlier, `ransac_n` defines the number of points that are randomly sampled to estimate a plane, `num_iterations` defines how often a random plane is sampled and verified, and `probability` defined the expected probability of finding the optimal plane. The function then returns the plane as $(a,b,c,d)$ such that for each point $(x,y,z)$ on the plane we have $ax + by + cz + d = 0$. The function further returns a indices of the inlier points."
+   ]
+  },
+  {
+   "cell_type": "code",
+   "execution_count": null,
+   "metadata": {},
+   "outputs": [],
+   "source": [
+    "sample_pcd_data = o3d.data.PCDPointCloud()\n",
+    "pcd = o3d.t.io.read_point_cloud(sample_pcd_data.path)\n",
+    "plane_model, inliers = pcd.segment_plane(distance_threshold=0.01,\n",
+    "                                            ransac_n=3,\n",
+    "                                            num_iterations=1000, \n",
+    "                                            probability=0.9999)\n",
+    "[a, b, c, d] = plane_model.numpy().tolist()\n",
+    "print(f\"Plane equation: {a:.2f}x + {b:.2f}y + {c:.2f}z + {d:.2f} = 0\")\n",
+    "\n",
+    "inlier_cloud = pcd.select_by_index(inliers)\n",
+    "inlier_cloud = inlier_cloud.paint_uniform_color([1.0, 0, 0])\n",
+    "outlier_cloud = pcd.select_by_index(inliers, invert=True)\n",
+    "o3d.visualization.draw_geometries([inlier_cloud.to_legacy(), outlier_cloud.to_legacy()],\n",
+    "                                  zoom=0.8,\n",
+    "                                  front=[-0.4999, -0.1659, -0.8499],\n",
+    "                                  lookat=[2.1813, 2.0619, 2.0999],\n",
+    "                                  up=[0.1204, -0.9852, 0.1215])"
+   ]
+  },
+  {
+   "cell_type": "markdown",
+   "metadata": {},
+   "source": []
+  },
+  {
+   "cell_type": "markdown",
+   "metadata": {},
+   "source": [
+    "To achieve the stable results with specific random seed, you can set `probability` to 1.0, which will force the executed iteration equal to `num_iterations`. (Since `0.16.0`, the `segment_plane` function is parallel, and the iteration will be updated by the equation: `iter = log(1 - probability) / log(1 - fitness ^ ransac_n)`, where `fitness` is the ratio of inliers number and total number of points)"
+   ]
+  },
+  {
+   "cell_type": "code",
+   "execution_count": null,
+   "metadata": {},
+   "outputs": [],
+   "source": [
+    "o3d.utility.random.seed(0)\n",
+    "\n",
+    "plane_model, inliers = pcd.segment_plane(distance_threshold=0.01,\n",
+    "                                            ransac_n=3,\n",
+    "                                            num_iterations=1000, \n",
+    "                                            probability=1.0)"
+   ]
+  },
+  {
+   "cell_type": "markdown",
+   "metadata": {},
+   "source": [
+    "## Hidden point removal\n",
+    "Imagine you want to render a point cloud from a given view point, but points from the background leak into the foreground because they are not occluded by other points. For this purpose we can apply a hidden point removal algorithm. In Open3D the method by [\\[Katz2007\\]](../reference.html#Katz2007) is implemented that approximates the visibility of a point cloud from a given view without surface reconstruction or normal estimation."
+   ]
+  },
+  {
+   "cell_type": "code",
+   "execution_count": null,
+   "metadata": {},
+   "outputs": [],
+   "source": [
+    "print(\"Convert mesh to a point cloud and estimate dimensions\")\n",
+    "armadillo = o3d.data.ArmadilloMesh()\n",
+    "mesh = o3d.io.read_triangle_mesh(armadillo.path)\n",
+    "# Tensor TriangleMesh not supported this function yet.\n",
+    "mesh.compute_vertex_normals()\n",
+    "\n",
+    "pcd = mesh.sample_points_poisson_disk(5000)\n",
+    "diameter = np.linalg.norm(\n",
+    "    np.asarray(pcd.get_max_bound()) - np.asarray(pcd.get_min_bound()))\n",
+    "o3d.visualization.draw_geometries([pcd])\n",
+    "\n",
+    "print(\"Define parameters used for hidden_point_removal\")\n",
+    "camera = o3d.core.Tensor([0, 0, diameter], o3d.core.float32)\n",
+    "radius = diameter * 100\n",
+    "\n",
+    "print(\"Get all points that are visible from given view point\")\n",
+    "pcd = o3d.t.geometry.PointCloud.from_legacy(pcd)\n",
+    "_, pt_map = pcd.hidden_point_removal(camera, radius)\n",
+    "pcd = pcd.select_by_index(pt_map)\n",
+    "\n",
+    "print(\"Visualize result\")\n",
+    "o3d.visualization.draw_geometries([pcd.to_legacy()])"
+   ]
+  },
+  {
+   "cell_type": "markdown",
+   "metadata": {},
+   "source": [
+    "## Boundary detection\n",
+    "Open3D implements the boundary detection algorithm inspired by [PCL](https://pointclouds.org/documentation/classpcl_1_1_boundary_estimation.html). The algorithm find the boundary points among a unordered point cloud by analyzing the angle among the normals of a point and its neighbors. The method has three arguments: `radius` and `max_nn` specify the hybrid nearest search parameters; The `angle_threshold` defines the maximum angle between the normals of a point and its neighbors to be considered as a boundary point. The functions returns the boundary points and a boolean tensor of the same size as the input point cloud."
+   ]
+  },
+  {
+   "cell_type": "code",
+   "execution_count": null,
+   "metadata": {},
+   "outputs": [],
+   "source": [
+    "ply_point_cloud = o3d.data.DemoCropPointCloud()\n",
+    "pcd = o3d.t.io.read_point_cloud(ply_point_cloud.point_cloud_path)\n",
+    "\n",
+    "boundarys, mask = pcd.compute_boundary_points(0.02, 30)\n",
+    "# TODO: not good to get size of points.\n",
+    "print(f\"Detect {boundarys.point.positions.shape[0]} bnoundary points from {pcd.point.positions.shape[0]} points.\")\n",
+    "\n",
+    "boundarys = boundarys.paint_uniform_color([1.0, 0.0, 0.0])\n",
+    "pcd = pcd.paint_uniform_color([0.6, 0.6, 0.6])\n",
+    "o3d.visualization.draw_geometries([pcd.to_legacy(), boundarys.to_legacy()],\n",
+    "                                      zoom=0.3412,\n",
+    "                                      front=[0.3257, -0.2125, -0.8795],\n",
+    "                                      lookat=[2.6172, 2.0475, 1.532],\n",
+    "                                      up=[-0.0694, -0.9768, 0.2024])"
+   ]
+  }
+ ],
+ "metadata": {
+  "kernelspec": {
+   "display_name": "Python 3 (ipykernel)",
+   "language": "python",
+   "name": "python3"
+  },
+  "language_info": {
+   "codemirror_mode": {
+    "name": "ipython",
+    "version": 3
+   },
+   "file_extension": ".py",
+   "mimetype": "text/x-python",
+   "name": "python",
+   "nbconvert_exporter": "python",
+   "pygments_lexer": "ipython3",
+   "version": "3.9.13"
+  },
+  "vscode": {
+   "interpreter": {
+    "hash": "c36d4cd2cfce5c26977a9560a8c96efbe52e59f8182dcd6a297957684d25bbef"
+   }
+  }
+ },
+ "nbformat": 4,
+ "nbformat_minor": 2
+}
diff --git a/docs/make_docs.py b/docs/make_docs.py
index 545812412a7..915ebfbb1a9 100644
--- a/docs/make_docs.py
+++ b/docs/make_docs.py
@@ -512,12 +512,8 @@ def run(self):
             'tensor.ipynb',
         ]
         example_dirs = [
-            "core",
-            "data",
-            "geometry",
-            "pipelines",
-            "t_pipelines",
-            "visualization",
+            "geometry", "t_geometry", "core", "data", "pipelines",
+            "visualization", "t_pipelines"
         ]
         for example_dir in example_dirs:
             in_dir = (Path(self.current_file_dir) / "jupyter" / example_dir)
diff --git a/docs/tutorial/t_geometry/index.rst b/docs/tutorial/t_geometry/index.rst
new file mode 100644
index 00000000000..e1f1e9a4bc8
--- /dev/null
+++ b/docs/tutorial/t_geometry/index.rst
@@ -0,0 +1,8 @@
+Geometry (Tensor)
+========
+
+.. toctree::
+    :caption: Basics
+
+    pointcloud
+
diff --git a/examples/python/visualization/mouse_and_point_coord.py b/examples/python/visualization/mouse_and_point_coord.py
index 99a40c726f7..d2a8613c57e 100644
--- a/examples/python/visualization/mouse_and_point_coord.py
+++ b/examples/python/visualization/mouse_and_point_coord.py
@@ -100,7 +100,7 @@ def depth_callback(depth_image):
                     text = ""
                 else:
                     world = self.widget3d.scene.camera.unproject(
-                        event.x, event.y, depth, self.widget3d.frame.width,
+                        x, y, depth, self.widget3d.frame.width,
                         self.widget3d.frame.height)
                     text = "({:.3f}, {:.3f}, {:.3f})".format(
                         world[0], world[1], world[2])
diff --git a/examples/python/visualization/to_mitsuba.py b/examples/python/visualization/to_mitsuba.py
new file mode 100644
index 00000000000..82206b319c9
--- /dev/null
+++ b/examples/python/visualization/to_mitsuba.py
@@ -0,0 +1,109 @@
+# ----------------------------------------------------------------------------
+# -                        Open3D: www.open3d.org                            -
+# ----------------------------------------------------------------------------
+# The MIT License (MIT)
+#
+# Copyright (c) 2018-2021 www.open3d.org
+#
+# Permission is hereby granted, free of charge, to any person obtaining a copy
+# of this software and associated documentation files (the "Software"), to deal
+# in the Software without restriction, including without limitation the rights
+# to use, copy, modify, merge, publish, distribute, sublicense, and/or sell
+# copies of the Software, and to permit persons to whom the Software is
+# furnished to do so, subject to the following conditions:
+#
+# The above copyright notice and this permission notice shall be included in
+# all copies or substantial portions of the Software.
+#
+# THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR
+# IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,
+# FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE
+# AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER
+# LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING
+# FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS
+# IN THE SOFTWARE.
+# ----------------------------------------------------------------------------
+
+import open3d as o3d
+import mitsuba as mi
+
+
+def render_mesh(mesh, mesh_center):
+    scene = mi.load_dict({
+        'type': 'scene',
+        'integrator': {
+            'type': 'path'
+        },
+        'light': {
+            'type': 'constant',
+            'radiance': {
+                'type': 'rgb',
+                'value': 1.0
+            }
+        },
+        'sensor': {
+            'type':
+                'perspective',
+            'focal_length':
+                '50mm',
+            'to_world':
+                mi.ScalarTransform4f.look_at(origin=[0, 0, 5],
+                                             target=mesh_center,
+                                             up=[0, 1, 0]),
+            'thefilm': {
+                'type': 'hdrfilm',
+                'width': 1024,
+                'height': 768,
+            },
+            'thesampler': {
+                'type': 'multijitter',
+                'sample_count': 64,
+            },
+        },
+        'themesh': mesh,
+    })
+
+    img = mi.render(scene, spp=256)
+    return img
+
+
+# Default to LLVM variant which should be available on all
+# platforms. If you have a system with a CUDA device then comment out LLVM
+# variant and uncomment cuda variant
+mi.set_variant('llvm_ad_rgb')
+# mi.set_variant('cuda_ad_rgb')
+
+# Load mesh and maps using Open3D
+dataset = o3d.data.MonkeyModel()
+mesh = o3d.t.io.read_triangle_mesh(dataset.path)
+mesh_center = mesh.get_axis_aligned_bounding_box().get_center()
+mesh.material.set_default_properties()
+mesh.material.material_name = 'defaultLit'
+mesh.material.scalar_properties['metallic'] = 1.0
+mesh.material.texture_maps['albedo'] = o3d.t.io.read_image(
+    dataset.path_map['albedo'])
+mesh.material.texture_maps['roughness'] = o3d.t.io.read_image(
+    dataset.path_map['roughness'])
+mesh.material.texture_maps['metallic'] = o3d.t.io.read_image(
+    dataset.path_map['metallic'])
+
+print('Render mesh with material converted to Mitsuba principled BSDF')
+mi_mesh = mesh.to_mitsuba('monkey')
+img = render_mesh(mi_mesh, mesh_center.numpy())
+mi.Bitmap(img).write('test.exr')
+
+print('Rendering mesh with Mitsuba smooth plastic BSDF')
+bsdf_smooth_plastic = mi.load_dict({
+    'type': 'plastic',
+    'diffuse_reflectance': {
+        'type': 'rgb',
+        'value': [0.1, 0.27, 0.36]
+    },
+    'int_ior': 1.9
+})
+mi_mesh = mesh.to_mitsuba('monkey', bsdf=bsdf_smooth_plastic)
+img = render_mesh(mi_mesh, mesh_center.numpy())
+mi.Bitmap(img).write('test2.exr')
+
+# Render with Open3D
+o3d.visualization.draw(mesh)
diff --git a/python/open3d/__init__.py b/python/open3d/__init__.py
index d1ced892d11..83dce96c7ff 100644
--- a/python/open3d/__init__.py
+++ b/python/open3d/__init__.py
@@ -34,34 +34,34 @@
 # https://github.com/dmlc/xgboost/issues/1715
 import os
 import sys
-os.environ['KMP_DUPLICATE_LIB_OK'] = 'True'
-from ctypes import CDLL as _CDLL
-from ctypes.util import find_library as _find_library
-from pathlib import Path as _Path
+os.environ["KMP_DUPLICATE_LIB_OK"] = "True"
+from ctypes import CDLL
+from ctypes.util import find_library
+from pathlib import Path
 import warnings
 
 from open3d._build_config import _build_config
-if _build_config["BUILD_GUI"] and not (_find_library('c++abi') or
-                                       _find_library('c++')):
+if _build_config["BUILD_GUI"] and not (find_library("c++abi") or
+                                       find_library("c++")):
     try:  # Preload libc++.so and libc++abi.so (required by filament)
-        _CDLL(str(next((_Path(__file__).parent).glob('*c++abi.*'))))
-        _CDLL(str(next((_Path(__file__).parent).glob('*c++.*'))))
+        CDLL(str(next((Path(__file__).parent).glob("*c++abi.*"))))
+        CDLL(str(next((Path(__file__).parent).glob("*c++.*"))))
     except StopIteration:  # Not found: check system paths while loading
         pass
 
 # Enable CPU rendering based on env vars
-if _build_config["BUILD_GUI"] and sys.platform.startswith('linux') and (
-        os.getenv('OPEN3D_CPU_RENDERING', default='') == 'true'):
-    os.environ['LIBGL_DRIVERS_PATH'] = str(_Path(__file__).parent)
-    _CDLL(_Path(__file__).parent / 'libEGL.so.1')
-    _CDLL(_Path(__file__).parent / 'libGL.so.1')
+if _build_config["BUILD_GUI"] and sys.platform.startswith("linux") and (
+        os.getenv("OPEN3D_CPU_RENDERING", default="") == "true"):
+    os.environ["LIBGL_DRIVERS_PATH"] = str(Path(__file__).parent)
+    CDLL(Path(__file__).parent / "libEGL.so.1")
+    CDLL(Path(__file__).parent / "libGL.so.1")
 
-__DEVICE_API__ = 'cpu'
+__DEVICE_API__ = "cpu"
 if _build_config["BUILD_CUDA_MODULE"]:
     # Load CPU pybind dll gracefully without introducing new python variable.
     # Do this before loading the CUDA pybind dll to correctly resolve symbols
     try:  # StopIteration if cpu version not available
-        _CDLL(str(next((_Path(__file__).parent / 'cpu').glob('pybind*'))))
+        CDLL(str(next((Path(__file__).parent / "cpu").glob("pybind*"))))
     except StopIteration:
         warnings.warn(
             "Open3D was built with CUDA support, but Open3D CPU Python "
@@ -70,13 +70,13 @@
     try:
         # Check CUDA availability without importing CUDA pybind symbols to
         # prevent "symbol already registered" errors if first import fails.
-        _pybind_cuda = _CDLL(
-            str(next((_Path(__file__).parent / 'cuda').glob('pybind*'))))
+        _pybind_cuda = CDLL(
+            str(next((Path(__file__).parent / "cuda").glob("pybind*"))))
         if _pybind_cuda.open3d_core_cuda_device_count() > 0:
-            from open3d.cuda.pybind import (camera, data, geometry, io,
+            from open3d.cuda.pybind import (core, camera, data, geometry, io,
                                             pipelines, utility, t)
             from open3d.cuda import pybind
-            __DEVICE_API__ = 'cuda'
+            __DEVICE_API__ = "cuda"
         else:
             warnings.warn(
                 "Open3D was built with CUDA support, but no suitable CUDA "
@@ -93,13 +93,28 @@
             "binding library not found! Falling back to the CPU Python "
             "binding library.", ImportWarning)
 
-if __DEVICE_API__ == 'cpu':
-    from open3d.cpu.pybind import (camera, data, geometry, io, pipelines,
+if __DEVICE_API__ == "cpu":
+    from open3d.cpu.pybind import (core, camera, data, geometry, io, pipelines,
                                    utility, t)
     from open3d.cpu import pybind
 
-import open3d.core
+
+def _insert_pybind_names(skip_names=()):
+    """Introduce pybind names as open3d names. Skip names corresponding to
+    python subpackages, since they have a different import mechanism."""
+    submodules = {}
+    for modname in sys.modules:
+        if "open3d." + __DEVICE_API__ + ".pybind" in modname:
+            if any("." + skip_name in modname for skip_name in skip_names):
+                continue
+            subname = modname.replace(__DEVICE_API__ + ".pybind.", "")
+            if subname not in sys.modules:
+                submodules[subname] = sys.modules[modname]
+    sys.modules.update(submodules)
+
+
 import open3d.visualization
+_insert_pybind_names(skip_names=("ml",))
 
 __version__ = "@PROJECT_VERSION@"
 
@@ -112,7 +127,7 @@
             platform.machine().startswith("aarch")):
         try:
             shell = get_ipython().__class__.__name__
-            if shell == 'ZMQInteractiveShell':
+            if shell == "ZMQInteractiveShell":
                 print("Jupyter environment detected. "
                       "Enabling Open3D WebVisualizer.")
                 # Set default window system.
@@ -128,11 +143,14 @@
 
 # OPEN3D_ML_ROOT points to the root of the Open3D-ML repo.
 # If set this will override the integrated Open3D-ML.
-if 'OPEN3D_ML_ROOT' in os.environ:
-    print('Using external Open3D-ML in {}'.format(os.environ['OPEN3D_ML_ROOT']))
-    sys.path.append(os.environ['OPEN3D_ML_ROOT'])
+if "OPEN3D_ML_ROOT" in os.environ:
+    print("Using external Open3D-ML in {}".format(os.environ["OPEN3D_ML_ROOT"]))
+    sys.path.append(os.environ["OPEN3D_ML_ROOT"])
 import open3d.ml
 
+# Finally insert pybind names corresponding to ml
+_insert_pybind_names()
+
 
 def _jupyter_labextension_paths():
     """Called by Jupyter Lab Server to detect if it is a valid labextension and
@@ -147,8 +165,8 @@ def _jupyter_labextension_paths():
             directory during widget installation.
     """
     return [{
-        'src': 'labextension',
-        'dest': 'open3d',
+        "src": "labextension",
+        "dest": "open3d",
     }]
 
 
@@ -158,7 +176,7 @@ def _jupyter_nbextension_paths():
 
     Returns:
         section: The section of the Jupyter Notebook Server to change.
-            Must be 'notebook' for widget extensions.
+            Must be "notebook" for widget extensions.
         src: Source directory name to copy files from. Webpack outputs generated
             files into this directory and Jupyter Notebook copies from this
             directory during widget installation.
@@ -170,8 +188,11 @@ def _jupyter_nbextension_paths():
             <jupyter path>/nbextensions/<dest> directory.
     """
     return [{
-        'section': 'notebook',
-        'src': 'nbextension',
-        'dest': 'open3d',
-        'require': 'open3d/extension'
+        "section": "notebook",
+        "src": "nbextension",
+        "dest": "open3d",
+        "require": "open3d/extension"
     }]
+
+
+del os, sys, CDLL, find_library, Path, warnings, _insert_pybind_names
diff --git a/python/open3d/core.py b/python/open3d/core.py
deleted file mode 100644
index 2e8aeab7e3b..00000000000
--- a/python/open3d/core.py
+++ /dev/null
@@ -1,32 +0,0 @@
-# ----------------------------------------------------------------------------
-# -                        Open3D: www.open3d.org                            -
-# ----------------------------------------------------------------------------
-# The MIT License (MIT)
-#
-# Copyright (c) 2018-2021 www.open3d.org
-#
-# Permission is hereby granted, free of charge, to any person obtaining a copy
-# of this software and associated documentation files (the "Software"), to deal
-# in the Software without restriction, including without limitation the rights
-# to use, copy, modify, merge, publish, distribute, sublicense, and/or sell
-# copies of the Software, and to permit persons to whom the Software is
-# furnished to do so, subject to the following conditions:
-#
-# The above copyright notice and this permission notice shall be included in
-# all copies or substantial portions of the Software.
-#
-# THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR
-# IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,
-# FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE
-# AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER
-# LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING
-# FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS
-# IN THE SOFTWARE.
-# ----------------------------------------------------------------------------
-
-import open3d as o3d
-
-if o3d.__DEVICE_API__ == 'cuda':
-    from open3d.cuda.pybind.core import *
-else:
-    from open3d.cpu.pybind.core import *
diff --git a/python/open3d/visualization/__init__.py b/python/open3d/visualization/__init__.py
index 4cdd9187699..aecb7c16b57 100644
--- a/python/open3d/visualization/__init__.py
+++ b/python/open3d/visualization/__init__.py
@@ -25,18 +25,19 @@
 # ----------------------------------------------------------------------------
 
 import open3d
-if open3d.__DEVICE_API__ == 'cuda':
-    if "@BUILD_GUI@" == "ON":
+if open3d.__DEVICE_API__ == "cuda":
+    if open3d._build_config["BUILD_GUI"]:
         from open3d.cuda.pybind.visualization import gui
     from open3d.cuda.pybind.visualization import *
 else:
-    if "@BUILD_GUI@" == "ON":
+    if open3d._build_config["BUILD_GUI"]:
         from open3d.cpu.pybind.visualization import gui
     from open3d.cpu.pybind.visualization import *
 
 from ._external_visualizer import *
 from .draw_plotly import draw_plotly
 from .draw_plotly import draw_plotly_server
+from .to_mitsuba import to_mitsuba
 
-if "@BUILD_GUI@" == "ON":
+if open3d._build_config["BUILD_GUI"]:
     from .draw import draw
diff --git a/python/open3d/visualization/app/__init__.py b/python/open3d/visualization/app/__init__.py
deleted file mode 100644
index 624165176bb..00000000000
--- a/python/open3d/visualization/app/__init__.py
+++ /dev/null
@@ -1,36 +0,0 @@
-# ----------------------------------------------------------------------------
-# -                        Open3D: www.open3d.org                            -
-# ----------------------------------------------------------------------------
-# The MIT License (MIT)
-#
-# Copyright (c) 2018-2021 www.open3d.org
-#
-# Permission is hereby granted, free of charge, to any person obtaining a copy
-# of this software and associated documentation files (the "Software"), to deal
-# in the Software without restriction, including without limitation the rights
-# to use, copy, modify, merge, publish, distribute, sublicense, and/or sell
-# copies of the Software, and to permit persons to whom the Software is
-# furnished to do so, subject to the following conditions:
-#
-# The above copyright notice and this permission notice shall be included in
-# all copies or substantial portions of the Software.
-#
-# THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR
-# IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,
-# FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE
-# AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER
-# LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING
-# FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS
-# IN THE SOFTWARE.
-# ----------------------------------------------------------------------------
-"""Functionality for running Open3D viewer."""
-
-if "@BUILD_GUI@" == "ON":
-    import open3d
-    if open3d.__DEVICE_API__ == 'cuda':
-        from open3d.cuda.pybind.visualization.app import *
-    else:
-        from open3d.cpu.pybind.visualization.app import *
-else:
-    print("Open3D was not compiled with BUILD_GUI, but script is importing "
-          "open3d.visualization.app")
diff --git a/python/open3d/visualization/draw.py b/python/open3d/visualization/draw.py
index 1354455a0ee..69b66399488 100644
--- a/python/open3d/visualization/draw.py
+++ b/python/open3d/visualization/draw.py
@@ -124,4 +124,4 @@ def stop_rpc():
     if non_blocking_and_return_uid:
         return w.uid
     else:
-        gui.Application.instance.run()
\ No newline at end of file
+        gui.Application.instance.run()
diff --git a/python/open3d/visualization/gui/__init__.py b/python/open3d/visualization/gui/__init__.py
deleted file mode 100644
index 5e46849b5a7..00000000000
--- a/python/open3d/visualization/gui/__init__.py
+++ /dev/null
@@ -1,36 +0,0 @@
-# ----------------------------------------------------------------------------
-# -                        Open3D: www.open3d.org                            -
-# ----------------------------------------------------------------------------
-# The MIT License (MIT)
-#
-# Copyright (c) 2018-2021 www.open3d.org
-#
-# Permission is hereby granted, free of charge, to any person obtaining a copy
-# of this software and associated documentation files (the "Software"), to deal
-# in the Software without restriction, including without limitation the rights
-# to use, copy, modify, merge, publish, distribute, sublicense, and/or sell
-# copies of the Software, and to permit persons to whom the Software is
-# furnished to do so, subject to the following conditions:
-#
-# The above copyright notice and this permission notice shall be included in
-# all copies or substantial portions of the Software.
-#
-# THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR
-# IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,
-# FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE
-# AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER
-# LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING
-# FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS
-# IN THE SOFTWARE.
-# ----------------------------------------------------------------------------
-"""Functionality for quickly building Graphical User Interfaces."""
-
-if "@BUILD_GUI@" == "ON":
-    import open3d
-    if open3d.__DEVICE_API__ == 'cuda':
-        from open3d.cuda.pybind.visualization.gui import *
-    else:
-        from open3d.cpu.pybind.visualization.gui import *
-else:
-    print("Open3D was not compiled with BUILD_GUI, but script is importing "
-          "open3d.visualization.gui")
diff --git a/python/open3d/visualization/rendering/__init__.py b/python/open3d/visualization/rendering/__init__.py
deleted file mode 100644
index 72a9351e44e..00000000000
--- a/python/open3d/visualization/rendering/__init__.py
+++ /dev/null
@@ -1,36 +0,0 @@
-# ----------------------------------------------------------------------------
-# -                        Open3D: www.open3d.org                            -
-# ----------------------------------------------------------------------------
-# The MIT License (MIT)
-#
-# Copyright (c) 2018-2021 www.open3d.org
-#
-# Permission is hereby granted, free of charge, to any person obtaining a copy
-# of this software and associated documentation files (the "Software"), to deal
-# in the Software without restriction, including without limitation the rights
-# to use, copy, modify, merge, publish, distribute, sublicense, and/or sell
-# copies of the Software, and to permit persons to whom the Software is
-# furnished to do so, subject to the following conditions:
-#
-# The above copyright notice and this permission notice shall be included in
-# all copies or substantial portions of the Software.
-#
-# THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR
-# IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,
-# FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE
-# AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER
-# LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING
-# FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS
-# IN THE SOFTWARE.
-# ----------------------------------------------------------------------------
-"""Functionality for Physically Based Rendering."""
-
-if "@BUILD_GUI@" == "ON":
-    import open3d
-    if open3d.__DEVICE_API__ == 'cuda':
-        from open3d.cuda.pybind.visualization.rendering import *
-    else:
-        from open3d.cpu.pybind.visualization.rendering import *
-else:
-    print("Open3D was not compiled with BUILD_GUI, but script is importing "
-          "open3d.visualization.rendering")
diff --git a/python/open3d/visualization/to_mitsuba.py b/python/open3d/visualization/to_mitsuba.py
new file mode 100644
index 00000000000..72e025044e4
--- /dev/null
+++ b/python/open3d/visualization/to_mitsuba.py
@@ -0,0 +1,136 @@
+# ----------------------------------------------------------------------------
+# -                        Open3D: www.open3d.org                            -
+# ----------------------------------------------------------------------------
+# The MIT License (MIT)
+#
+# Copyright (c) 2018-2021 www.open3d.org
+#
+# Permission is hereby granted, free of charge, to any person obtaining a copy
+# of this software and associated documentation files (the "Software"), to deal
+# in the Software without restriction, including without limitation the rights
+# to use, copy, modify, merge, publish, distribute, sublicense, and/or sell
+# copies of the Software, and to permit persons to whom the Software is
+# furnished to do so, subject to the following conditions:
+#
+# The above copyright notice and this permission notice shall be included in
+# all copies or substantial portions of the Software.
+#
+# THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR
+# IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,
+# FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE
+# AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER
+# LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING
+# FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS
+# IN THE SOFTWARE.
+# ----------------------------------------------------------------------------
+
+import open3d as o3d
+
+
+def o3d_material_to_bsdf(mat, vertex_color=False):
+    import mitsuba as mi
+
+    def create_bsdf_entry(mat, value, o3d_name, per_vertex):
+        if per_vertex:
+            return {'type': 'mesh_attribute', 'name': 'vertex_color'}
+        elif o3d_name in mat.texture_maps:
+            return {
+                'type':
+                    'bitmap',
+                'bitmap':
+                    mi.Bitmap(mat.texture_maps[o3d_name].as_tensor().numpy())
+            }
+        else:
+            return {'type': 'rgb', 'value': value}
+
+    base_color = mat.vector_properties['base_color'][0:3]
+    roughness = mat.scalar_properties['roughness']
+    metallic = mat.scalar_properties['metallic']
+    reflectance = mat.scalar_properties['reflectance']
+    anisotropy = mat.scalar_properties['anisotropy']
+
+    bsdf_dict = {'type': 'principled'}
+    bsdf_dict['base_color'] = create_bsdf_entry(mat, base_color, 'albedo',
+                                                vertex_color)
+    bsdf_dict['roughness'] = create_bsdf_entry(mat, roughness, 'roughness',
+                                               False)
+    bsdf_dict['metallic'] = create_bsdf_entry(mat, metallic, 'metallic', False)
+    bsdf_dict['anisotropic'] = create_bsdf_entry(mat, anisotropy, 'anisotropy',
+                                                 False)
+    bsdf_dict['specular'] = reflectance
+    bsdf = mi.load_dict(bsdf_dict)
+    return bsdf
+
+
+def to_mitsuba(self, name, bsdf=None):
+    """Convert Open3D TriangleMesh to Mitsuba Mesh.
+
+    Converts an Open3D TriangleMesh to a Mitsuba Mesh which can be used directly
+    in a Mitsbua scene. The TriangleMesh's material will be converted to a
+    Mitsuba Principled BSDF and assigned to the Mitsuba Mesh. Optionally, the
+    user may provide a Mitsuba BSDF to be used instead of converting the Open3D
+    material.
+
+    Args:
+        name (str): Name for the Mitsuba Mesh. Used by Mitsuba as an identifier
+
+        bsdf (default None): If a Mitsuba BSDF is supplied it will be used as
+        the BSDF for the converted mesh. Otherwise, the TriangleMesh's material
+        will be converted to Mitsuba Principled BSDF.
+
+    Returns:
+        A Mitsuba Mesh (with associated BSDF) ready for use in a Mitsuba scene.
+    """
+
+    import mitsuba as mi
+    import numpy as np
+
+    # What features does this mesh have
+    has_normals = 'normals' in self.vertex
+    has_uvs = 'texture_uvs' in self.triangle
+    has_colors = 'colors' in self.vertex
+
+    # Convert Open3D Material to Mitsuba's principled BSDF
+    if bsdf is None:
+        bsdf = o3d_material_to_bsdf(self.material, vertex_color=has_colors)
+
+    # Mesh constructor looks for this specific property for setting BSDF
+    bsdf_prop = mi.Properties()
+    bsdf_prop['mesh_bsdf'] = bsdf
+
+    # Create Mitsuba mesh shell
+    mi_mesh = mi.Mesh(name,
+                      vertex_count=self.vertex.positions.shape[0],
+                      face_count=self.triangle.indices.shape[0],
+                      has_vertex_normals=has_normals,
+                      has_vertex_texcoords=has_uvs,
+                      props=bsdf_prop)
+
+    # Vertex color is not a 'built-in' attribute. Needs to be added.
+    if has_colors:
+        mi_mesh.add_attribute('vertex_color', 3,
+                              self.vertex.colors.numpy().flatten())
+
+    # "Traverse" the mesh to get its updateable parameters
+    mesh_params = mi.traverse(mi_mesh)
+    mesh_params['vertex_positions'] = self.vertex.positions.numpy().flatten()
+    mesh_params['faces'] = self.triangle.indices.numpy().flatten()
+    if has_normals:
+        mesh_params['vertex_normals'] = self.vertex.normals.numpy().flatten()
+    if has_uvs:
+        # Mitsuba wants UVs per-vertex so copy them into place
+        per_vtx_uvs = np.zeros((self.vertex.positions.shape[0], 2))
+        for idx, uvs in zip(self.triangle.indices, self.triangle.texture_uvs):
+            per_vtx_uvs[idx.numpy()] = uvs.numpy()
+        mesh_params['vertex_texcoords'] = np.subtract(1.0,
+                                                      per_vtx_uvs,
+                                                      out=per_vtx_uvs,
+                                                      where=[False,
+                                                             True]).flatten()
+
+    # Let Mitsuba know parameters have been updated
+    return mi_mesh
+
+
+# Add to_mitsuba method to TriangleMesh
+o3d.t.geometry.TriangleMesh.to_mitsuba = to_mitsuba
diff --git a/python/test/core/test_core.py b/python/test/core/test_core.py
index 0eac87f3c7e..01bcea33bb4 100644
--- a/python/test/core/test_core.py
+++ b/python/test/core/test_core.py
@@ -667,6 +667,10 @@ def test_unary_ew_ops(device):
                                -src_vals,
                                rtol=rtol,
                                atol=atol)
+    np.testing.assert_allclose((-src).cpu().numpy(),
+                               -src_vals,
+                               rtol=rtol,
+                               atol=atol)
     np.testing.assert_allclose(src.exp().cpu().numpy(),
                                np.exp(src_vals),
                                rtol=rtol,
diff --git a/python/test/t/geometry/test_raycasting_scene.py b/python/test/t/geometry/test_raycasting_scene.py
index 635eab193ff..4e1c1352de5 100644
--- a/python/test/t/geometry/test_raycasting_scene.py
+++ b/python/test/t/geometry/test_raycasting_scene.py
@@ -285,3 +285,48 @@ def test_output_shapes(shape):
             v.shape
         ) == expected_shape, 'shape mismatch: expected {} but got {} for {}'.format(
             expected_shape, list(v.shape), k)
+
+
+def test_sphere_wrong_occupancy():
+    # This test checks a specific scenario where the old implementation
+    # without ray jitter produced wrong results for a sphere because some
+    # rays miss hitting exactly a vertex or an edge.
+    mesh = o3d.geometry.TriangleMesh.create_sphere(0.8)
+    mesh = o3d.t.geometry.TriangleMesh.from_legacy(mesh)
+
+    scene = o3d.t.geometry.RaycastingScene()
+    scene.add_triangles(mesh)
+
+    min_bound = mesh.vertex.positions.min(0).numpy() * 1.1
+    max_bound = mesh.vertex.positions.max(0).numpy() * 1.1
+
+    xyz_range = np.linspace(min_bound, max_bound, num=6)
+    query_points = np.stack(np.meshgrid(*xyz_range.T),
+                            axis=-1).astype(np.float32)
+
+    occupancy = scene.compute_occupancy(query_points)
+    expected = np.array(
+        [[[0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 0.0, 0.0],
+          [0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 0.0, 0.0],
+          [0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 0.0, 0.0]],
+         [[0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 1.0, 1.0, 0.0, 0.0],
+          [0.0, 1.0, 1.0, 1.0, 1.0, 0.0], [0.0, 1.0, 1.0, 1.0, 1.0, 0.0],
+          [0.0, 0.0, 1.0, 1.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 0.0, 0.0]],
+         [[0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.0, 1.0, 1.0, 1.0, 1.0, 0.0],
+          [0.0, 1.0, 1.0, 1.0, 1.0, 0.0], [0.0, 1.0, 1.0, 1.0, 1.0, 0.0],
+          [0.0, 1.0, 1.0, 1.0, 1.0, 0.0], [0.0, 0.0, 0.0, 0.0, 0.0, 0.0]],
+         [[0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.0, 1.0, 1.0, 1.0, 1.0, 0.0],
+          [0.0, 1.0, 1.0, 1.0, 1.0, 0.0], [0.0, 1.0, 1.0, 1.0, 1.0, 0.0],
+          [0.0, 1.0, 1.0, 1.0, 1.0, 0.0], [0.0, 0.0, 0.0, 0.0, 0.0, 0.0]],
+         [[0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 1.0, 1.0, 0.0, 0.0],
+          [0.0, 1.0, 1.0, 1.0, 1.0, 0.0], [0.0, 1.0, 1.0, 1.0, 1.0, 0.0],
+          [0.0, 0.0, 1.0, 1.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 0.0, 0.0]],
+         [[0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 0.0, 0.0],
+          [0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 0.0, 0.0],
+          [0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 0.0, 0.0]]],
+        dtype=np.float32)
+    np.testing.assert_equal(occupancy.numpy(), expected)
+
+    # we should get the same result with more samples
+    occupancy_3samples = scene.compute_occupancy(query_points, nsamples=3)
+    np.testing.assert_equal(occupancy_3samples.numpy(), expected)
diff --git a/python/tools/cli.py b/python/tools/cli.py
index e13ee49008b..5d7f0fb4557 100644
--- a/python/tools/cli.py
+++ b/python/tools/cli.py
@@ -37,8 +37,7 @@
 class _Open3DArgumentParser(argparse.ArgumentParser):
 
     def error(self, message):
-        sys.stderr.write("Error: %s\n" % message)
-        self.print_help()
+        print(f"Error: {message}\n", file=sys.stderr)
         self.exit(2)
 
 
@@ -72,15 +71,17 @@ def _get_all_examples_dict():
 def _get_runnable_examples_dict():
     examples_dict = _get_all_examples_dict()
     categories_to_remove = [
-        "benchmark", "reconstruction_system", "t_reconstruction_system"
+        "benchmark",
+        "reconstruction_system",
+        "t_reconstruction_system",
     ]
     examples_to_remove = {
-        "io": ["realsense_io",],
+        "io": ["realsense_io"],
         "visualization": [
             "online_processing",
             "tensorboard_pytorch",
             "tensorboard_tensorflow",
-        ]
+        ],
     }
     for cat in categories_to_remove:
         examples_dict.pop(cat)
@@ -127,7 +128,9 @@ def _example_help_categories():
     msg = f"\ncategories:\n"
     for category in sorted(_get_example_categories()):
         msg += f"  {category}\n"
-    msg += "\nTo view the example in each category, run one of the following commands:\n"
+    msg += (
+        "\nTo view the example in each category, run one of the following commands:\n"
+    )
     for category in sorted(_get_example_categories()):
         msg += f"  open3d example --list {category}\n"
     return msg
@@ -135,7 +138,7 @@ def _example_help_categories():
 
 def _example(parser, args):
 
-    if args.category_example == None:
+    if args.category_example is None:
         if args.list:
             for category in _get_example_categories():
                 print("examples in " + category + ": ")
@@ -150,13 +153,12 @@ def _example(parser, args):
     try:
         category = args.category_example.split("/")[0]
         example = args.category_example.split("/")[1]
-    except:
+    except IndexError:
         category = args.category_example
         example = ""
 
     if category not in _get_example_categories():
-        print("Error: invalid category provided: " + category)
-        parser.print_help()
+        print("Error: invalid category provided: " + category, file=sys.stderr)
         parser.exit(2)
 
     if args.list:
@@ -169,13 +171,17 @@ def _example(parser, args):
             print("  open3d example --list\n")
             return 0
         else:
-            print("Error: invalid category provided: " + args.category_example)
-            parser.print_help()
+            print(
+                "Error: invalid category provided: " + args.category_example,
+                file=sys.stderr,
+            )
             parser.exit(2)
 
     if args.category_example not in _get_all_examples():
-        print("Error: invalid example name provided: " + args.category_example)
-        parser.print_help()
+        print(
+            "Error: invalid example name provided: " + args.category_example,
+            file=sys.stderr,
+        )
         parser.exit(2)
 
     examples_dir = _get_examples_dir()
@@ -202,11 +208,10 @@ def _example(parser, args):
 
 
 def _draw(parser, args):
-    if args.filename == None:
+    if args.filename is None:
         parser.print_help()
     elif not os.path.isfile(args.filename):
-        print(f"Error: could not find file: {args.filename}")
-        parser.print_help()
+        print(f"Error: could not find file: {args.filename}", file=sys.stderr)
         parser.exit(2)
 
     removed_arg = sys.argv[1]
@@ -216,6 +221,26 @@ def _draw(parser, args):
     return 0
 
 
+def _draw_webrtc(parser, args):
+    if args.filename is None:
+        parser.print_help()
+    elif not os.path.isfile(args.filename):
+        print(f"Error: could not find file: {args.filename}", file=sys.stderr)
+        parser.exit(2)
+    if args.bind_all:
+        os.environ["WEBRTC_IP"] = "0.0.0.0"
+    filetype = o3d.io.read_file_geometry_type(args.filename)
+    if (filetype & o3d.io.CONTAINS_TRIANGLES):
+        geometry = o3d.io.read_triangle_model(args.filename)
+    else:
+        geometry = o3d.t.io.read_point_cloud(args.filename)
+        if 'normals' not in geometry.point and 'colors' not in geometry.point:
+            geometry.estimate_normals()
+            geometry.normalize_normals()
+    o3d.visualization.webrtc_server.enable_webrtc()
+    o3d.visualization.draw(geometry)
+
+
 def main():
     print(f"***************************************************\n"
           f"* Open3D: A Modern Library for 3D Data Processing *\n"
@@ -228,12 +253,15 @@ def main():
     main_parser = _Open3DArgumentParser(
         description="Open3D commad-line tools",
         add_help=False,
-        formatter_class=argparse.RawTextHelpFormatter)
-    main_parser.add_argument("-V",
-                             "--version",
-                             action="version",
-                             version="Open3D " + o3d.__version__,
-                             help="Show program's version number and exit.")
+        formatter_class=argparse.RawTextHelpFormatter,
+    )
+    main_parser.add_argument(
+        "-V",
+        "--version",
+        action="version",
+        version="Open3D " + o3d.__version__,
+        help="Show program's version number and exit.",
+    )
     main_parser.add_argument("-h",
                              "--help",
                              action="help",
@@ -256,13 +284,15 @@ def main():
         add_help=False,
         description=example_help + _example_help_categories(),
         help=example_help,
-        formatter_class=argparse.RawTextHelpFormatter)
+        formatter_class=argparse.RawTextHelpFormatter,
+    )
     parser_example.add_argument(
         "category_example",
         nargs="?",
         help=
         "Category/example_name of an example (supports .py extension too)\n",
-        type=_support_choice_with_dot_py)
+        type=_support_choice_with_dot_py,
+    )
     parser_example.add_argument("example_args",
                                 nargs="*",
                                 help="Arguments for the example to be run\n")
@@ -277,7 +307,8 @@ def main():
         "  open3d example --list \n"
         "  open3d example --list [category]\n"
         "e.g.:\n"
-        "  open3d example --list geometry\n ")
+        "  open3d example --list geometry\n ",
+    )
     parser_example.add_argument(
         "-s",
         "--show",
@@ -288,7 +319,8 @@ def main():
         "usage:\n"
         "  open3d example --show [category]/[example_name]\n"
         "e.g.:\n"
-        "  open3d example --show geometry/triangle_mesh_deformation\n ")
+        "  open3d example --show geometry/triangle_mesh_deformation\n",
+    )
     parser_example.add_argument("-h",
                                 "--help",
                                 action="help",
@@ -298,14 +330,15 @@ def main():
     draw_help = (
         "Load and visualize a 3D model. Example usage:\n"
         "  open3d draw                                            # Start a blank Open3D viewer\n"
-        "  open3d draw path/to/model_file                         # Visualize a 3D model file\n"
+        "  open3d draw path/to/model_file                         # Visualize a 3D model file\n\n"
     )
     parser_draw = subparsers.add_parser(
         "draw",
         description=draw_help,
         help=draw_help,
         add_help=False,
-        formatter_class=argparse.RawTextHelpFormatter)
+        formatter_class=argparse.RawTextHelpFormatter,
+    )
 
     parser_draw.add_argument("filename",
                              nargs="?",
@@ -316,6 +349,39 @@ def main():
                              help="Show this help message and exit.")
     parser_draw.set_defaults(func=_draw)
 
+    draw_web_help = (
+        "Load and visualize a 3D model in a browser with WebRTC. Optionally, you can\n"
+        "customize the serving IP address and port with WEBRTC_IP and WEBRTC_PORT\n"
+        "environment variables. Example usage:\n"
+        "  open3d draw_web path/to/model_file            # Visualize at http://localhost:8888\n"
+        "  open3d draw_web --bind_all path/to/model_file # Serve to the entire local network\n"
+        "                                                # at http://hostname.domainname:8888\n"
+    )
+    parser_draw_web = subparsers.add_parser(
+        "draw_web",
+        description=draw_web_help,
+        help=draw_web_help,
+        add_help=False,
+        formatter_class=argparse.RawTextHelpFormatter,
+    )
+
+    parser_draw_web.add_argument("filename",
+                                 nargs="?",
+                                 help="Name of the mesh or point cloud file.")
+    parser_draw_web.add_argument(
+        "--bind_all",
+        required=False,
+        action="store_true",
+        dest="bind_all",
+        help="Listen for connections on all interfaces in the local network.\n"
+        "Note: There is no encryption.",
+    )
+    parser_draw_web.add_argument("-h",
+                                 "--help",
+                                 action="help",
+                                 help="Show this help message and exit.")
+    parser_draw_web.set_defaults(func=_draw_webrtc)
+
     args = main_parser.parse_args()
     if args.command in subparsers.choices.keys():
         return args.func(subparsers.choices[args.command], args)
diff --git a/util/ci_utils.sh b/util/ci_utils.sh
index 39f2c0d4dde..2112ce70d58 100644
--- a/util/ci_utils.sh
+++ b/util/ci_utils.sh
@@ -419,12 +419,12 @@ build_docs() {
 		"-DGLIBCXX_USE_CXX11_ABI=OFF"
 		"-DBUILD_TENSORFLOW_OPS=ON"
 		"-DBUILD_PYTORCH_OPS=ON"
-		"-DBUNDLE_OPEN3D_ML=ON"
 		"-DBUILD_EXAMPLES=OFF"
 	)
 	set -x # Echo commands on
 	cmake "${cmakeOptions[@]}" \
 		-DENABLE_HEADLESS_RENDERING=ON \
+		-DBUNDLE_OPEN3D_ML=OFF \
 		-DBUILD_GUI=OFF \
 		-DBUILD_WEBRTC=OFF \
 		-DBUILD_JUPYTER_EXTENSION=OFF \
@@ -444,6 +444,7 @@ build_docs() {
 	set -x # Echo commands on
 	cmake "${cmakeOptions[@]}" \
 		-DENABLE_HEADLESS_RENDERING=OFF \
+		-DBUNDLE_OPEN3D_ML=ON \
 		-DBUILD_GUI=ON \
 		-DBUILD_WEBRTC=ON \
 		-DBUILD_JUPYTER_EXTENSION=OFF \
